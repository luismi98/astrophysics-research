{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jt -t onedork -T\n",
    "# !jt -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False # To make auto-complete faster\n",
    "\n",
    "#Reloads imported files automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:88% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import os\n",
    "from collections import namedtuple\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import colormaps as mplcmaps\n",
    "\n",
    "from plotting.matplotlib_param_funcs import set_matplotlib_params,reset_rcParams\n",
    "set_matplotlib_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.compute_variables as CV\n",
    "import src.bootstrap_errors as bootstrap\n",
    "import src.montecarlo_errors as monte_carlo\n",
    "from src.errorconfig import MonteCarloConfig,BootstrapConfig\n",
    "\n",
    "import plotting.plotting_helpers as PH\n",
    "import plotting.map_functions as mapf\n",
    "import plotting.mixed_plots as MP\n",
    "\n",
    "import utils.error_helpers as error_helpers\n",
    "import utils.miscellaneous_functions as MF\n",
    "import utils.coordinates as coordinates\n",
    "import utils.load_sim as load_sim\n",
    "import utils.load_data as load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHOOSE\n",
    "\n",
    "x_var = \"l\"\n",
    "y_var = \"b\"\n",
    "\n",
    "vel_x_var = 'r'\n",
    "vel_y_var = 'l'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_symbol = \"^\\circ\"\n",
    "\n",
    "symbol_dict = mapf.get_kinematic_symbols_dict(x_variable=x_var,\n",
    "                                             y_variable=y_var,\n",
    "                                             vel_x_variable=vel_x_var,\n",
    "                                             vel_y_variable=vel_y_var)\n",
    "\n",
    "units_dict = mapf.get_kinematic_units_dict(degree_symbol=degree_symbol)\n",
    "\n",
    "pos_symbols_dict,pos_units_dict = mapf.get_position_symbols_and_units_dict(degree_symbol=r\"$%s$\"%degree_symbol)\n",
    "\n",
    "titles_dict = mapf.get_kinematic_titles_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_path = '/Users/luismi/Desktop/MRes_UCLan/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_path_spatial_cuts(base_path, spatial_cuts):\n",
    "    \n",
    "    full_str = MF.combine_multiple_cut_dicts_into_str(spatial_cuts, cut_separator=\"_\", order_separator=\"/\")\n",
    "    \n",
    "    save_path = base_path + full_str + \"/\"\n",
    "    \n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_funcs_dict = {\n",
    "    \"anisotropy\": CV.calculate_anisotropy,\n",
    "    \"correlation\": CV.calculate_correlation,\n",
    "    \"tilt_abs\": CV.calculate_tilt\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "zabs = True\n",
    "# zabs = False\n",
    "\n",
    "R0 = 8.1\n",
    "\n",
    "GSR = True\n",
    "# GSR = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_choice = \"708main\"\n",
    "# sim_choice = \"708mainDiff4\"\n",
    "# sim_choice = \"708mainDiff5\"\n",
    "\n",
    "rot_angle = 27\n",
    "axisymmetric = False\n",
    "pos_scaling = 1.7\n",
    "\n",
    "filename = load_sim.build_filename(choice=sim_choice,rot_angle=rot_angle,R0=R0,axisymmetric=axisymmetric,zabs=zabs,pos_factor=pos_scaling,GSR=GSR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_path = general_path+f\"data/{sim_choice}/numpy_arrays/\"\n",
    "        \n",
    "df0 = load_sim.load_simulation(path=np_path,filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_errors = True\n",
    "# obs_errors = False\n",
    "\n",
    "data_zabs = True\n",
    "# data_zabs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = general_path+\"data/Observational_data/\"\n",
    "\n",
    "data = load_data.load_and_process_data(data_path=data_path, error_bool=obs_errors, zabs=zabs, R0=R0, GSR=GSR, drop_unused=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# Data uncertainty histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = general_path + \"graphs/Observations/Apogee/Uncertainties/\"\n",
    "save_path += f\"{var}/\"\n",
    "\n",
    "MF.create_dir(save_path)\n",
    "\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuts_dict = {}\n",
    "cuts_dict = {\"FeH\":[-1,0.61]}\n",
    "\n",
    "data_df = MF.apply_cuts_to_df(data, cuts_dict=cuts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 100\n",
    "# log_bool = True\n",
    "log_bool = False\n",
    "# plot_range = [0,0.4]\n",
    "plot_range = None\n",
    "\n",
    "if True: # error hist\n",
    "    fig,ax=plt.subplots()\n",
    "    ax.hist(data_df[var+\"_error\"],bins=bins,log=log_bool,range=plot_range)\n",
    "    ax.axvline(data_df[var+\"_error\"].median(),label=\"Median: %s %s\"%(MF.return_int_or_dec(data_df[var+\"_error\"].median(),2),mapf.get_units(var)),color=\"red\")\n",
    "    ax.set_xlabel(mapf.get_symbol(var+\"_error\")+(f\" [{mapf.get_units(var)}]\" if mapf.get_units(var) != \"\" else \"\"))\n",
    "    ax.set_ylabel(r\"$N$\",rotation=0,labelpad=20)\n",
    "    ax.legend()\n",
    "\n",
    "if True: # filename, save\n",
    "    filename = var\n",
    "    filename += \"_\" + MF.extract_str_from_cuts_dict(cuts_dict) if len(cuts_dict) > 0 else \"\"\n",
    "    filename += f\"_{plot_range[0]}range{plot_range[1]}\" if plot_range is not None else \"\"\n",
    "    filename += f\"_{bins}bins\"\n",
    "    filename += \"_log\" if log_bool else \"\"\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        plt.savefig(save_path+filename+\".png\", bbox_inches=\"tight\")\n",
    "        print(\"Saved in\",save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 100\n",
    "# log_bool = True\n",
    "log_bool = False\n",
    "# plot_range = [0,0.2]\n",
    "plot_range = None\n",
    "\n",
    "if True: # fractional error hist\n",
    "    fig,ax=plt.subplots()\n",
    "\n",
    "    ax.hist(data_df[var+\"_error\"]/np.abs(data_df[var]),bins=bins,range=plot_range,log=log_bool)\n",
    "    ax.axvline((data_df[var+\"_error\"]/np.abs(data_df[var])).median(),\\\n",
    "               label=\"Median $%s$\"%(100*MF.return_int_or_dec((data_df[var+\"_error\"]/np.abs(data_df[var])).median(),2)) +r\"$~$%\",color=\"red\")\n",
    "    ax.set_xlabel(mapf.get_symbol(var+\"_fractionalerror\"))\n",
    "    ax.set_ylabel(r\"$N$\",rotation=0,labelpad=20)\n",
    "    ax.legend()\n",
    "\n",
    "if True: # filename, save\n",
    "    filename = f\"{var}_frac\"\n",
    "    filename += \"_\" + MF.extract_str_from_cuts_dict(cuts_dict)\n",
    "    filename += f\"_{plot_range[0]}range{plot_range[1]}\" if plot_range is not None else \"\"\n",
    "    filename += f\"_{bins}bins\"\n",
    "    filename += \"_log\" if log_bool else \"\"\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        plt.savefig(save_path+filename+\".png\", bbox_inches=\"tight\")\n",
    "        print(\"Saved in\",save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_path_MC(perturbed_vars, data_bool):\n",
    "    \n",
    "    save_path = general_path + f\"graphs/other_plots/MonteCarlo/\" + str.join(\",\", perturbed_vars) + \"/\"\n",
    "    MF.create_dir(save_path)\n",
    "\n",
    "    save_path += \"data/\" if data_bool else \"model/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_bool = True\n",
    "data_bool = False\n",
    "\n",
    "# perturbed_vars = [\"d\",\"vr\",\"pmra\",\"pmdec\"]\n",
    "perturbed_vars = [\"d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_bool:\n",
    "    cuts_dict = {\"FeH\":[-1,-0.21], \"l\":[-2,2], \"R\":[0,2]}\n",
    "#     cuts_dict = {\"FeH\":[-0.21,0.61], \"l\":[-2,2], \"R\":[0,3.5]}\n",
    "#     cuts_dict = {\"FeH\":[-0.21,0.61], \"l\":[-2,2], \"R\":[0,2]}\n",
    "else:\n",
    "#     cuts_dict={\"age\":[0,4],\"R\":[0,5],\"l\":[-2,2],\"b\":[0,0.01], \"R\":[0,3.5]} # nuclear disc\n",
    "#     cuts_dict={\"age\":[4,7],\"l\":[-2,2],\"b\":[3.51,6.6], \"R\":[0,3.5]} # young pop\n",
    "#     cuts_dict={\"age\":[4,7],\"l\":[-2,2],\"b\":[3,6], \"R\":[0,2]} # young pop\n",
    "    cuts_dict={\"age\":[9.5,10],\"l\":[-2,2],\"b\":[3.51,6.6], \"R\":[0,3.5]} # old pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = MF.apply_cuts_to_df(data if data_bool else df0, cuts_dict=cuts_dict)\n",
    "print(len(df),\"stars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func_name = \"correlation\"\n",
    "func_name = \"anisotropy\"\n",
    "# func_name = \"tilt_abs\"\n",
    "\n",
    "func = all_funcs_dict[func_name]\n",
    "\n",
    "true_value = func(vx=df[\"v\"+vel_x_var].values,vy=df[\"v\"+vel_y_var].values)\n",
    "print(f\"{func_name}: {true_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"d\" in perturbed_vars:\n",
    "    affected_cuts_dict = {k:v for k,v in cuts_dict.items() if k in [\"d\",\"R\"]}\n",
    "else:\n",
    "    affected_cuts_dict = None\n",
    "    \n",
    "repeats = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## Multiple frac errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = get_save_path_MC(perturbed_vars=perturbed_vars,data_bool=data_bool)\n",
    "\n",
    "save_path += \"multiple_frac_errors/\"\n",
    "MF.create_dir(save_path)\n",
    "\n",
    "save_path += func_name + \"/\"\n",
    "MF.create_dir(save_path)\n",
    "\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MC = MF.apply_cuts_to_df(data if data_bool else df0, cuts_dict=MF.clean_cuts_from_dict(cuts_dict,cuts_to_remove=affected_cuts_dict))\n",
    "\n",
    "print(f\"Before affected cuts: {len(df_MC)}\")\n",
    "print(f\"After affected cuts: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_result_68 = bootstrap.scipy_bootstrap(vx=df[\"v\"+vel_x_var],vy=df[\"v\"+vel_y_var],function=all_funcs_dict[func_name],repeats=repeats,\n",
    "                                           confidence_level=0.68)\n",
    "# boot_result_95 = bootstrap.scipy_bootstrap(vx=df[\"v\"+vel_x_var],vy=df[\"v\"+vel_y_var],function=all_funcs_dict[func_name],repeats=repeats,\n",
    "#                                            confidence_level=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_frac_err = 0.05\n",
    "max_frac_err = 0.35\n",
    "frac_err_step = 0.025\n",
    "\n",
    "frac_errors = np.arange(min_frac_err, max_frac_err+frac_err_step, frac_err_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_MC_results = np.full(shape=(len(frac_errors),repeats), fill_value=None)\n",
    "\n",
    "montecarloconfig = MonteCarloConfig(perturbed_vars=perturbed_vars,affected_cuts_dict=affected_cuts_dict,repeats=repeats,symmetric=False)\n",
    "\n",
    "for i,frac_err in enumerate(frac_errors):\n",
    "    print(f\"{frac_err:.3f}\",end=\"; \")\n",
    "    \n",
    "    montecarloconfig.error_frac = frac_err\n",
    "    \n",
    "    MC_result = monte_carlo.get_std_MC(function=func,df=df_MC,config=montecarloconfig,true_value=true_value,vel_x_var=vel_x_var,vel_y_var=vel_y_var)\n",
    "    \n",
    "    all_MC_results[i] = MC_result.MC_distribution\n",
    "    \n",
    "if None in all_MC_results:\n",
    "    raise ValueError(\"Not all MC results were filled correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_boot_CI = True\n",
    "# show_boot_CI = False\n",
    "\n",
    "boot_CI_level = 68\n",
    "# boot_CI_level = 95\n",
    "\n",
    "if boot_CI_level == 68:\n",
    "    CI_low,CI_high = boot_result_68.confidence_interval\n",
    "elif boot_CI_level == 95:\n",
    "    CI_low,CI_high = boot_result_95.confidence_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_bool = True\n",
    "save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "deviations = np.mean(all_MC_results, axis=1) - true_value\n",
    "\n",
    "norm = plt.Normalize(vmin=deviations.min(), vmax=deviations.max())\n",
    "cmap = PH.choose_cmap(vmin=deviations.min(), vmax=deviations.max(),all_from_divergent_cmap=True)\n",
    "\n",
    "colors = [cmap(norm(dev)) for dev in deviations]\n",
    "\n",
    "if True: # plot\n",
    "    \n",
    "    for f,frac_err in enumerate(frac_errors):\n",
    "        ax.boxplot(x=all_MC_results[f],positions=[f],patch_artist=True,widths=0.75,medianprops={\"color\":\"k\"},\n",
    "                   boxprops={\"facecolor\": colors[f]})\n",
    "    \n",
    "    ax.axhline(y=true_value,color=\"red\",label=\"True value\")\n",
    "    \n",
    "    if show_boot_CI:\n",
    "        ax.axhline(y=CI_low,color=\"grey\",linestyle=\"--\")\n",
    "        ax.axhline(y=CI_high,color=\"grey\",linestyle=\"--\",label=f\"{boot_CI_level}% bootstrap CI\")\n",
    "\n",
    "if True: # axis, legend\n",
    "    xticklabels = len(frac_errors)*[None]\n",
    "    for f,frac_err in enumerate(frac_errors):\n",
    "        if f%2!=0:\n",
    "            continue\n",
    "        xticklabels[f] = f\"{frac_err:.3f}\"\n",
    "    \n",
    "    ax.set_xticks(ticks=range(len(frac_errors)),labels=xticklabels)\n",
    "    \n",
    "    ax.set(xlabel=\"Fractional distance error\", ylabel=mapf.get_kinematic_titles_dict()[func_name])\n",
    "    \n",
    "    if func_name == \"tilt_abs\":\n",
    "        ax.set_ylim(bottom=max([-45,ax.get_ylim[0]]))\n",
    "    \n",
    "    ax.legend()\n",
    "\n",
    "if True: # filename and save\n",
    "    filename = func_name\n",
    "    filename += f\"_boxplots_{min_frac_err}frac{max_frac_err}step{frac_err_step}\"\n",
    "    filename += \"_\" + MF.extract_str_from_cuts_dict(cuts_dict)\n",
    "    filename += f\"_{repeats}repeats\"\n",
    "    filename += f\"_boot{boot_CI_level}CI\"\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        print(\"Saving in\",save_path)\n",
    "        \n",
    "        for fileformat in [\".png\",\".pdf\"]:\n",
    "            plt.savefig(save_path+filename+fileformat, bbox_inches=\"tight\", dpi=250)\n",
    "            print(fileformat)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_boot_dist = True\n",
    "# show_boot_dist = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "min_i = 0\n",
    "\n",
    "if True: # range, colors\n",
    "    hist_range = [\n",
    "        min([np.min(all_MC_results), np.min(boot_result_68.bootstrap_distribution)]),\n",
    "        max([np.max(all_MC_results), np.max(boot_result_68.bootstrap_distribution)])\n",
    "    ]\n",
    "\n",
    "    deviations = all_MC_results.mean(axis=1) - true_value\n",
    "    \n",
    "    norm = plt.Normalize(vmin=deviations.min(), vmax=deviations.max())\n",
    "    # cmap = PH.choose_cmap(vmin=deviations.min(), vmax=deviations.max(),all_from_divergent_cmap=True, divergent_cmap=mplcmaps[\"seismic\"])\n",
    "    cmap=mplcmaps[\"jet\"]\n",
    "    colors = [cmap(norm(dev)) for dev in deviations]\n",
    "    \n",
    "if True: # plot\n",
    "    for i,frac_err in enumerate(frac_errors):\n",
    "        if i < min_i: continue\n",
    "\n",
    "        ax.hist(all_MC_results[i],alpha=0.5,bins=100,range=hist_range,histtype=\"barstacked\",edgecolor=\"k\",label=f\"{frac_err:.3f}\",\\\n",
    "                color=colors[i])\n",
    "\n",
    "    if show_boot_dist:\n",
    "        ax.hist(boot_result_68.bootstrap_distribution,alpha=0.5,bins=100,histtype=\"barstacked\",range=hist_range,edgecolor=\"k\",label=\"Bootstrap\",color=\"grey\")\n",
    "\n",
    "    ax.axvline(x=true_value,color=\"red\")\n",
    "    ax.legend()\n",
    "    ax.set(xlabel=mapf.get_kinematic_titles_dict()[func_name],ylabel=r\"$N$\")\n",
    "\n",
    "if True: # filename and save\n",
    "    filename = func_name\n",
    "    filename += f\"_hists_{MF.return_int_or_dec(frac_errors[min_i],2)}frac{MF.return_int_or_dec(max_frac_err,2)}step{frac_err_step}\"\n",
    "    filename += \"_\" + MF.extract_str_from_cuts_dict(cuts_dict)\n",
    "    filename += f\"_{repeats}repeats\"\n",
    "    filename += \"_boot\" if show_boot_dist else \"\"\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        print(\"Saving in\",save_path)\n",
    "        plt.savefig(save_path+filename+\".png\", bbox_inches=\"tight\", dpi=250)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "### Multiple panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_vars = [\"d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = get_save_path_MC(perturbed_vars=perturbed_vars,data_bool=data_bool)\n",
    "\n",
    "save_path += \"multiple_frac_errors/\"\n",
    "MF.create_dir(save_path)\n",
    "\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_cuts = {\"l\":[-2,2],\"b\":[3.51,6.6]}\n",
    "affected_cut = {\"R\":[0,3.5]}\n",
    "\n",
    "pop_cuts_list = [\n",
    "    {\"age\":[4,7]},\n",
    "    {\"age\":[9.5,10]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_list = [\"anisotropy\", \"correlation\", \"tilt_abs\"]; func_prefix = \"anicorr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MC_ages = [\n",
    "    MF.apply_cuts_to_df(df0, cuts_dict=[spatial_cuts,pop_cut]) for pop_cut in pop_cuts_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_frac_err = 0.05\n",
    "max_frac_err = 0.35\n",
    "frac_err_step = 0.025\n",
    "\n",
    "frac_errors = np.arange(min_frac_err, max_frac_err+frac_err_step, frac_err_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = 500\n",
    "\n",
    "boot_CI_level = 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values = np.full(shape=(len(pop_cuts_list), len(func_list)), fill_value=None)\n",
    "boot_CIs = np.full(shape=(len(pop_cuts_list), len(func_list), 2), fill_value=None)\n",
    "all_MC_results = np.full(shape=(len(pop_cuts_list), len(func_list), len(frac_errors),repeats), fill_value=None)\n",
    "\n",
    "montecarloconfig = MonteCarloConfig(perturbed_vars=perturbed_vars,affected_cuts_dict=affected_cut,repeats=repeats)\n",
    "\n",
    "for a,df_MC in enumerate(df_MC_ages):\n",
    "    print(\"age:\",pop_cuts_list[a][\"age\"])\n",
    "    \n",
    "    df = MF.apply_cuts_to_df(df_MC, cuts_dict=affected_cut)\n",
    "    \n",
    "    for f,func_name in enumerate(func_list):\n",
    "        print(func_name)\n",
    "        \n",
    "        func = all_funcs_dict[func_name]\n",
    "    \n",
    "        true_values[a,f] = func(vx=df[\"v\"+vel_x_var].values,vy=df[\"v\"+vel_y_var].values)\n",
    "        \n",
    "        boot_res = bootstrap.scipy_bootstrap(vx=df[\"v\"+vel_x_var],vy=df[\"v\"+vel_y_var],function=func,repeats=repeats,\n",
    "                                               confidence_level=boot_CI_level/100)\n",
    "        \n",
    "        boot_CIs[a,f] = boot_res.confidence_interval\n",
    "        \n",
    "        for e,frac_err in enumerate(frac_errors):\n",
    "            print(f\"{frac_err:.3f}\",end=\"; \" if frac_err != max(frac_errors) else \"\\n\")\n",
    "\n",
    "            montecarloconfig.error_frac = frac_err\n",
    "\n",
    "            MC_result = monte_carlo.get_std_MC(function=func,df=df_MC,config=montecarloconfig,true_value=true_value,vel_x_var=vel_x_var,vel_y_var=vel_y_var)\n",
    "\n",
    "            all_MC_results[a,f,e] = MC_result.MC_distribution\n",
    "            \n",
    "    print(\"\\n\")\n",
    "\n",
    "if True: # check all arrays were filled correctly\n",
    "    assert None not in true_values, \"Not all true values were filled correctly\"\n",
    "    assert None not in boot_CIs, \"Not all boot CIs were filled correctly\"\n",
    "    assert None not in all_MC_results, \"Not all MC results were filled correctly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_boot_CI = True\n",
    "# show_boot_CI = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs=plt.subplots(figsize=(16,15),ncols=len(pop_cuts_list),nrows=len(func_list),sharex=True,gridspec_kw={\"hspace\":0})\n",
    "\n",
    "for col in range(len(pop_cuts_list)):\n",
    "    for row,func_name in enumerate(func_list):\n",
    "        \n",
    "        ax = axs[row,col]\n",
    "        true_value = true_values[col,row]\n",
    "\n",
    "        if True: # plot\n",
    "            \n",
    "            deviations = np.mean(all_MC_results[col,row], axis=1) - true_value\n",
    "            norm = plt.Normalize(vmin=deviations.min(), vmax=deviations.max())\n",
    "            cmap = PH.choose_cmap(vmin=deviations.min(), vmax=deviations.max(),all_from_divergent_cmap=True)\n",
    "            colors = [cmap(norm(dev)) for dev in deviations]\n",
    "\n",
    "            for f,frac_err in enumerate(frac_errors):\n",
    "                ax.boxplot(x=all_MC_results[col,row,f],positions=[f],patch_artist=True,widths=0.75,medianprops={\"color\":\"k\"},\n",
    "                           boxprops={\"facecolor\": colors[f]})\n",
    "\n",
    "            ax.axhline(y=true_value,color=\"blueviolet\",label=\"True value\", linestyle=\"--\")\n",
    "            \n",
    "            if PH.shall_plot_zero_line(minima=all_MC_results[col,row,f].min(), maxima=all_MC_results[col,row,f].max()):\n",
    "                ax.axhline(y=0,color=\"grey\",linestyle=\"dotted\")\n",
    "                \n",
    "\n",
    "            if show_boot_CI:\n",
    "                \n",
    "                CI_low,CI_high = boot_CIs[col,row]\n",
    "                ax.fill_between(x=ax.get_xlim(),y1=CI_low,y2=CI_high,color=\"grey\",alpha=0.15,label=f\"{boot_CI_level}% bootstrap CI\")\n",
    "\n",
    "        if True: # axis, title, legend\n",
    "            xticklabels = len(frac_errors)*[None]\n",
    "            for f,frac_err in enumerate(frac_errors):\n",
    "                if f%2!=0:\n",
    "                    continue\n",
    "                xticklabels[f] = f\"{frac_err:.3f}\"\n",
    "\n",
    "            ax.set_xticks(ticks=range(len(frac_errors)),labels=xticklabels)\n",
    "            \n",
    "            if col == 0:\n",
    "                ax.set_ylabel(mapf.get_kinematic_titles_dict()[func_name])\n",
    "                \n",
    "            if row == len(func_list) - 1:\n",
    "                ax.set_xlabel(\"Fractional distance error\")\n",
    "\n",
    "            if func_name == \"tilt_abs\":\n",
    "                ax.set_ylim(bottom=max([-45,ax.get_ylim()[0]]))\n",
    "            \n",
    "            if row == 0:\n",
    "                ax.set_title([\"Young\",\"Old\"][col])\n",
    "            if col+row==0:\n",
    "                ax.legend()\n",
    "\n",
    "if True: # filename and save\n",
    "    filename = func_prefix\n",
    "    filename += f\"_boxplots_{min_frac_err}frac{max_frac_err}step{frac_err_step}\"\n",
    "    filename += \"_\" + MF.combine_multiple_cut_dicts_into_str(pop_cuts_list)\n",
    "    filename += \"_\" + MF.combine_multiple_cut_dicts_into_str([spatial_cuts,affected_cut],order_separator=\"_\")\n",
    "    filename += f\"_{repeats}repeats\"\n",
    "    filename += f\"_boot{boot_CI_level}CI\"\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        print(\"Saving in\",save_path)\n",
    "        \n",
    "        for fileformat in [\".png\",\".pdf\"]:\n",
    "            plt.savefig(save_path+filename+fileformat, bbox_inches=\"tight\", dpi=300)\n",
    "            print(fileformat)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "## Single MC error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frac_error = 0.1\n",
    "frac_error = 0.2\n",
    "# frac_error = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "montecarloconfig = MonteCarloConfig(perturbed_vars=perturbed_vars,affected_cuts_dict=affected_cuts_dict,error_frac=frac_error,repeats=repeats,symmetric=False)\n",
    "\n",
    "bootstrapconfig = BootstrapConfig(repeats=repeats,symmetric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MC = MF.apply_cuts_to_df(data if data_bool else df0, cuts_dict=MF.clean_cuts_from_dict(cuts_dict,affected_cuts_dict))\n",
    "print(len(df),len(df_MC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_result = monte_carlo.get_std_MC(function=func,df=df_MC,config=montecarloconfig,true_value=true_value,\\\n",
    "                                                               vel_x_var=vel_x_var,vel_y_var=vel_y_var)\n",
    "\n",
    "boot_result = bootstrap.get_std_bootstrap(function=func,vx=df[f\"v{vel_x_var}\"].values,vy=df[f\"v{vel_y_var}\"].values,config=bootstrapconfig)\n",
    "\n",
    "print(f\"Mean\\t MC: {np.mean(MC_values):.4f}. Boot: {np.mean(boot_result.bootstrap_distribution):.4f}\")\n",
    "print(f\"Median\\t MC: {np.median(MC_values):.4f}. Boot: {np.median(boot_result.bootstrap_distribution):.4f}\")\n",
    "print(f\"CI low\\t MC: {MC_result.confidence_interval[0]:.4f}. Boot: {boot_result.confidence_interval[0]:.4f}\")\n",
    "print(f\"CI high\\t MC: {MC_result.confidence_interval[1]:.4f}. Boot: {boot_result.confidence_interval[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_bool = True\n",
    "save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_hist_bool = True\n",
    "# boot_hist_bool = False\n",
    "MC_bar_width = None\n",
    "# MC_bar_width = 0.001\n",
    "\n",
    "if True: # boot & MC value hist\n",
    "    fig,ax=plt.subplots()\n",
    "    if MC_bar_width is not None:\n",
    "        ax.hist(MC_result.MC_distribution,bins=50,color=\"blue\",alpha=0.5,label=fr\"MC values ($R={repeats}$)\",width=MC_bar_width)\n",
    "    else: # It doesn't like it if I pass width=None and I couldn't find what the default is\n",
    "        ax.hist(MC_result.MC_distribution,bins=50,color=\"blue\",alpha=0.5,label=fr\"MC values ($R={repeats}$)\")\n",
    "    if boot_hist_bool:\n",
    "        ax.hist(boot_result.bootstrap_distribution,bins=50,color=\"green\",alpha=0.5, label=fr\"Bootstrap values ($R={repeats}$)\")\n",
    "    ax.axvline(true_value,color=\"red\",label=\"True value\")\n",
    "    ax.set_xlabel(symbol_dict[func_name]); ax.set_ylabel(r\"$N$\",rotation=0,labelpad=20)\n",
    "    ax.legend()\n",
    "\n",
    "if True: # filename and save\n",
    "    filename = func_name\n",
    "    filename += f\"_{frac_error}fracErr\" if frac_error is not None else \"_dataErr\"\n",
    "    filename += f\"_noBoot\" if not boot_hist_bool else \"\"\n",
    "    filename += \"_\" + MF.extract_str_from_cuts_dict(cuts_dict)\n",
    "    filename += f\"_{repeats}repeats\"\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        plt.savefig(save_path+filename+\".png\", bbox_inches=\"tight\")\n",
    "        print(\"Saved in\",save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "## d-specific plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "originally_within_Rmax = df_MC[\"R\"] <= 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # plot scatter inside/outside limit\n",
    "    \n",
    "    fig,ax=plt.subplots()\n",
    "    \n",
    "    colors = [\"grey\",\"red\",\"limegreen\"]\n",
    "    elements_dic = {\n",
    "        \"Stayed inside/outside\": [(originally_within_Rmax&within_cut)|(~originally_within_Rmax&~within_cut), 1, colors[0],1,\"grey\"],\n",
    "        \"Moved outside\": [originally_within_Rmax&~within_cut, 10, colors[1],0.5,\"k\"],\n",
    "        \"Moved inside\": [~originally_within_Rmax&within_cut, 10, colors[2],0.5,\"k\"]\n",
    "    }\n",
    "\n",
    "    y_var = \"vr\"; ylabel = r\"$v_r$\" + units_dict[\"mean_vx\"]\n",
    "#     y_var = \"d\"; ylabel = r\"$d~$[kpc]\"\n",
    "\n",
    "    for k in elements_dic:\n",
    "        condition,size,color,lw,edgecolor = elements_dic[k]\n",
    "\n",
    "        ax.scatter(x=df_MC[condition][\"R\"], y=df_MC[condition][y_var], color=color, s=size, label=f\"{k} ({sum(condition)})\",lw=lw,edgecolor=edgecolor)\n",
    "\n",
    "    ax.axvline(x=3.5,color=\"grey\",lw=1,linestyle=\"--\")\n",
    "    ax.text(x=3.5+0.1,y=0.85*ax.get_ylim()[1], s=r\"$R=3.5~$kpc\",color=\"grey\",size=15)\n",
    "\n",
    "    ax.set_xlabel(r\"$R$ [kpc]\"); ax.set_ylabel(ylabel)\n",
    "\n",
    "    leg = ax.legend()\n",
    "\n",
    "    for text,c in zip(leg.get_texts(),colors):\n",
    "        text.set_color(c)\n",
    "             \n",
    "if True: # filename and save\n",
    "    filename = f\"{y_var}-R\"\n",
    "    filename += f\"_{frac_error}fracErr\" if frac_error is not None else \"_dataErr\"\n",
    "    filename += \"_\" + MF.extract_str_from_cuts_dict(cuts_dict)\n",
    "\n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        plt.savefig(save_path+filename+\".png\", bbox_inches=\"tight\")\n",
    "        print(\"Saved in\",save_path)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 50 if data_bool else 100\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "MC_d = np.random.normal(loc=df_MC[\"d\"],scale=df_MC[\"d_error\"] if \"d_error\" in df_MC else frac_error*df_MC[\"d\"]) # this is an example - in the std calculation this is calculated {repeats} number of times\n",
    "\n",
    "ax.hist(MC_d,bins=bins,label=r\"MC $d$\")\n",
    "ax.hist(df_MC[\"d\"],bins=bins,color=\"red\",alpha=0.4,label=r\"Original $d$\")\n",
    "ax.hist(MC_d-df_MC[\"d\"],bins=bins,color=\"k\",histtype=\"step\",label=\"Difference\")\n",
    "ax.set_xlabel(r\"$d$ [kpc]\"); ax.set_ylabel(r\"$N$\",rotation=0,labelpad=20)\n",
    "ax.legend()\n",
    "\n",
    "if True:\n",
    "    filename = \"dHists\"\n",
    "    filename += f\"_{frac_error}fracErr\" if frac_error is not None else \"_dataErr\"\n",
    "    filename += \"_\" + MF.extract_str_from_cuts_dict(cuts_dict)\n",
    "    filename += f\"_{bins}bins\"\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        plt.savefig(save_path+filename+\".png\", bbox_inches=\"tight\")\n",
    "        print(\"Saved in\",save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "# Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_multiple_sampling_sizes(df, function, sampling_sizes, config, vectorised=False, batch_size=None, tilt=False, absolute=True, verbose=True):\n",
    "    \n",
    "    confidence_intervals = np.full(shape=(len(sampling_sizes),2), fill_value=np.nan)\n",
    "    bootstrap_distributions = np.full(shape=(len(sampling_sizes),config.repeats), fill_value=np.nan)\n",
    "    standard_errors = np.full(shape=len(sampling_sizes), fill_value=np.nan)\n",
    "    biases = np.full(shape=len(sampling_sizes), fill_value=np.nan)\n",
    "    \n",
    "    for s,size in enumerate(sampling_sizes):\n",
    "        config.sample_size = size\n",
    "        res = bootstrap.get_std_bootstrap(function=function,vx=df.vr.values,vy=df.vl.values,tilt=tilt,absolute=absolute,\\\n",
    "                                          config=config,vectorised=vectorised,batch_size=batch_size)\n",
    "        \n",
    "        confidence_intervals[s] = res.confidence_interval\n",
    "        bootstrap_distributions[s] = res.bootstrap_distribution\n",
    "        standard_errors[s] = res.standard_error\n",
    "        biases[s] = res.bias\n",
    "        \n",
    "        if verbose:\n",
    "            print(size,end=\"; \")\n",
    "    if verbose:\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    for v, var in enumerate([confidence_intervals, bootstrap_distributions, standard_errors, biases]):\n",
    "        assert not np.any(np.isnan(var)), f\"Array {v} was not filled correctly\"\n",
    "        \n",
    "    Result = namedtuple(\"Result\", [\"confidence_intervals\", \"bootstrap_distributions\", \"standard_errors\", \"biases\"])\n",
    "    \n",
    "    return Result(confidence_intervals=confidence_intervals, bootstrap_distributions=bootstrap_distributions,\\\n",
    "                  standard_errors=standard_errors, biases=biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_multiple_sampling_sizes_recursive(df, function, sampling_sizes, config, nested_config=None, vectorised=False, batch_size=None, tilt=False, absolute=True, verbose=True):\n",
    "    \n",
    "    confidence_intervals = np.full(shape=(len(sampling_sizes),2), fill_value=np.nan)\n",
    "    standard_errors = np.full(shape=len(sampling_sizes), fill_value=np.nan)\n",
    "    biases = np.full(shape=len(sampling_sizes), fill_value=np.nan)\n",
    "    \n",
    "    nested_confidence_intervals = np.full(shape=(len(sampling_sizes), config.repeats, 2), fill_value=np.nan)\n",
    "    nested_standard_errors = np.full(shape=(len(sampling_sizes),config.repeats), fill_value=np.nan)\n",
    "    nested_biases = np.full(shape=(len(sampling_sizes), config.repeats), fill_value=np.nan)\n",
    "    \n",
    "    for s,size in enumerate(sampling_sizes):\n",
    "        config.sample_size = size\n",
    "        \n",
    "        res = bootstrap.get_std_bootstrap_recursive(function=function,vx=df.vr.values,vy=df.vl.values,tilt=tilt,absolute=absolute,\\\n",
    "                                          config=config, nested_config=nested_config, boot_vectorised=vectorised, boot_batch_size=batch_size)\n",
    "        \n",
    "        confidence_intervals[s] = res.confidence_interval\n",
    "        standard_errors[s] = res.standard_error\n",
    "        biases[s] = res.bias\n",
    "        \n",
    "        nested_confidence_intervals[s] = res.bootstrap_confidence_intervals\n",
    "        nested_standard_errors[s] = res.bootstrap_standard_errors\n",
    "        nested_biases[s] = res.bootstrap_biases\n",
    "        \n",
    "        if verbose:\n",
    "            print(size,end=\"; \")\n",
    "    if verbose:\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    for v, var in enumerate([confidence_intervals, standard_errors, biases, nested_confidence_intervals, nested_standard_errors, nested_biases]):\n",
    "        assert not np.any(np.isnan(var)), f\"Array {v} was not filled correctly\"\n",
    "        \n",
    "    Result = namedtuple(\"Result\", [\"confidence_intervals\", \"standard_errors\", \"biases\",\\\n",
    "                                   \"nested_confidence_intervals\",\"nested_standard_errors\",\"nested_biases\"])\n",
    "    \n",
    "    return Result(confidence_intervals=confidence_intervals, standard_errors=standard_errors,biases=biases,\\\n",
    "                  nested_confidence_intervals=nested_confidence_intervals,nested_standard_errors=nested_standard_errors,nested_biases=nested_biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "## Method comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = general_path + \"/graphs/other_plots/Bootstrapping/comparison_scipy/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuts_dict = {\"R\":[0,2],\"b\":[3,3.01],\"l\":[-2,2],\"age\":[4,7]}\n",
    "cuts_dict = {\"R\":[0,2],\"b\":[3,3.01],\"l\":[-2,2],\"age\":[9.5,10]}\n",
    "\n",
    "df = MF.apply_cuts_to_df(df0, cuts_dict=cuts_dict)\n",
    "\n",
    "vx = df.vr.values\n",
    "vy = df.vl.values\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "function_dict = all_funcs_dict\n",
    "repeats = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_error_methods(df, func_name, function, repeats, ax, hist_range=None, common_labels_on=False, tilt=False,absolute=True,R_hat=None):\n",
    "    n = len(df)\n",
    "    vx = df.vr.values\n",
    "    vy = df.vl.values\n",
    "    \n",
    "    true_value = error_helpers.apply_function(vx=vx,vy=vy,function=function,tilt=tilt,absolute=absolute,R_hat=R_hat)\n",
    "    \n",
    "    our_res = bootstrap.get_std_bootstrap(vx=vx,vy=vy,function=function,config=BootstrapConfig(repeats=repeats,symmetric=False),tilt=tilt,absolute=absolute,R_hat=R_hat)\n",
    "    scipy_res = bootstrap.scipy_bootstrap(vx=vx,vy=vy,function=function,config=BootstrapConfig(repeats=repeats),tilt=tilt,absolute=absolute,R_hat=R_hat)\n",
    "    \n",
    "    # plot\n",
    "    our_distribution, our_CI, our_se = our_res.bootstrap_distribution, our_res.confidence_interval, our_res.standard_error\n",
    "    scipy_distribution, scipy_CI, scipy_se = scipy_res.bootstrap_distribution, scipy_res.confidence_interval, scipy_res.standard_error\n",
    "    \n",
    "    bootstrap_mean = np.mean(our_distribution)\n",
    "        \n",
    "    ax.hist(our_distribution,bins=75,label=\"Ours\" if common_labels_on else None, alpha=0.5,color=\"blue\",range=hist_range)\n",
    "    ax.hist(scipy_distribution,bins=75,color=\"orange\",label=\"SciPy\" if common_labels_on else None, alpha=0.5,range=hist_range)\n",
    "\n",
    "    ax.axvline(x=true_value,alpha=0.5,color=\"green\",label=\"True value\" if common_labels_on else None)\n",
    "    ax.axvline(x=np.mean(our_distribution),alpha=0.5,color=\"cyan\",label=\"Bootstrap mean\" if common_labels_on else None)\n",
    "    ax.axvline(x=np.median(our_distribution),alpha=0.5,color=\"red\",label=\"Bootstrap median\" if common_labels_on else None)\n",
    "    ax.axvline(x=np.mean(scipy_CI),alpha=0.5,color=\"orange\",linestyle=\"--\",label=\"Scipy CI centre\" if common_labels_on else None)\n",
    "    \n",
    "    ax.axvline(x=scipy_CI[0],color=\"orange\",label=\"SciPy CI\" if common_labels_on else None)\n",
    "    ax.axvline(x=scipy_CI[1],color=\"orange\")\n",
    "\n",
    "    ax.axvline(x=true_value-our_CI[0],color=\"blue\",linestyle=\"-\", label=\"Our CI\" if common_labels_on else None)\n",
    "    ax.axvline(x=true_value+our_CI[1],color=\"blue\",linestyle=\"-\")\n",
    "    \n",
    "    ax.axvline(x=np.percentile(our_distribution,16),color=\"k\",linestyle=\"dotted\", label=\"Percentile CI\" if common_labels_on else None)\n",
    "    ax.axvline(x=np.percentile(our_distribution,84),color=\"k\",linestyle=\"dotted\")\n",
    "    \n",
    "    ax.axvline(x=bootstrap_mean-our_se,color=\"magenta\",linestyle=\"--\", label=\"Standard error\" if common_labels_on else None)\n",
    "    ax.axvline(x=bootstrap_mean+our_se,color=\"magenta\",linestyle=\"--\")\n",
    "    \n",
    "    our_symmetric_CI = error_helpers.build_confidence_interval(values=our_distribution,central_value=true_value,symmetric=True)\n",
    "    \n",
    "    ax.axvline(x=true_value-our_symmetric_CI[0],color=\"pink\",linestyle=\"--\", label=\"Our symmetric CI\" if common_labels_on else None)\n",
    "    ax.axvline(x=true_value+our_symmetric_CI[1],color=\"pink\",linestyle=\"--\")\n",
    "    \n",
    "    if func_name == \"tilt_abs\": # Roca-Fabrega\n",
    "        \n",
    "        roca_fabrega_error = MF.get_error_vertex_deviation_roca_fabrega(n=len(df),vx=vx,vy=vy)\n",
    "        \n",
    "        ax.axvline(x=true_value-roca_fabrega_error,color=\"grey\",linestyle=\"dotted\", label=\"Roca-Fabrega 2014\")\n",
    "        ax.axvline(x=true_value+roca_fabrega_error,color=\"grey\",linestyle=\"dotted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(figsize=(10,20),nrows=3)\n",
    "\n",
    "legend_rows = [0,1,2]\n",
    "\n",
    "hist_ranges = [None, None, [-45,10]]\n",
    "for i,(func_name,func) in enumerate(function_dict.items()):\n",
    "    compare_error_methods(df=df, func_name=func_name, function=func, repeats=repeats, ax=axs[i], hist_range=hist_ranges[i], common_labels_on=i in legend_rows)\n",
    "    axs[i].set_xlabel(titles_dict[func_name])\n",
    "    axs[i].set_ylabel(r\"N\")\n",
    "    \n",
    "    if i in legend_rows or i == len(function_dict):\n",
    "        axs[i].legend()\n",
    "    \n",
    "if True: # filename, save, show\n",
    "    filename = \"hist\"\n",
    "    \n",
    "    if list(function_dict.keys()) == [\"anisotropy\",\"correlation\",\"tilt_abs\"]:\n",
    "        filename += \"_anicorr\"\n",
    "    else:\n",
    "        raise ValueError(\"Please specify map list name\")\n",
    "    \n",
    "    filename += \"_\"+MF.combine_multiple_cut_dicts_into_str(all_cuts=cuts_dict,cut_separator=\"_\",order_separator=\"_\")\n",
    "    filename += \"_%srepeats\"%str(repeats)\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        plt.savefig(save_path + filename + \".png\", dpi=250, bbox_inches=\"tight\")\n",
    "        print(\"Saved in\",save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "### Normal vs vectorised (ours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "Single sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "vx = np.random.normal(size=(50000))\n",
    "# vy = np.random.normal(size=(50000),scale=100) + np.random.normal(size=(50000),scale=1)\n",
    "vy = np.random.normal(size=(50000),scale=3)\n",
    "# sample_size = len(vx)\n",
    "sample_size = 5000\n",
    "repeats = 5000\n",
    "\n",
    "batch_size = None\n",
    "\n",
    "func = CV.calculate_tilt\n",
    "tilt = True; absolute = True\n",
    "\n",
    "# func = CV.calculate_correlation\n",
    "# tilt = False\n",
    "\n",
    "#####\n",
    "\n",
    "begin_time = time.time()\n",
    "\n",
    "res_vectorised = bootstrap.get_std_bootstrap(vx=vx,vy=vy,function=func,tilt=tilt,absolute=absolute,vectorised=True,batch_size=batch_size,\\\n",
    "                               config=BootstrapConfig(sample_size=sample_size,repeats=repeats))\n",
    "\n",
    "vector_time = time.time()\n",
    "\n",
    "res = bootstrap.get_std_bootstrap(vx=vx,vy=vy,function=func,tilt=tilt,absolute=absolute,\\\n",
    "                                       config=BootstrapConfig(sample_size=sample_size,repeats=repeats))\n",
    "\n",
    "normal_time = time.time()\n",
    "\n",
    "print(\"Vectorised time:\",vector_time - begin_time)\n",
    "print(\"Normal time:\",normal_time - vector_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "Multiple sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sample_size = 5000\n",
    "repeats = 5000\n",
    "batch_size = None\n",
    "timeit_repeats = 15\n",
    "\n",
    "vectorised_times = []\n",
    "normal_times = []\n",
    "\n",
    "all_sample_sizes = np.int64(np.round(10**np.linspace(np.log10(50),np.log10(max_sample_size),10))); logSampling=True\n",
    "\n",
    "for sample_size in all_sample_sizes:\n",
    "    print(sample_size, end=\"; \")\n",
    "\n",
    "    def bootstrap_vectorized():\n",
    "        return bootstrap.get_std_bootstrap(vx=vx,vy=vy,function=func,tilt=tilt,absolute=absolute,vectorised=True,batch_size=batch_size,\\\n",
    "                                       config=BootstrapConfig(sample_size=sample_size,repeats=repeats))\n",
    "\n",
    "    def bootstrap_normal():\n",
    "        return bootstrap.get_std_bootstrap(vx=vx,vy=vy,function=func,tilt=tilt,absolute=absolute,\\\n",
    "                                       config=BootstrapConfig(sample_size=sample_size,repeats=repeats))\n",
    "\n",
    "    vectorised_times.append(timeit.timeit(bootstrap_vectorized, number=timeit_repeats))\n",
    "    normal_times.append(timeit.timeit(bootstrap_normal, number=timeit_repeats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/luismi/Desktop/MRes_UCLan/graphs/other_plots/bootstrapping/vectorisation_timeit/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.plot(all_sample_sizes, np.array(vectorised_times)/timeit_repeats, color=\"green\",label=\"Vectorised\")\n",
    "ax.plot(all_sample_sizes, np.array(normal_times)/timeit_repeats, color=\"blue\",label=\"Normal\")\n",
    "\n",
    "ax.set_ylabel(\"Time per run [s]\")\n",
    "ax.set_xlabel(\"Sample size\")\n",
    "ax.legend()\n",
    "\n",
    "if True: # filename and save\n",
    "    filename = \"timevsN\"\n",
    "    \n",
    "    filename += f\"_{min(all_sample_sizes)}size{max(all_sample_sizes)}\"\n",
    "    filename += f\"_{len(all_sample_sizes)}steps\" + (\"Log\" if logSampling else \"\")\n",
    "    filename += f\"_{repeats}repeats\"\n",
    "    filename += f\"_{timeit_repeats}times\"\n",
    "    filename += f\"_batchsize{batch_size}\"\n",
    "    \n",
    "    print(filename)\n",
    "\n",
    "    if save_bool:\n",
    "        plt.savefig(save_path+filename+\".png\",dpi=200,bbox_inches=\"tight\")\n",
    "        \n",
    "        print(\"Saved in save_path\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlog = True\n",
    "xlog = False\n",
    "\n",
    "ylog = True\n",
    "# ylog = False\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.plot(all_sample_sizes, np.array(normal_times)/np.array(vectorised_times), color=\"green\",label=\"Vectorised\")\n",
    "\n",
    "ax.set_ylabel(r\"$t_\\mathrm{normal} / t_\\mathrm{vectorised}$\")\n",
    "ax.set_xlabel(\"Sample size\")\n",
    "\n",
    "if xlog:\n",
    "    ax.set_xscale(\"log\")\n",
    "if ylog:\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "\n",
    "ax.set_ylim(bottom=1)\n",
    "ax.grid(which=\"both\")\n",
    "\n",
    "if xlog:\n",
    "    ax.set_xlim(45,5600)\n",
    "\n",
    "if True: # filename and save\n",
    "    filename = \"ratio\"\n",
    "    \n",
    "    filename += f\"_{min(all_sample_sizes)}size{max(all_sample_sizes)}\"\n",
    "    filename += f\"_{len(all_sample_sizes)}steps\" + (\"Log\" if logSampling else \"\")\n",
    "    filename += f\"_{repeats}repeats\"\n",
    "    filename += f\"_{timeit_repeats}times\"\n",
    "    filename += f\"_batchsize{batch_size}\"\n",
    "    \n",
    "    if xlog and ylog:\n",
    "        filename += f\"_logscale\"\n",
    "    elif xlog:\n",
    "        filename += f\"_xlogscale\"\n",
    "    elif ylog:\n",
    "        filename += f\"_ylogscale\"\n",
    "    \n",
    "    print(filename)\n",
    "\n",
    "    if save_bool:\n",
    "        plt.savefig(save_path+filename+\".png\",dpi=200,bbox_inches=\"tight\")\n",
    "        \n",
    "        print(\"Saved in save_path\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "## Sampling distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = general_path + \"/graphs/other_plots/Bootstrapping/sampling_distributions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = 5000\n",
    "\n",
    "all_cuts_list = [\n",
    "    {\"R\":[0,2],\"b\":[3,6],\"l\":[-2,2],\"age\":[4,7]},\n",
    "    {\"R\":[0,2],\"b\":[3,6],\"l\":[-2,2],\"age\":[9.5,10]}\n",
    "]\n",
    "\n",
    "all_sizes = [\n",
    "    [50,65,80,100,250,500,1000,5000,len(MF.apply_cuts_to_df(df0, cuts_dict=all_cuts_list[0]))],\n",
    "    [50,65,80,100,250,500,1000,5000,len(MF.apply_cuts_to_df(df0, cuts_dict=all_cuts_list[1]))]\n",
    "]\n",
    "\n",
    "n_sizes = len(all_sizes[0])\n",
    "\n",
    "function_dict = all_funcs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_estimate_symbols_dict = {\n",
    "    \"tilt_abs\": r\"$\\overline{l^*_\\mathrm{v}}$\",\n",
    "    \"anisotropy\": r\"$\\overline{\\beta_{rl}^*}$\",\n",
    "    \"correlation\": r\"$\\overline{\\rho_{rl}^*}$\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_N = np.zeros(shape=len(all_cuts_list))\n",
    "true_values = np.zeros(shape=(len(all_cuts_list), len(function_dict)))\n",
    "all_values = np.zeros(shape=(len(all_cuts_list), len(function_dict), n_sizes, repeats))\n",
    "\n",
    "for c,(cuts,sizes) in enumerate(zip(all_cuts_list,all_sizes)):\n",
    "    print(cuts,end=\"\\n\")\n",
    "\n",
    "    df = MF.apply_cuts_to_df(df0, cuts_dict=cuts)\n",
    "    \n",
    "    total_N[c] = len(df)\n",
    "    \n",
    "    for f,func_name in enumerate(function_dict):\n",
    "        print(func_name,end=\"\\n\")\n",
    "        \n",
    "        true_values[c,f] = all_funcs_dict[func_name](df.vr.values,df.vl.values)\n",
    "        \n",
    "        _,all_values[c,f],_,_ = bootstrap_multiple_sampling_sizes(df=df,function=all_funcs_dict[func_name],repeats=repeats,sampling_sizes=sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "bins = 50\n",
    "\n",
    "cmap = mplcmaps['jet']\n",
    "\n",
    "fig,axs=plt.subplots(figsize=(15,15),nrows=3,ncols=2,gridspec_kw={\"hspace\":0.25})\n",
    "\n",
    "for row,func_name in enumerate(function_dict):\n",
    "    \n",
    "    for col,sizes in enumerate(all_sizes):\n",
    "        \n",
    "        max_size = total_N[col]\n",
    "        true_val = true_values[col, row]\n",
    "        ax = axs[row,col]\n",
    "        \n",
    "        if row == 0:\n",
    "            ax.set_title([\"Young\",\"Old\"][col],fontsize=\"large\")\n",
    "        \n",
    "        for s,size in enumerate(sizes):\n",
    "        \n",
    "            color = cmap(int(256*s/(len(sizes)-1)))\n",
    "\n",
    "            vals = all_values[col,row,s]\n",
    "\n",
    "            if size != max_size:\n",
    "                val_label = r\"$N=%i,$%s$=%.3f$%s$)$\"%(size, bootstrap_estimate_symbols_dict[func_name],np.mean(vals), mapf.get_units(func_name)) if true_val%10 == 0 else\\\n",
    "                            r\"$N=%i,$%s$=%.2f$%s$)$\"%(size, bootstrap_estimate_symbols_dict[func_name],np.mean(vals), mapf.get_units(func_name))\n",
    "            else:\n",
    "                val_label = r\"Total $(N=%i)$\"%max_size\n",
    "\n",
    "            ax.hist(vals,bins=bins,alpha=alpha,label=val_label,color=color)\n",
    "\n",
    "        if True: # axvline, labels, legend\n",
    "            true_val_label = r\"True value $($%s$=%.3f$%s$)$\"%(symbol_dict[func_name],true_val, mapf.get_units(func_name)) if true_val%10 == 0 else\\\n",
    "                             r\"True value $($%s$=%.2f$%s$)$\"%(symbol_dict[func_name],true_val, mapf.get_units(func_name))\n",
    "\n",
    "            ax.axvline(true_val,color=\"grey\",label=true_val_label,linestyle=\"--\")\n",
    "            ax.legend(fontsize=10.5)\n",
    "            ax.set_xlabel(mapf.get_kinematic_titles_dict(\"r\",\"l\")[func_name.removesuffix(\"_abs\")] + units_dict[func_name])\n",
    "            ax.set_ylabel(r\"$N$\")\n",
    "\n",
    "if True: # filename, save, show\n",
    "    filename = \"hists\"\n",
    "    \n",
    "    if list(function_dict.keys()) == [\"anisotropy\",\"correlation\",\"tilt_abs\"]:\n",
    "        filename += \"_anicorr\"\n",
    "    else:\n",
    "        raise ValueError(\"Please specify map list name\")\n",
    "    \n",
    "    filename += \"_\"+MF.combine_multiple_cut_dicts_into_str(all_cuts=all_cuts_list,cut_separator=\"_\",order_separator=\"_\")\n",
    "    filename += \"_%ssizes\"%len(sizes)\n",
    "    filename += \"_%srepeats\"%str(repeats)\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        plt.savefig(save_path+filename+\".png\",dpi=200,bbox_inches=\"tight\")\n",
    "        print(\"Saved in\",save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "## Bias vs N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = general_path + \"/graphs/other_plots/Bootstrapping/bias/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"xtick.major.size\"] = 7\n",
    "plt.rcParams[\"xtick.minor.size\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_sizes = np.int64(np.round(10**np.linspace(np.log10(50),np.log10(5000),100))); logSampling = True\n",
    "\n",
    "all_cuts_list = [\n",
    "    {\"R\":[0,2],\"b\":[3,6],\"l\":[-2,2],\"age\":[4,7]},\n",
    "    {\"R\":[0,2],\"b\":[3,6],\"l\":[-2,2],\"age\":[9.5,10]}\n",
    "]\n",
    "\n",
    "colors = [\"blue\",\"red\"]\n",
    "zorders = [0,1]\n",
    "\n",
    "function_dict = all_funcs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapconfig = BootstrapConfig(repeats=5000, symmetric=False, from_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values = np.zeros(shape=(len(all_cuts_list), len(function_dict)))\n",
    "bias_values = np.zeros(shape=(len(all_cuts_list), len(function_dict), len(sampling_sizes)))\n",
    "std_lowhigh_values = np.zeros(shape=(len(all_cuts_list), len(function_dict), len(sampling_sizes), 2))\n",
    "bootstrap_distributions = np.zeros(shape=(len(all_cuts_list), len(function_dict), len(sampling_sizes), bootstrapconfig.repeats))\n",
    "\n",
    "for c,cuts in enumerate(all_cuts_list):\n",
    "    print(cuts,end=\"\\n\")\n",
    "\n",
    "    df = MF.apply_cuts_to_df(df0, cuts_dict=cuts)\n",
    "    \n",
    "    for f,func_name in enumerate(function_dict):\n",
    "        print(func_name,end=\"\\n\")\n",
    "        \n",
    "        true_values[c,f] = all_funcs_dict[func_name](df.vr.values,df.vl.values)\n",
    "        \n",
    "        res = bootstrap_multiple_sampling_sizes(df=df,function=all_funcs_dict[func_name],sampling_sizes=sampling_sizes,config=bootstrapconfig)\n",
    "        \n",
    "        std_lowhigh_values[c,f] = res.confidence_intervals\n",
    "        bootstrap_distributions[c,f] = res.bootstrap_distributions\n",
    "        bias_values[c,f] = res.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_bool = True\n",
    "save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias vs N\n",
    "\n",
    "fig,axs = plt.subplots(figsize=(8,10),nrows=len(function_dict),gridspec_kw={\"hspace\":0})\n",
    "\n",
    "for f,(ax,func) in enumerate(zip(axs,function_dict)):\n",
    "    \n",
    "    for c in range(len(all_cuts_list)):\n",
    "        \n",
    "        ax.plot(sampling_sizes, np.mean(bootstrap_distributions[c,f],axis=-1) - true_values[c,f],\\\n",
    "                color=colors[c], zorder=zorders[c], label=[\"Young\",\"Old\"][c])\n",
    "    \n",
    "    ax.set_xlabel(\"Sample size\")\n",
    "    ax.set_ylabel(\"Bias %s\"%((r\"$[$\" + mapf.get_units(func) + r\"$]$\") if mapf.get_units(func) != \"\" else \"\"))\n",
    "    \n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlim(42,6000)\n",
    "    \n",
    "    if f==1:\n",
    "        ax.set_ylim(-0.01,0.01)\n",
    "\n",
    "    func_str = mapf.get_kinematic_titles_dict(\"r\",\"l\")[func.removesuffix(\"_abs\")]\n",
    "    ax.text(s=func_str,x=0.75,y=0.75,transform=ax.transAxes,size=15)\n",
    "    \n",
    "    ax.axhline(y=0,color=\"grey\",linestyle=\"--\")\n",
    "    \n",
    "    if f == 0:\n",
    "        ax.legend(loc=\"lower right\")\n",
    "    \n",
    "if True: # filename, save, show\n",
    "    \n",
    "    filename = \"biasVsN\"\n",
    "    filename += \"_\" + MF.combine_multiple_cut_dicts_into_str(all_cuts_list,cut_separator=\"_\",order_separator=\"_\")\n",
    "    \n",
    "    filename += f\"_{bootstrapconfig.repeats}repeats\"\n",
    "    filename += f\"_{min(sampling_sizes)}size{max(sampling_sizes)}\"\n",
    "    filename += f\"_{len(sampling_sizes)}steps\" + (\"Log\" if logSampling else \"\")\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        plt.savefig(save_path+filename+\".png\",dpi=200,bbox_inches=\"tight\")\n",
    "        print(\"Saved in\",save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true value and bootstrap mean as function of N\n",
    "\n",
    "# boot_std = True; surface_label = \"Bootstrap standard deviation\"\n",
    "boot_std = False\n",
    "\n",
    "boot_ci = True; ci_percentile = 68; surface_label = f\"Bootstrap {ci_percentile}% interval\"\n",
    "# boot_ci = False\n",
    "\n",
    "surface_alpha = 0.3\n",
    "\n",
    "fig,axs = plt.subplots(figsize=(8,10),nrows=len(function_dict),gridspec_kw={\"hspace\":0})\n",
    "\n",
    "for f,(ax,func) in enumerate(zip(axs,function_dict)):\n",
    "\n",
    "    for c in range(len(all_cuts_list)):\n",
    "        \n",
    "        ax.plot(sampling_sizes, len(sampling_sizes)*[true_values[c,f]], color=colors[c], zorder=zorders[c],linestyle=\"--\")\n",
    "        ax.plot(sampling_sizes, np.mean(bootstrap_distributions[c,f], axis=-1), color=colors[c], zorder=zorders[c])\n",
    "        \n",
    "        if boot_std:\n",
    "            ax.fill_between(x=sampling_sizes,\\\n",
    "                            y1=mean_values[c,f]-std_lowhigh_values[c,f,:,0],\\\n",
    "                            y2=mean_values[c,f]+std_lowhigh_values[c,f,:,1],color=colors[c],alpha=surface_alpha)\n",
    "        elif boot_ci:\n",
    "            q_low = (100-ci_percentile)/2\n",
    "            q_high = (100+ci_percentile)/2 # this is the same as 100-q_low\n",
    "\n",
    "            ax.fill_between(x=sampling_sizes, \\\n",
    "                             y1=np.percentile(bootstrap_distributions[c,f],axis=-1, q=q_low),\\\n",
    "                             y2=np.percentile(bootstrap_distributions[c,f],axis=-1, q=q_high),\\\n",
    "                             color=colors[c], alpha=surface_alpha)\n",
    "\n",
    "if True: # labels, lims, legend\n",
    "    \n",
    "    for ax,func in zip(axs,function_dict):\n",
    "        ax.set_ylabel(symbol_dict[func]+units_dict[func])\n",
    "        ax.set_xlim(42,6000)\n",
    "        ax.set_xscale(\"log\")\n",
    "    \n",
    "    axs[-1].set_xlabel(\"Sample size\")\n",
    "    \n",
    "    axs[-1].plot([-1,-1],[0,0],color=\"k\",linestyle=\"--\",label=\"True value\")\n",
    "    axs[-1].plot([-1,-1],[0,0],color=\"k\",linestyle=\"-\",label=\"Bootstrap mean\")\n",
    "    \n",
    "    if boot_std or boot_ci:\n",
    "        axs[-1].fill_between([-1,-1],[0,0],[0,0],color=\"k\",alpha=surface_alpha,label=surface_label)\n",
    "    \n",
    "    axs[-1].scatter([-1],[0],color=\"blue\",label=\"Young\")\n",
    "    axs[-1].scatter([-1],[0],color=\"red\",label=\"Old\")\n",
    "\n",
    "#     axs[0].legend()\n",
    "    axs[-1].legend(loc=\"upper right\",fontsize=14)\n",
    "    \n",
    "    fig.align_labels()\n",
    "\n",
    "if True: # filename, save, show\n",
    "    \n",
    "    filename = \"bias\"\n",
    "    filename += \"_\" + MF.combine_multiple_cut_dicts_into_str(all_cuts_list,cut_separator=\"_\",order_separator=\"_\")\n",
    "    \n",
    "    filename += \"_symmetricStd\" if bootstrapconfig.symmetric else \"\"\n",
    "    \n",
    "    filename += f\"_{bootstrapconfig.repeats}repeats\"\n",
    "    filename += f\"_{min(sampling_sizes)}size{max(sampling_sizes)}\"\n",
    "    filename += f\"_{len(sampling_sizes)}steps\" + (\"Log\" if logSampling else \"\")\n",
    "    \n",
    "    filename += \"_boot\"\n",
    "        \n",
    "    nested_bootstrap_strings = [\n",
    "        \"Std\" if boot_std else \"\",\n",
    "        f\"{ci_percentile}q\" if boot_ci else \"\"\n",
    "    ]\n",
    "\n",
    "    joint_boot_strings = str.join(\",\", nested_bootstrap_strings)\n",
    "    while \",,\" in joint_boot_strings:\n",
    "        joint_boot_strings = joint_boot_strings.replace(\",,\",\",\")\n",
    "\n",
    "    filename += joint_boot_strings.strip(\",\")\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        plt.savefig(save_path+filename+\".png\",dpi=200,bbox_inches=\"tight\")\n",
    "        print(\"Saved in\",save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109",
   "metadata": {},
   "source": [
    "## SE vs N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = general_path+\"graphs/other_plots/bootstrapping/assumption_test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_dict = {\n",
    "    \"anisotropy\": CV.calculate_anisotropy,\n",
    "    \"correlation\": CV.calculate_correlation,\n",
    "    \"tilt_abs\": CV.calculate_tilt\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sampling_arrays(save_path, base_filename, func_name, res, recursive=False, verbose=True):\n",
    "    np.save(save_path+base_filename+f\"_{func_name}_CIs\", res.confidence_intervals)        \n",
    "    np.save(save_path+base_filename+f\"_{func_name}_SEs\", res.standard_errors)        \n",
    "    np.save(save_path+base_filename+f\"_{func_name}_biases\", res.biases)\n",
    "    \n",
    "    if recursive:\n",
    "        np.save(save_path+base_filename+f\"_{func_name}_nestedCIs\", res.nested_confidence_intervals)            \n",
    "        np.save(save_path+base_filename+f\"_{func_name}_nestedSEs\", res.nested_standard_errors)            \n",
    "        np.save(save_path+base_filename+f\"_{func_name}_nestedbiases\", res.nested_biases)    \n",
    "    else:\n",
    "        np.save(save_path+base_filename+f\"_{func_name}_distributions\", res.bootstrap_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_repeats = 10000\n",
    "bootstrap_repeats = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bootstrap_errors = True\n",
    "# save_bootstrap_errors = False # only sampling errors will be saved, not nested bootstrap errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_sizes = np.int64(np.round(10**np.linspace(np.log10(50),np.log10(5000),100))); logSampling = True\n",
    "\n",
    "# sampling_sizes = np.arange(50,5000+50,50); logSampling = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_config = BootstrapConfig(repeats=sampling_repeats,symmetric=False,replace=True)\n",
    "bootstrap_config = BootstrapConfig(repeats=bootstrap_repeats,symmetric=False,replace=True)\n",
    "\n",
    "bootstrap_vectorised = True\n",
    "# bootstrap_vectorised = False\n",
    "\n",
    "batch_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dicts = [ # select for plotting\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,2],\"b\":[3.5,4.5],\"l\":[-2,2]},\n",
    "#         \"pop_cuts\": {\"age\": [4,7]},\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,2],\"b\":[3.5,4.5],\"l\":[-2,2]},\n",
    "#         \"pop_cuts\": {\"age\":[9.5,10]},\n",
    "\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,3.5],\"b\":[3.5,4.5],\"l\":[-2,2]},\n",
    "#         \"pop_cuts\": {\"age\": [4,7]},\n",
    "\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,3.5],\"b\":[3.5,4.5],\"l\":[-2,2]},\n",
    "#         \"pop_cuts\": {\"age\":[9.5,10]},\n",
    "\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,2],\"b\":[6,9],\"l\":[-2,2]},\n",
    "#         \"pop_cuts\": {\"age\": [4,7]},\n",
    "\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,2],\"b\":[6,9],\"l\":[-2,2]},\n",
    "#         \"pop_cuts\": {\"age\":[9.5,10]},\n",
    "\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,3.5],\"b\":[6,13],\"l\":[-2,2]},\n",
    "#         \"pop_cuts\": {\"age\": [4,7]},\n",
    "\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,3.5],\"b\":[6,13],\"l\":[-2,2]},\n",
    "#         \"pop_cuts\": {\"age\":[9.5,10]},\n",
    "\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,2],\"b\":[3,6],\"l\":[-2,2]},\n",
    "#         \"pop_cuts\": {\"age\": [4,7]},\n",
    "\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,2],\"b\":[3,6],\"l\":[-2,2]},\n",
    "#         \"pop_cuts\": {\"age\":[9.5,10]},\n",
    "\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,2],\"b\":[1.5,2],\"l\":[-2,2]},\n",
    "#         \"pop_cuts\": {\"age\": [4,7]},\n",
    "\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,2],\"b\":[1.5,2],\"l\":[-2,2]},\n",
    "#         \"pop_cuts\": {\"age\":[9.5,10]},\n",
    "\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,2],\"b\":[3,6],\"l\":[3,6]},\n",
    "#         \"pop_cuts\": {\"age\": [4,7]},\n",
    "\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,2],\"b\":[3,6],\"l\":[3,6]},\n",
    "#         \"pop_cuts\": {\"age\":[9.5,10]},\n",
    "\n",
    "#     },\n",
    "    {\n",
    "        \"spatial_cuts\": {\"R\":[0,3.5],\"b\":[3,6],\"l\":[-2,2]},\n",
    "        \"pop_cuts\": {\"age\": [4,7]}\n",
    "    },\n",
    "    {\n",
    "        \"spatial_cuts\": {\"R\":[0,3.5],\"b\":[3,6],\"l\":[-2,2]},\n",
    "        \"pop_cuts\": {\"age\":[9.5,10]},\n",
    "\n",
    "    },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,2],\"b\":[3,6],\"l\":[-2,2]},\n",
    "#         \"pop_cuts\": {\"age\": [4,7]},\n",
    "\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,2],\"b\":[3,6],\"l\":[-2,2]},\n",
    "#         \"pop_cuts\": {\"age\":[9.5,10]},\n",
    "\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,3.5],\"b\":[3,6],\"l\":[3,6]},\n",
    "#         \"pop_cuts\": {\"age\": [4,7]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,3.5],\"b\":[3,6],\"l\":[3,6]},\n",
    "#         \"pop_cuts\": {\"age\":[9.5,10]},\n",
    "\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,3.5],\"b\":[1.5,2],\"l\":[-2,2]},\n",
    "#         \"pop_cuts\": {\"age\": [4,7]}\n",
    "#     },\n",
    "#     {\n",
    "#         \"spatial_cuts\": {\"R\":[0,3.5],\"b\":[1.5,2],\"l\":[-2,2]},\n",
    "#         \"pop_cuts\": {\"age\" :[9.5,10]},\n",
    "\n",
    "#     }\n",
    "];\n",
    "\n",
    "\n",
    "for dic in all_dicts: # check there are enough stars if sampling without replacement \n",
    "    star_number = len(MF.apply_cuts_to_df(df0, cuts_dict=[dic[\"spatial_cuts\"],dic[\"pop_cuts\"]]))\n",
    "    if not (sampling_config.replace or max(sampling_sizes) > 0.05*star_number):\n",
    "        warnings.warn(f\"Sampling without replacement but the max sampling size is larger than 5%% of the\\\n",
    "        population for the cuts %s and %s\"%(dic[\"spatial_cuts\"],dic[\"pop_cuts\"]))\n",
    "\n",
    "for dic in all_dicts:\n",
    "    df = MF.apply_cuts_to_df(df0, cuts_dict=[dic[\"spatial_cuts\"],dic[\"pop_cuts\"]])\n",
    "    \n",
    "    if True: # save_path and general filename\n",
    "        save_path = get_save_path_spatial_cuts(base_path=base_path,spatial_cuts=dic[\"spatial_cuts\"])\n",
    "        \n",
    "        save_path += \"arrays/\"\n",
    "        MF.create_dir(save_path)\n",
    "        \n",
    "        save_path += f\"sampling{sampling_repeats}repeats/\"\n",
    "        MF.create_dir(save_path)\n",
    "        \n",
    "        save_path += f\"bootstrap{bootstrap_repeats}repeats/\"\n",
    "        MF.create_dir(save_path)\n",
    "        \n",
    "        save_path += MF.extract_str_from_cuts_dict(dic[\"pop_cuts\"]) + \"/\"\n",
    "        MF.create_dir(save_path)\n",
    "        \n",
    "        base_filename = f\"{min(sampling_sizes)}size{max(sampling_sizes)}\"\n",
    "        base_filename += f\"_{len(sampling_sizes)}steps\" + (\"Log\" if logSampling else \"\")\n",
    "\n",
    "        print(\"General filename:\",base_filename)\n",
    "        print(\"Saving in\",save_path,\"\\n\")\n",
    "    \n",
    "    for func in function_dict:\n",
    "        print(func)\n",
    "        \n",
    "        if save_bootstrap_errors:\n",
    "            res = bootstrap_multiple_sampling_sizes_recursive(df=df,function=function_dict[func],sampling_sizes=sampling_sizes,\\\n",
    "                                                              vectorised=bootstrap_vectorised, batch_size=batch_size,\\\n",
    "                                                              config=sampling_config, nested_config=bootstrap_config)\n",
    "        else:\n",
    "            res = bootstrap_multiple_sampling_sizes(df=df,function=function_dict[func],sampling_sizes=sampling_sizes,\\\n",
    "                                                    config=sampling_config, vectorised=bootstrap_vectorised, batch_size=batch_size)\n",
    "        \n",
    "        save_sampling_arrays(save_path=save_path, func_name=func,base_filename=base_filename, res=res, recursive=save_bootstrap_errors)\n",
    "        \n",
    "        print(\"Arrays saved successfully.\\n\")\n",
    "    \n",
    "    print(\"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 19\n",
    "plt.rcParams[\"legend.fontsize\"] = 15\n",
    "\n",
    "plt.rcParams[\"xtick.major.size\"] = 7\n",
    "plt.rcParams[\"xtick.minor.size\"] = 3\n",
    "plt.rcParams[\"ytick.major.size\"] = 7\n",
    "plt.rcParams[\"ytick.minor.size\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "class Func():\n",
    "    def fit(self,x,y):\n",
    "        self.fit_params,_ = curve_fit(f=self.func, p0=self.p0, xdata=x,ydata=y)\n",
    "        \n",
    "class ReciprocalFunc(Func):\n",
    "    def __init__(self, p0=[39.65,100,0.02]):\n",
    "        self.func = lambda x,a,b,c: a/(x+b)+c\n",
    "        self.name = \"reciprocal\"\n",
    "        self.label = r\"$f(n)=\\frac{a}{n+b}+c$\"\n",
    "        self.p0 = p0\n",
    "\n",
    "class InverseSquareFunc(Func):\n",
    "    def __init__(self, p0=[10]):\n",
    "        self.func = lambda x,a: a/(np.sqrt(x))\n",
    "        self.name = \"inverse_square\"\n",
    "#         self.label = r\"$f(n)=\\frac{a}{\\sqrt{n}}$\"\n",
    "        self.label = r\"$f(n)\\propto\\frac{1}{\\sqrt{n}}$\"\n",
    "        self.p0 = p0\n",
    "        \n",
    "def show_fit_params_text(ax, Func, x_eq=0.6,y_eq=0.42, color=\"grey\", ndec_text=2, alpha=1, size=13, units=\"\"):\n",
    "    \n",
    "    if not hasattr(Func,\"fit_params\"):\n",
    "        raise AttributeError(\"Fit the function first!\")\n",
    "    \n",
    "    abc_str = str.join(\",\",[\"abcdefg\"[i] for i in range(len(Func.p0))])\n",
    "    values_str = (len(Func.p0)*\"%s,\").removesuffix(\",\")\n",
    "    final_str = (r\"$(\" if len(Func.p0)>1 else r\"$\") + abc_str + (\")=(\" if len(Func.p0)>1 else \"=\") + values_str + (\")$\" if len(Func.p0)>1 else \"$\")\n",
    "    final_str += units\n",
    "\n",
    "    ax.text(x=x_eq,y=y_eq,transform=ax.transAxes,color=color,alpha=alpha,size=size,\n",
    "             s=final_str%tuple([MF.return_int_or_dec(param,ndec_text) for param in Func.fit_params]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122",
   "metadata": {},
   "source": [
    "#### In bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_vs_N(all_dicts, xlog_bool, ylog_bool, save_bool=True, show_bool=False, fit_bool=True, same_youngold_fits=True, logSampling=True):\n",
    "    max_sampling_size = max(sampling_sizes)\n",
    "    xtick_step = 500\n",
    "    major_locator = 1000\n",
    "    minor_locator = 250\n",
    "    \n",
    "    # fit_func = ReciprocalFunc(p0=[1,10,10])\n",
    "    fit_func = InverseSquareFunc(p0=[1])\n",
    "\n",
    "    if xlog_bool and ylog_bool:\n",
    "        x_eq,y_eq = 0.75, 0.15\n",
    "    elif xlog_bool:\n",
    "        x_eq,y_eq = 0.65,0.4\n",
    "    else:\n",
    "        x_eq,y_eq = 0.4, 0.4\n",
    "        \n",
    "    hard_coded_ylims_dict = {\n",
    "        \"anisotropy\": [0 if not ylog_bool else 0.001,0.3],\n",
    "        \"correlation\": [0 if not ylog_bool else 0.001,0.149],\n",
    "        \"tilt_abs\": [0 if not ylog_bool else 0.1,33]\n",
    "    }\n",
    "\n",
    "    if xlog_bool and ylog_bool:\n",
    "        for k in hard_coded_ylims_dict:\n",
    "            hard_coded_ylims_dict[k][1] *= 1.5\n",
    "            \n",
    "    MC_error_bool = xlog_bool and ylog_bool\n",
    "    \n",
    "    width_broken_axes = 0.13\n",
    "    nrows = len(function_dict)\n",
    "\n",
    "    fig,axs = plt.subplots(figsize=(8,10),ncols=3,nrows=nrows,gridspec_kw={\"width_ratios\":[1]+2*[width_broken_axes],\"wspace\":0.1,\"hspace\":0})\n",
    "\n",
    "    for row,func in enumerate(function_dict):\n",
    "        lax,cax,rax = axs[row]\n",
    "\n",
    "        if True: # broken axes\n",
    "\n",
    "            d = 0.02\n",
    "            d_factor = 1/width_broken_axes\n",
    "\n",
    "            for ax in [lax,cax]:\n",
    "                ax.spines['right'].set_visible(False)\n",
    "                ax.tick_params(which='both',right=False)\n",
    "\n",
    "            lax.plot((1-d,1+d), (-d,d), transform=lax.transAxes, color='k', clip_on=False,lw=\"1\")\n",
    "            lax.plot((1-d,1+d),(1-d,1+d), transform=lax.transAxes, color='k', clip_on=False,lw=\"1\")\n",
    "\n",
    "            cax.plot((1-d_factor*d,1+d_factor*d), (-d,d), transform=cax.transAxes, color='k', clip_on=False,lw=\"1\")\n",
    "            cax.plot((1-d_factor*d,1+d_factor*d), (1-d,1+d), transform=cax.transAxes, color='k', clip_on=False,lw=\"1\")\n",
    "\n",
    "            for ax in [cax,rax]:\n",
    "                ax.spines['left'].set_visible(False)\n",
    "                ax.tick_params(which='both',left=False)\n",
    "\n",
    "                ax.plot((-d_factor*d,+d_factor*d), (1-d,1+d), transform=ax.transAxes, color='k', clip_on=False,lw=\"1\")\n",
    "                ax.plot((-d_factor*d,+d_factor*d), (-d,d), transform=ax.transAxes, color='k', clip_on=False,lw=\"1\")\n",
    "\n",
    "        if True: # plot\n",
    "            for dic in all_dicts:\n",
    "                lax.plot(sampling_sizes[sampling_sizes <= max_sampling_size],np.array(dic[func+\"_errors\"])[sampling_sizes <= max_sampling_size],\\\n",
    "                         label=dic[\"label\"],color=dic[\"color\"],alpha=0.7)\n",
    "\n",
    "            for dic,ax in zip(all_dicts,[cax,rax]):\n",
    "                ax.scatter(dic[\"total_N\"],dic[func+\"_bootstrap_error\"],marker=\"*\",color=dic[\"color\"])\n",
    "\n",
    "                if MC_error_bool:\n",
    "                    ax.scatter(dic[\"total_N\"],dic[func+\"_MC_d_0.2_error_low\"],marker=\"v\",color=dic[\"color\"],s=23)\n",
    "                    ax.scatter(dic[\"total_N\"],dic[func+\"_MC_d_0.2_error_high\"],marker=\"^\",color=dic[\"color\"],s=23)\n",
    "\n",
    "                ax.set_xticks([dic[\"total_N\"]])\n",
    "\n",
    "            lax.scatter(x=-100,y=0,marker=\"*\",color=\"k\",label=\"Bootstrap error\") # just for the legend label\n",
    "\n",
    "            if MC_error_bool:\n",
    "                lax.scatter(x=-100,y=0,marker=\"v\",color=\"k\",label=\"MC 20% distance error\",s=23) # just for the legend label\n",
    "\n",
    "        if True: # ticks, lims, logscale\n",
    "\n",
    "            if xlog_bool:\n",
    "                lax.set_xscale(\"log\")\n",
    "\n",
    "            lax_leftlim = 40 if xlog_bool else 0\n",
    "            lax.set_xlim(lax_leftlim,max_sampling_size+minor_locator*0.9)\n",
    "\n",
    "            if not xlog_bool:\n",
    "                lax.xaxis.set_major_locator(ticker.MultipleLocator(major_locator))\n",
    "                lax.xaxis.set_minor_locator(ticker.MultipleLocator(minor_locator))\n",
    "    #             lax.set_xticks([50]+list(np.arange(xtick_step,max_sampling_size+xtick_step,xtick_step)))\n",
    "\n",
    "            for ax in [lax,cax,rax]:\n",
    "                ax.tick_params(axis='x', which='major', pad=10)\n",
    "\n",
    "                if ylog_bool:\n",
    "                    ax.set_yscale(\"log\")\n",
    "\n",
    "                if ax in [cax,rax]:\n",
    "                    ax.yaxis.set_ticklabels([])\n",
    "\n",
    "                if func in hard_coded_ylims_dict:\n",
    "                    ax.set_ylim(hard_coded_ylims_dict[func])\n",
    "                else:\n",
    "                    ax.set_ylim(bottom=0.005 if ylog_bool else 0)\n",
    "\n",
    "                if row != nrows - 1:\n",
    "                    ax.xaxis.set_ticklabels([])\n",
    "                    ax.xaxis.set_ticklabels([])\n",
    "\n",
    "        if fit_bool:\n",
    "\n",
    "            x_plot = np.linspace(min(sampling_sizes),max_sampling_size,500)\n",
    "\n",
    "            if func != \"tilt_abs\" and same_youngold_fits:\n",
    "                fit_func.fit(x = sampling_sizes[sampling_sizes<=max_sampling_size], y = np.array(all_dicts[0][func+\"_errors\"])[sampling_sizes<=max_sampling_size])\n",
    "                lax.plot(x_plot, fit_func.func(x_plot, *fit_func.fit_params), color=\"grey\", linestyle=\"--\")\n",
    "                show_fit_params_text(ax=lax,Func=fit_func,color=\"grey\",x_eq=x_eq,y_eq=y_eq)\n",
    "            else:\n",
    "                for (pop_idx,color,y) in zip([0,1],[\"blue\",\"red\"],[y_eq-0.04,y_eq+0.04]):\n",
    "                    fit_func.fit(x = sampling_sizes[sampling_sizes<=max_sampling_size], y = np.array(all_dicts[pop_idx][func+\"_errors\"])[sampling_sizes<=max_sampling_size])\n",
    "\n",
    "                    lax.plot(x_plot, fit_func.func(x_plot, *fit_func.fit_params), color=color, linestyle=\"--\",alpha=0.5)\n",
    "                    show_fit_params_text(ax=lax,Func=fit_func,alpha=0.7,color=color,x_eq=x_eq,y_eq=y,units=mapf.get_units(func))\n",
    "\n",
    "            lax.plot([-100,-100],[0,1],label=fit_func.label,linestyle=\"--\",color=\"grey\") # just for the legend label\n",
    "\n",
    "        if True: # labels, legend, text\n",
    "            if row == nrows-1:\n",
    "    #             lax.set_xlabel(\"Sample size\"); lax.text(s=r\"Total $N$\",x=1.1,y=-0.25,transform=lax.transAxes,size=\"medium\")\n",
    "                lax.text(s=\"Sample size\",x=0.5,y=-0.25,transform=lax.transAxes,size=\"medium\")\n",
    "\n",
    "            if row == 0:\n",
    "                fig.legend(loc=(0.65,0.77) if not (xlog_bool and ylog_bool) else (0.16,0.7),framealpha=0 if xlog_bool and ylog_bool else 1)\n",
    "            elif row == 1:\n",
    "                lax.set_ylabel(r\"Standard error\")\n",
    "\n",
    "            if xlog_bool and ylog_bool:\n",
    "                x_func_text = 0.98\n",
    "            elif xlog_bool:\n",
    "                x_func_text = 0.3\n",
    "            else:\n",
    "                x_func_text = 0.2\n",
    "            fig.text(s=mapf.get_kinematic_titles_dict(\"r\",\"l\")[func.removesuffix(\"_abs\")],x=x_func_text,y=0.83,transform=lax.transAxes,size=15)\n",
    "\n",
    "            fig.align_labels()\n",
    "\n",
    "    if True: # filename, save and show\n",
    "        save_path = get_save_path_spatial_cuts(save_path=base_path, spatial_cuts_dict=all_dicts[0][\"spatial_cuts\"])\n",
    "\n",
    "        if list(function_dict.keys()) == [\"anisotropy\",\"correlation\",\"tilt_abs\"]:\n",
    "            filename = \"anicorr\"\n",
    "        else:\n",
    "            raise ValueError(\"Please specify map list name\")\n",
    "            \n",
    "        filename += \"_\"+MF.extract_str_from_cuts_dict(dic[\"spatial_cuts\"])\n",
    "\n",
    "        for dic in all_dicts:\n",
    "            filename += '_'+MF.extract_str_from_cuts_dict(dic[\"pop_cuts\"])\n",
    "\n",
    "        if xlog_bool and ylog_bool:\n",
    "            filename += \"_xylog\"\n",
    "        elif xlog_bool:\n",
    "            filename += \"_xlog\"\n",
    "        elif ylog_bool:\n",
    "            filename += \"_ylog\"\n",
    "\n",
    "        if MC_error_bool:\n",
    "            filename += \"_MC\"\n",
    "\n",
    "        filename += f\"_{repeats}repeats\"\n",
    "        filename += f\"_{min(sampling_sizes)}size{max(sampling_sizes)}\"\n",
    "        filename += f\"_{len(sampling_sizes)}steps\" + (\"Log\" if logSampling else \"\")\n",
    "\n",
    "        if not fit_bool:\n",
    "            filename += \"_noFit\"\n",
    "        elif not same_youngold_fits:\n",
    "            filename += \"_diffFits\"\n",
    "\n",
    "        print(filename)\n",
    "\n",
    "        if save_bool:\n",
    "            print(\"Saving in\",save_path)\n",
    "            plt.savefig(save_path+filename+\".png\",dpi=200,bbox_inches=\"tight\")\n",
    "\n",
    "        if show_bool:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "logSampling = True\n",
    "# logSampling = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not logSampling:\n",
    "    all_dicts_list = [\n",
    "        [\n",
    "            MF.load_dic_from_json(filename=base_path+\"3b6/0R3.5/-2l2/anicorr_4age7_5000maxsize_5000repeats\"),\n",
    "            MF.load_dic_from_json(filename=base_path+\"3b6/0R3.5/-2l2/anicorr_9.5age10_5000maxsize_5000repeats\"),\n",
    "        ],\n",
    "        [\n",
    "            MF.load_dic_from_json(filename=base_path+\"3b6/0R2/-2l2/anicorr_4age7_5000maxsize_5000repeats\"),\n",
    "            MF.load_dic_from_json(filename=base_path+\"3b6/0R2/-2l2/anicorr_9.5age10_5000maxsize_5000repeats\"),\n",
    "        ],\n",
    "    ]\n",
    "\n",
    "    sampling_sizes = np.arange(50,5000+50,50)\n",
    "\n",
    "    for all_dicts in all_dicts_list: # check pairwise consistency of spatial cuts\n",
    "        spatial_cuts = all_dicts[0][\"spatial_cuts\"]\n",
    "        for dic in all_dicts:\n",
    "            assert dic[\"spatial_cuts\"] == spatial_cuts, \"The spatial cuts were not the same across the dicts!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {},
   "outputs": [],
   "source": [
    "if logSampling:\n",
    "    all_dicts_list = [\n",
    "    #     [\n",
    "    #         MF.load_dic_from_json(filename=base_path+\"3.5b4.5/0R3.5/-2l2/anicorr_4age7_5000repeats_50size5000_100stepsLog.json\"),\n",
    "    #         MF.load_dic_from_json(filename=base_path+\"3.5b4.5/0R3.5/-2l2/anicorr_9.5age10_5000repeats_50size5000_100stepsLog.json\"),\n",
    "    #     ],\n",
    "    #     [\n",
    "    #         MF.load_dic_from_json(filename=base_path+\"3.5b4.5/0R2/-2l2/anicorr_4age7_5000repeats_50size5000_100stepsLog.json\"),\n",
    "    #         MF.load_dic_from_json(filename=base_path+\"3.5b4.5/0R2/-2l2/anicorr_9.5age10_5000repeats_50size5000_100stepsLog.json\"),\n",
    "    #     ],\n",
    "        [\n",
    "            MF.load_dic_from_json(filename=base_path+\"1.5b2/0R3.5/-2l2/anicorr_4age7_500repeats_50size5000_100stepsLog.json\"),\n",
    "            MF.load_dic_from_json(filename=base_path+\"1.5b2/0R3.5/-2l2/anicorr_9.5age10_500repeats_50size5000_100stepsLog.json\"),\n",
    "        ],\n",
    "        [\n",
    "            MF.load_dic_from_json(filename=base_path+\"1.5b2/0R2/-2l2/anicorr_4age7_500repeats_50size5000_100stepsLog.json\"),\n",
    "            MF.load_dic_from_json(filename=base_path+\"1.5b2/0R2/-2l2/anicorr_9.5age10_500repeats_50size5000_100stepsLog.json\"),\n",
    "        ],\n",
    "        [\n",
    "            MF.load_dic_from_json(filename=base_path+\"3b6/0R3.5/-2l2/anicorr_4age7_500repeats_50size5000_100stepsLog.json\"),\n",
    "            MF.load_dic_from_json(filename=base_path+\"3b6/0R3.5/-2l2/anicorr_9.5age10_500repeats_50size5000_100stepsLog.json\"),\n",
    "        ],\n",
    "        [\n",
    "            MF.load_dic_from_json(filename=base_path+\"3b6/0R2/-2l2/anicorr_4age7_500repeats_50size5000_100stepsLog.json\"),\n",
    "            MF.load_dic_from_json(filename=base_path+\"3b6/0R2/-2l2/anicorr_9.5age10_500repeats_50size5000_100stepsLog.json\"),\n",
    "        ],\n",
    "    ]\n",
    "\n",
    "    sampling_sizes = np.int64(np.round(10**np.linspace(np.log10(50),np.log10(5000),100)))\n",
    "\n",
    "    for all_dicts in all_dicts_list: # check pairwise consistency of spatial cuts\n",
    "        spatial_cuts = all_dicts[0][\"spatial_cuts\"]\n",
    "        for dic in all_dicts:\n",
    "            assert dic[\"spatial_cuts\"] == spatial_cuts, \"The spatial cuts were not the same across the dicts!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "for all_dicts in all_dicts_list:\n",
    "    if logSampling:\n",
    "        plot_error_vs_N(all_dicts, True, False, save_bool=True, show_bool=False, logSampling=True)\n",
    "        plot_error_vs_N(all_dicts, True, True, save_bool=True, show_bool=False, logSampling=True)\n",
    "        plot_error_vs_N(all_dicts, True, False, save_bool=True, show_bool=False, logSampling=True, same_youngold_fits=False)\n",
    "        plot_error_vs_N(all_dicts, True, True, save_bool=True, show_bool=False, logSampling=True, same_youngold_fits=False)\n",
    "    else:\n",
    "        plot_error_vs_N(all_dicts, False, False, save_bool=True, show_bool=False, logSampling=False)\n",
    "        plot_error_vs_N(all_dicts, True, False, save_bool=True, show_bool=False, logSampling=False)\n",
    "        plot_error_vs_N(all_dicts, True, True, save_bool=True, show_bool=False, logSampling=False)\n",
    "        plot_error_vs_N(all_dicts, False, False, save_bool=True, show_bool=False, logSampling=False,same_youngold_fits=False)\n",
    "        plot_error_vs_N(all_dicts, True, False, save_bool=True, show_bool=False, logSampling=False,same_youngold_fits=False)\n",
    "        plot_error_vs_N(all_dicts, True, True, save_bool=True, show_bool=False, logSampling=False,same_youngold_fits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128",
   "metadata": {},
   "source": [
    "#### Individually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129",
   "metadata": {},
   "source": [
    "Load from numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_all_dicts_with_arrays(all_dicts, base_path, function_dict, sample_sizes_str, array_name_dict, calculate_correlation=False, verbose=True):\n",
    "    if verbose and calculate_correlation:\n",
    "        print(\"Calculating correlation\")\n",
    "    \n",
    "    for dic in all_dicts:\n",
    "        spatial_path = get_save_path_spatial_cuts(base_path=base_path,spatial_cuts=dic[\"spatial_cuts\"])\n",
    "\n",
    "        for func in function_dict:\n",
    "\n",
    "            sampling_repeats_str = \"sampling\" + str(dic[\"sampling_repeats\"]) +\"repeats\"\n",
    "            bootstrap_repeats_str = \"bootstrap\" + str(dic[\"bootstrap_repeats\"]) +\"repeats\"\n",
    "            pop_str = MF.extract_str_from_cuts_dict(dic[\"pop_cuts\"])\n",
    "\n",
    "            load_path = f\"{spatial_path}arrays/{sampling_repeats_str}/{bootstrap_repeats_str}/{pop_str}/{sample_sizes_str}\"\n",
    "            \n",
    "            for array_name in array_name_dict:\n",
    "                dic[func + \"_\" + array_name_dict[array_name]] = np.load(load_path + f\"_{func}_\" + array_name + \".npy\")\n",
    "                dic[func + \"_bootstrap_\" + array_name_dict[array_name]] = np.load(load_path + f\"_{func}_nested\" + array_name + \".npy\")\n",
    "\n",
    "            if func == \"correlation\" and calculate_correlation:\n",
    "                df_cut = MF.apply_cuts_to_df(df=df0,cuts_dict=[dic[\"spatial_cuts\"],dic[\"pop_cuts\"]])\n",
    "                dic[\"correlation\"] = CV.calculate_correlation(vx=df_cut.vr.values,vy=df_cut.vl.values)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Arrays filled successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption test on standard error\n",
    "\n",
    "all_dicts = [\n",
    "    {\n",
    "        \"spatial_cuts\": {\"b\":[3,6],\"R\":[0,3.5],\"l\":[-2,2]},\n",
    "        \"pop_cuts\": {\"age\":[4,7]},\n",
    "        \"sampling_repeats\": 5000,\n",
    "        \"bootstrap_repeats\": 500\n",
    "    },\n",
    "    {\n",
    "        \"spatial_cuts\": {\"b\":[3,6],\"R\":[0,3.5],\"l\":[-2,2]},\n",
    "        \"pop_cuts\": {\"age\":[9.5,10]},\n",
    "        \"sampling_repeats\": 5000,\n",
    "        \"bootstrap_repeats\": 500\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "sample_sizes_str = \"50size5000_100stepsLog\"\n",
    "\n",
    "array_name_dict = {\n",
    "    \"SEs\": \"errors\"\n",
    "}\n",
    "\n",
    "fill_all_dicts_with_arrays(all_dicts=all_dicts,base_path=base_path,function_dict=function_dict,\\\n",
    "                           sample_sizes_str=sample_sizes_str,array_name_dict=array_name_dict,calculate_correlation=True)\n",
    "\n",
    "# for filename\n",
    "repeats_str = f\"_s{5000}b{500}rep\"\n",
    "print(\"Repeats string is\",repeats_str)\n",
    "\n",
    "ylabel = \"Standard error\"\n",
    "print(\"ylabel is\",ylabel)\n",
    "\n",
    "leg_label = \"SE\"\n",
    "quantity = \"errors\"\n",
    "            \n",
    "colors = [\"blue\", \"red\"]\n",
    "labels = [\"Young SE\", \"Old SE\"]\n",
    "\n",
    "for i,dic in enumerate(all_dicts):\n",
    "    dic[\"color\"] = colors[i]\n",
    "    dic[\"label\"] = labels[i]\n",
    "    \n",
    "    dic[\"linestyle\"] = \"-\"\n",
    "    dic[\"alpha\"] = 0.7\n",
    "    \n",
    "    dic[\"mean_boot_label\"] = None\n",
    "    dic[\"median_boot_label\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption test on bias\n",
    "\n",
    "all_dicts = [\n",
    "    {\n",
    "        \"spatial_cuts\": {\"b\":[3,6],\"R\":[0,3.5],\"l\":[-2,2]},\n",
    "        \"pop_cuts\": {\"age\":[4,7]},\n",
    "        \"sampling_repeats\": 5000,\n",
    "        \"bootstrap_repeats\": 500\n",
    "    },\n",
    "    {\n",
    "        \"spatial_cuts\": {\"b\":[3,6],\"R\":[0,3.5],\"l\":[-2,2]},\n",
    "        \"pop_cuts\": {\"age\":[9.5,10]},\n",
    "        \"sampling_repeats\": 5000,\n",
    "        \"bootstrap_repeats\": 500\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "sample_sizes_str = \"50size5000_100stepsLog\"\n",
    "\n",
    "array_name_dict = {\n",
    "    \"biases\": \"biases\"\n",
    "}\n",
    "\n",
    "fill_all_dicts_with_arrays(all_dicts=all_dicts,base_path=base_path,function_dict=function_dict,sample_sizes_str=sample_sizes_str,array_name_dict=array_name_dict)\n",
    "\n",
    "# for filename\n",
    "repeats_str = f\"_s{5000}b{500}rep\"\n",
    "print(\"Repeats string is\",repeats_str)\n",
    "            \n",
    "colors = [\"blue\", \"red\"]\n",
    "labels = [\"Young\", \"Old\"]\n",
    "\n",
    "ylabel = \"Bias\"\n",
    "print(\"ylabel is\",ylabel)\n",
    "\n",
    "leg_label = \"biases\"\n",
    "print(\"leg_label is\",leg_label)\n",
    "\n",
    "for i,dic in enumerate(all_dicts):\n",
    "    dic[\"color\"] = colors[i]\n",
    "    dic[\"label\"] = labels[i]\n",
    "    \n",
    "    dic[\"linestyle\"] = \"-\"\n",
    "    dic[\"alpha\"] = 0.7\n",
    "    \n",
    "    dic[\"mean_boot_label\"] = None\n",
    "    dic[\"median_boot_label\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess robustness of errors for different B\n",
    "\n",
    "all_dicts = [\n",
    "    {\n",
    "        \"spatial_cuts\": {\"b\":[3,6],\"R\":[0,3.5],\"l\":[-2,2]},\n",
    "        \"pop_cuts\": {\"age\":[4,7]},\n",
    "        \"sampling_repeats\": 5000,\n",
    "        \"bootstrap_repeats\": 500\n",
    "    },\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R3.5/-2l2/arrays/sampling1000repeats/bootstrap1000repeats/\"+\\\n",
    "                          \"anicorr_4age7_1000repeats_50size5000_100stepsLog_sampleBootErrors.json\"),\n",
    "    {\n",
    "        \"spatial_cuts\": {\"b\":[3,6],\"R\":[0,3.5],\"l\":[-2,2]},\n",
    "        \"pop_cuts\": {\"age\":[9.5,10]},\n",
    "        \"sampling_repeats\": 5000,\n",
    "        \"bootstrap_repeats\": 500\n",
    "    },\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R3.5/-2l2/arrays/sampling1000repeats/bootstrap1000repeats/\"+\\\n",
    "                          \"anicorr_9.5age10_1000repeats_50size5000_100stepsLog_sampleBootErrors.json\"),\n",
    "]\n",
    "\n",
    "sample_sizes_str = \"50size5000_100stepsLog\"\n",
    "fill_all_dicts_with_arrays(all_dicts=[all_dicts[0],all_dicts[2]],base_path=base_path,function_dict=function_dict,\\\n",
    "                           sample_sizes_str=sample_sizes_str,calculate_correlation=True)\n",
    "\n",
    "# for filename\n",
    "repeats_str = f\"_s5000b500rep,s1000b1000rep\"\n",
    "print(\"Repeats string is\",repeats_str)\n",
    "            \n",
    "colors = [\"blue\", \"cyan\", \"red\", \"orange\"]\n",
    "labels = [r\"Young $S,B=5000,500$\", r\"Young $S,B=1000,1000$\", r\"Old $S,B=5000,500$\", r\"Old $S,B=1000,1000$\"]\n",
    "\n",
    "# mean_boot_labels = labels\n",
    "mean_boot_labels = 4*[None]\n",
    "\n",
    "median_boot_labels = labels\n",
    "# median_boot_labels = 4*[None]\n",
    "\n",
    "# ylabel = \"Standard error\"\n",
    "# ylabel = \"Mean bootstrap SE\"\n",
    "ylabel = \"Median bootstrap SE\"\n",
    "print(\"ylabel is\",ylabel)\n",
    "\n",
    "for i,dic in enumerate(all_dicts):\n",
    "    dic[\"color\"] = colors[i]\n",
    "    dic[\"label\"] = labels[i]\n",
    "    dic[\"mean_boot_label\"] = mean_boot_labels[i]\n",
    "    dic[\"median_boot_label\"] = median_boot_labels[i]\n",
    "    \n",
    "    dic[\"linestyle\"] = \"-\"\n",
    "    dic[\"alpha\"] = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134",
   "metadata": {},
   "source": [
    "Load from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with vs without resampling\n",
    "\n",
    "base_path_no_resampling = base_path.split(\"with_replacement\")[0]+\"without_replacement/\"\n",
    "\n",
    "all_dicts = [\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R2/-2l2/anicorr_4age7_{repeats}repeats_50size5000_100stepsLog_sampleBootErrors.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R2/-2l2/anicorr_9.5age10_{repeats}repeats_50size5000_100stepsLog_sampleBootErrors.json\"),\n",
    "    \n",
    "    MF.load_dic_from_json(filename=base_path_no_resampling+f\"3b6/0R2/-2l2/anicorr_4age7_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path_no_resampling+f\"3b6/0R2/-2l2/anicorr_9.5age10_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "]\n",
    "\n",
    "colors = 2*[\"blue\", \"red\"]\n",
    "labels = [\"Young\", \"Old\"] + 2*[None]\n",
    "linestyles = 2*[\"-\"] + 2*[\"--\"]\n",
    "\n",
    "for i,dic in enumerate(all_dicts):\n",
    "    dic[\"color\"] = colors[i]\n",
    "    dic[\"label\"] = labels[i]\n",
    "    \n",
    "    dic[\"linestyle\"] = linestyles[i]\n",
    "    dic[\"alpha\"] = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampleBootErrors\n",
    "\n",
    "all_dicts = [\n",
    "#     MF.load_dic_from_json(filename=base_path+f\"1.5b2/0R2/-2l2/anicorr_4age7_{repeats}repeats_50size5000_100stepsLog_sampleBootErrors.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R3.5/-2l2/anicorr_4age7_{repeats}repeats_50size5000_100stepsLog_sampleBootErrors.json\"),\n",
    "    \n",
    "#     MF.load_dic_from_json(filename=base_path+f\"1.5b2/0R2/-2l2/anicorr_9.5age10_{repeats}repeats_50size5000_100stepsLog_sampleBootErrors.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R3.5/-2l2/anicorr_9.5age10_{repeats}repeats_50size5000_100stepsLog_sampleBootErrors.json\"),\n",
    "]\n",
    "\n",
    "colors = [\"blue\", \"red\"]\n",
    "labels = [\"Young SE\", \"Old SE\"]\n",
    "\n",
    "for i,dic in enumerate(all_dicts):\n",
    "    dic[\"color\"] = colors[i]\n",
    "    dic[\"label\"] = labels[i]\n",
    "    \n",
    "    dic[\"linestyle\"] = \"-\"\n",
    "    dic[\"alpha\"] = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude, radius\n",
    "\n",
    "all_dicts = [\n",
    "    MF.load_dic_from_json(filename=base_path+f\"1.5b2/0R3.5/-2l2/anicorr_4age7_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+\"1.5b2/0R2/-2l2/anicorr_4age7_5000repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R3.5/-2l2/anicorr_4age7_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+\"3b6/0R2/-2l2/anicorr_4age7_5000repeats_50size5000_100stepsLog.json\"),\n",
    "    \n",
    "    MF.load_dic_from_json(filename=base_path+f\"1.5b2/0R3.5/-2l2/anicorr_9.5age10_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+\"1.5b2/0R2/-2l2/anicorr_9.5age10_5000repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R3.5/-2l2/anicorr_9.5age10_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+\"3b6/0R2/-2l2/anicorr_9.5age10_5000repeats_50size5000_100stepsLog.json\"),\n",
    "]\n",
    "\n",
    "colors = [\"blue\",\"blue\",\"cyan\",\"cyan\"] + [\"red\",\"red\",\"orange\",\"orange\"]\n",
    "labels = [r\"Young $1.5^\\circ<|b|<2^\\circ$\", None, r\"Young $3^\\circ<|b|<6^\\circ$\", None] +\\\n",
    "         [r\"Old $1.5^\\circ<|b|<2^\\circ$\", None, r\"Old $3^\\circ<|b|<6^\\circ$\", None]\n",
    "linestyles = 4*[\"-\",\"-.\"]\n",
    "\n",
    "for i,dic in enumerate(all_dicts):\n",
    "    dic[\"color\"] = colors[i]\n",
    "    dic[\"label\"] = labels[i]\n",
    "    dic[\"linestyle\"] = linestyles[i]\n",
    "    \n",
    "    dic[\"alpha\"] = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude\n",
    "\n",
    "all_dicts = [\n",
    "    MF.load_dic_from_json(filename=base_path+f\"1.5b2/0R3.5/-2l2/anicorr_4age7_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R3.5/-2l2/anicorr_4age7_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+f\"6b13/0R3.5/-2l2/anicorr_4age7_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    \n",
    "    MF.load_dic_from_json(filename=base_path+f\"1.5b2/0R3.5/-2l2/anicorr_9.5age10_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R3.5/-2l2/anicorr_9.5age10_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+f\"6b13/0R3.5/-2l2/anicorr_9.5age10_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "]\n",
    "\n",
    "colors = [\"blue\",\"dodgerblue\",\"cyan\"] + [\"red\", \"darkviolet\", \"orange\"]\n",
    "labels = [r\"Young $1.5^\\circ<|b|<2^\\circ$\", r\"Young $3^\\circ<|b|<6^\\circ$\", r\"Young $6^\\circ<|b|<13^\\circ$\"] + \\\n",
    "         [r\"Old $1.5^\\circ<|b|<2^\\circ$\", r\"Old $3^\\circ<|b|<6^\\circ$\", r\"Old $6^\\circ<|b|<13^\\circ$\"]\n",
    "\n",
    "for i,dic in enumerate(all_dicts):\n",
    "    dic[\"color\"] = colors[i]\n",
    "    dic[\"label\"] = labels[i]\n",
    "    \n",
    "    dic[\"linestyle\"] = \"-\"\n",
    "    dic[\"alpha\"] = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# longitude, radius\n",
    "\n",
    "all_dicts = [\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R3.5/-2l2/anicorr_4age7_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R2/-2l2/anicorr_4age7_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R3.5/3l6/anicorr_4age7_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R2/3l6/anicorr_4age7_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    \n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R3.5/-2l2/anicorr_9.5age10_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R2/-2l2/anicorr_9.5age10_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R3.5/3l6/anicorr_9.5age10_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "    MF.load_dic_from_json(filename=base_path+f\"3b6/0R2/3l6/anicorr_9.5age10_{repeats}repeats_50size5000_100stepsLog.json\"),\n",
    "]\n",
    "\n",
    "colors = [\"blue\", \"blue\", \"cyan\", \"cyan\"] + [\"red\",\"red\",\"orange\",\"orange\"]\n",
    "labels = [r\"Young $|l|<2^\\circ$\", None, r\"Young $3^\\circ<l<6^\\circ$\", None] + [r\"Old $|l|<2^\\circ$\", None, r\"Old $3^\\circ<l<6^\\circ$\", None]\n",
    "linestyles = 4*[\"-\",\"-.\"]\n",
    "\n",
    "for i,dic in enumerate(all_dicts):\n",
    "    dic[\"color\"] = colors[i]\n",
    "    dic[\"label\"] = labels[i]\n",
    "    dic[\"linestyle\"] = linestyles[i]\n",
    "    \n",
    "    dic[\"alpha\"] = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": [
    "logSampling = True\n",
    "# logSampling = False\n",
    "\n",
    "if logSampling:\n",
    "    sampling_sizes = np.int64(np.round(10**np.linspace(np.log10(50),np.log10(5000),100)))\n",
    "else:\n",
    "    sampling_sizes = np.arange(50,5000+50,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sampling_size = max(sampling_sizes)\n",
    "# xtick_step = 500\n",
    "# major_locator = 1000\n",
    "# minor_locator = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ylog_bool = True\n",
    "ylog_bool = False\n",
    "\n",
    "xlog_bool = True\n",
    "# xlog_bool = False\n",
    "\n",
    "if logSampling and not xlog_bool:\n",
    "    print(\"WARNING: Using logSampling with non-log x-axis\")\n",
    "elif not logSampling and xlog_bool:\n",
    "    print(\"WARNING: Using non-log sampling with log x-axis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_fits_all_dicts = {\n",
    "    \"anisotropy\": False,\n",
    "    \"correlation\": False,\n",
    "    \"tilt_abs\": False\n",
    "}\n",
    "\n",
    "# fit_func = ReciprocalFunc(p0=[1,10,10])\n",
    "fit_func = InverseSquareFunc(p0=[1])\n",
    "\n",
    "# fit_params_text_bool = True\n",
    "fit_params_text_bool = False\n",
    "\n",
    "if fit_params_text_bool:\n",
    "    if xlog_bool and ylog_bool:\n",
    "        x_eq,y_eq = 0.75, 0.15\n",
    "    elif xlog_bool:\n",
    "        x_eq,y_eq = 0.65,0.4\n",
    "    else:\n",
    "        x_eq,y_eq = 0.4, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_true_pearson_standard_error = True\n",
    "# show_true_pearson_standard_error = False\n",
    "\n",
    "def pearson_standard_error(n_plot, correlation):\n",
    "    return (1-correlation**2)/np.sqrt(n_plot - 3); # https://doi.org/10.1525/collabra.87615\n",
    "#     return (1-correlation**2)/np.sqrt(n_plot - 2) # https://en.youscribe.com/BookReader/Index/520541/?documentId=491664\n",
    "#     return (1-correlation**2)/np.sqrt(n_plot) # https://www.tandfonline.com/doi/abs/10.1080/01621459.1928.10502991\n",
    "pearson_se_label = r\"$\\frac{1-\\rho^2}{\\sqrt{n-3}}$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147",
   "metadata": {},
   "outputs": [],
   "source": [
    "if quantity == \"errors\":\n",
    "    hard_coded_ylims_dict = {\n",
    "    #     \"anisotropy\": [0 if not ylog_bool else 0.001, 0.3],\n",
    "#         \"correlation\": [0 if not ylog_bool else 0.001, 0.149],\n",
    "    #     \"tilt_abs\": [0 if not ylog_bool else 0.1, 33]\n",
    "    }\n",
    "elif quantity == \"biases\":\n",
    "    hard_coded_ylims_dict = {\n",
    "        \"correlation\": [-0.019,0.019],\n",
    "    }\n",
    "    \n",
    "if xlog_bool and ylog_bool:\n",
    "    for k in hard_coded_ylims_dict:\n",
    "        hard_coded_ylims_dict[k][1] *= 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brokenaxes = True\n",
    "brokenaxes = False\n",
    "\n",
    "# MC_error_bool = brokenaxes and xlog_bool and ylog_bool\n",
    "MC_error_bool = False\n",
    "\n",
    "bootstrap_error_bool = brokenaxes\n",
    "\n",
    "figsize = (8,10) if brokenaxes else (10,10)\n",
    "if brokenaxes: # reduce tick size\n",
    "    plt.rcParams[\"xtick.major.size\"] = 6\n",
    "    plt.rcParams[\"xtick.minor.size\"] = 3\n",
    "    plt.rcParams[\"ytick.major.size\"] = 6\n",
    "    plt.rcParams[\"ytick.minor.size\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_bool = True\n",
    "# fit_bool = False\n",
    "\n",
    "if quantity != \"errors\":\n",
    "    fit_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_actual_standard_errors = True\n",
    "# show_actual_standard_errors = False\n",
    "\n",
    "show_sample_bootstrap_errors = True\n",
    "# show_sample_bootstrap_errors = False\n",
    "\n",
    "if show_sample_bootstrap_errors:\n",
    "    \n",
    "    ### Mean\n",
    "    show_bootstrap_mean = True; bootstrap_mean_label = f\"Mean of bootstrap {leg_label}\"\n",
    "#     show_bootstrap_mean = False\n",
    "    \n",
    "    ### Median\n",
    "#     show_bootstrap_median = True; bootstrap_median_label = f\"Median of bootstrap {leg_label}\"\n",
    "    show_bootstrap_median = False\n",
    "    \n",
    "    ### STD\n",
    "#     show_nested_bootstrap_std = True; bootstrap_std_label = f\"STD of bootstrap {leg_label}\"\n",
    "    show_nested_bootstrap_std = False\n",
    "\n",
    "#     nested_bootstrap_std_symmetric = True\n",
    "    nested_bootstrap_std_symmetric = False\n",
    "\n",
    "    ### PERCENTILE\n",
    "    \n",
    "    show_percentile_sample_bootstrap_errors_surface = True\n",
    "#     show_percentile_sample_bootstrap_errors_surface = False\n",
    "    \n",
    "    percentile = 68; percentile_sample_bootstrap_error_surface_label = f\"68% interval of bootstrap {leg_label}\"; filename_suffix_percentile_bootstrap = \"68q\"\n",
    "#     percentile = 95; percentile_sample_bootstrap_error_surface_label = f\"95% interval of bootstrap {leg_label}\"; filename_suffix_percentile_bootstrap = \"95q\"\n",
    "#     percentile = 99.7; percentile_sample_bootstrap_error_surface_label = f\"99.7% interval of bootstrap {leg_label}\"; filename_suffix_percentile_bootstrap = \"99.7q\"\n",
    "#     percentile = 100; percentile_sample_bootstrap_error_surface_label = f\"Full range of bootstrap {leg_label}\"; filename_suffix_percentile_bootstrap = \"100q\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_y = [0.001,0.001,0] if quantity == \"errors\" else 3*[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantity vs N\n",
    "\n",
    "width_broken_axes = 0.13\n",
    "nrows = len(function_dict)\n",
    "\n",
    "fig,axs = plt.subplots(figsize=figsize,ncols=3,nrows=nrows,gridspec_kw={\"width_ratios\":[1]+2*[width_broken_axes],\"wspace\":0.1,\"hspace\":0})\n",
    "\n",
    "for row,func in enumerate(function_dict):\n",
    "    lax,cax,rax = axs[row]\n",
    "\n",
    "    if brokenaxes: # broken axes\n",
    "\n",
    "        d = 0.02\n",
    "        d_factor = 1/width_broken_axes\n",
    "        \n",
    "        for ax in [lax,cax]:\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            ax.tick_params(which='both',right=False)\n",
    "        \n",
    "        lax.plot((1-d,1+d), (-d,d), transform=lax.transAxes, color='k', clip_on=False,lw=\"1\")\n",
    "        lax.plot((1-d,1+d),(1-d,1+d), transform=lax.transAxes, color='k', clip_on=False,lw=\"1\")\n",
    "        \n",
    "        cax.plot((1-d_factor*d,1+d_factor*d), (-d,d), transform=cax.transAxes, color='k', clip_on=False,lw=\"1\")\n",
    "        cax.plot((1-d_factor*d,1+d_factor*d), (1-d,1+d), transform=cax.transAxes, color='k', clip_on=False,lw=\"1\")\n",
    "        \n",
    "        for ax in [cax,rax]:\n",
    "            ax.spines['left'].set_visible(False)\n",
    "            ax.tick_params(which='both',left=False)\n",
    "            \n",
    "            ax.plot((-d_factor*d,+d_factor*d), (1-d,1+d), transform=ax.transAxes, color='k', clip_on=False,lw=\"1\")\n",
    "            ax.plot((-d_factor*d,+d_factor*d), (-d,d), transform=ax.transAxes, color='k', clip_on=False,lw=\"1\")\n",
    "    else:\n",
    "        fig.delaxes(cax)\n",
    "        fig.delaxes(rax)\n",
    "    \n",
    "    if True: # plot\n",
    "        for d,dic in enumerate(all_dicts):\n",
    "            \n",
    "            quantity = list(array_name_dict.values())[0]\n",
    "            \n",
    "            if quantity == \"biases\":\n",
    "                lax.axhline(y=0,color=\"grey\",linestyle=\"dotted\")\n",
    "            \n",
    "            if show_actual_standard_errors:\n",
    "                lax.plot(sampling_sizes[sampling_sizes <= max_sampling_size],np.array(dic[func+\"_\"+quantity])[sampling_sizes <= max_sampling_size],\\\n",
    "                         label=dic[\"label\"] if row==0 else None,color=dic[\"color\"],alpha=dic[\"alpha\"],linestyle=dic[\"linestyle\"])\n",
    "            \n",
    "            if show_sample_bootstrap_errors:\n",
    "\n",
    "                mean_bootstrap_errors = np.mean(dic[func+\"_bootstrap_\"+quantity],axis=1)\n",
    "                \n",
    "                if show_nested_bootstrap_std:\n",
    "                    std_low,std_high = np.zeros(shape=(len(sampling_sizes))),np.zeros(shape=(len(sampling_sizes)))\n",
    "\n",
    "                    for i,mean in enumerate(mean_bootstrap_errors):\n",
    "                        std_low[i],std_high[i] = error_helpers.build_confidence_interval(central_value=mean, values=dic[func+\"_bootstrap_\"+quantity][i],\\\n",
    "                                                                                        symmetric=nested_bootstrap_std_symmetric)\n",
    "                    \n",
    "                    lax.fill_between(x=sampling_sizes, y1=mean_bootstrap_errors-std_low, y2=mean_bootstrap_errors+std_high, color=dic[\"color\"], \\\n",
    "                                 alpha=0.25, linewidth=0 if show_percentile_sample_bootstrap_errors_surface else None)\n",
    "                    \n",
    "                if show_percentile_sample_bootstrap_errors_surface:\n",
    "                    q_low = (100-percentile)/2\n",
    "                    q_high = (100+percentile)/2 # this is the same as 100-q_low\n",
    "                    \n",
    "                    lax.fill_between(x=sampling_sizes, \\\n",
    "                                     y1=np.percentile(dic[func+\"_bootstrap_\"+quantity],axis=1, q=q_low),\\\n",
    "                                     y2=np.percentile(dic[func+\"_bootstrap_\"+quantity],axis=1, q=q_high),\\\n",
    "                                     color=dic[\"color\"], alpha=0.1 if show_nested_bootstrap_std else 0.25)\n",
    "                \n",
    "                if show_bootstrap_mean:\n",
    "                    lax.plot(sampling_sizes, mean_bootstrap_errors, color=dic[\"color\"], linestyle=\"--\", label=dic[\"mean_boot_label\"])\n",
    "                \n",
    "                if show_bootstrap_median:\n",
    "                    lax.plot(sampling_sizes, np.median(dic[func+\"_bootstrap_\"+quantity],axis=1),color=dic[\"color\"],linestyle=\"-.\",label=dic[\"median_boot_label\"])\n",
    "        \n",
    "        if show_sample_bootstrap_errors and row==0: # just for legend labels\n",
    "            \n",
    "            labely = np.mean(dic[func+\"_\"+quantity])\n",
    "            \n",
    "            if show_bootstrap_mean and dic[\"mean_boot_label\"] is None:\n",
    "                lax.plot([-2,-1],[labely,labely],color=\"k\",linestyle=\"--\",label=bootstrap_mean_label)\n",
    "                \n",
    "            if show_bootstrap_median and dic[\"median_boot_label\"] is None:\n",
    "                lax.plot([-2,-1],[labely,labely],color=\"k\",linestyle=\"-.\",label=bootstrap_median_label)\n",
    "            \n",
    "            if show_nested_bootstrap_std:\n",
    "                lax.fill_between(x=[-2,-1],y1=[labely,labely],y2=[labely,labely],color=\"k\",alpha=0.25,label=bootstrap_std_label)\n",
    "            \n",
    "            if show_percentile_sample_bootstrap_errors_surface:\n",
    "                lax.fill_between(x=[-2,-1],y1=[labely,labely],y2=[labely,labely],color=\"k\",alpha=0.1 if show_nested_bootstrap_std else 0.25,\\\n",
    "                                 label=percentile_sample_bootstrap_error_surface_label)\n",
    "                    \n",
    "        if brokenaxes:\n",
    "            for dic,ax in zip(all_dicts,[cax,rax]):\n",
    "                ax.scatter(dic[\"total_N\"],dic[func+\"_bootstrap_error\"],marker=\"*\",color=dic[\"color\"])\n",
    "\n",
    "                if MC_error_bool:\n",
    "                    ax.scatter(dic[\"total_N\"],dic[func+\"_MC_d_0.2_error_low\"],marker=\"v\",color=dic[\"color\"],s=23)\n",
    "                    ax.scatter(dic[\"total_N\"],dic[func+\"_MC_d_0.2_error_high\"],marker=\"^\",color=dic[\"color\"],s=23)\n",
    "\n",
    "                ax.set_xticks([dic[\"total_N\"]])\n",
    "\n",
    "            if bootstrap_error_bool:\n",
    "                lax.scatter(x=-100,y=0,marker=\"*\",color=\"k\",label=\"Bootstrap error\") # just for the legend label\n",
    "\n",
    "            if MC_error_bool:\n",
    "                lax.scatter(x=-100,y=0,marker=\"v\",color=\"k\",label=\"MC 20% distance error\",s=23) # just for the legend label\n",
    "    \n",
    "    if True: # ticks, lims, logscale\n",
    "        \n",
    "        if xlog_bool:\n",
    "            lax.set_xscale(\"log\")\n",
    "        \n",
    "        lax_leftlim = 45 if xlog_bool else 0\n",
    "        lax_rightlim = max_sampling_size+minor_locator*0.7 if not xlog_bool else max_sampling_size+10**(MF.get_exponent(max_sampling_size))//2\n",
    "        lax.set_xlim(lax_leftlim,lax_rightlim)\n",
    "        \n",
    "        if not xlog_bool:\n",
    "            lax.xaxis.set_major_locator(ticker.MultipleLocator(major_locator))\n",
    "            lax.xaxis.set_minor_locator(ticker.MultipleLocator(minor_locator))\n",
    "#             lax.set_xticks([50]+list(np.arange(xtick_step,max_sampling_size+xtick_step,xtick_step)))\n",
    "        \n",
    "        for ax in [lax,cax,rax]:\n",
    "            if brokenaxes:\n",
    "                ax.tick_params(axis='x', which='major', pad=10)\n",
    "            \n",
    "            if ylog_bool:\n",
    "                ax.set_yscale(\"log\")\n",
    "                \n",
    "            if ax in [cax,rax]:\n",
    "                ax.yaxis.set_ticklabels([])\n",
    "            \n",
    "            if func in hard_coded_ylims_dict:\n",
    "                ax.set_ylim(hard_coded_ylims_dict[func])\n",
    "#             else:\n",
    "#                 ax.set_ylim(bottom=0.005 if ylog_bool else 0)\n",
    "\n",
    "            if not ylog_bool and quantity==\"errors\":\n",
    "                if func == \"anisotropy\" and lax.get_ylim()[1] < 0.6:\n",
    "                    ax.yaxis.set_major_locator(ticker.MultipleLocator(0.1))\n",
    "                if func == \"correlation\":\n",
    "                    ax.yaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "                if func == \"tilt_abs\":\n",
    "                    ax.yaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "\n",
    "            if row != nrows - 1:\n",
    "                ax.xaxis.set_ticklabels([])\n",
    "                ax.xaxis.set_ticklabels([])\n",
    "        \n",
    "    if show_actual_standard_errors and fit_bool:\n",
    "\n",
    "        x_plot = np.linspace(min(sampling_sizes),max_sampling_size,500)\n",
    "        \n",
    "        if same_fits_all_dicts[func]:\n",
    "            fit_func.fit(x = sampling_sizes[sampling_sizes<=max_sampling_size], y = np.array(all_dicts[0][func+\"_errors\"])[sampling_sizes<=max_sampling_size])\n",
    "            lax.plot(x_plot, fit_func.func(x_plot, *fit_func.fit_params), color=\"grey\", linestyle=\"dotted\")\n",
    "            \n",
    "            if fit_params_text_bool:\n",
    "                show_fit_params_text(ax=lax,Func=fit_func,color=\"grey\",x_eq=x_eq,y_eq=y_eq)\n",
    "        elif not (func == \"correlation\" and show_true_pearson_standard_error):\n",
    "            for i, dic in enumerate(all_dicts):\n",
    "                fit_func.fit(x = sampling_sizes[sampling_sizes<=max_sampling_size], y = np.array(dic[func+\"_errors\"])[sampling_sizes<=max_sampling_size])\n",
    "\n",
    "                lax.plot(x_plot, fit_func.func(x_plot, *fit_func.fit_params), color=dic[\"color\"], linestyle=\"dotted\",alpha=0.5)\n",
    "                \n",
    "                if fit_params_text_bool:\n",
    "                    show_fit_params_text(ax=lax,Func=fit_func,alpha=0.7,color=dic[\"color\"],x_eq=x_eq,y_eq=y_eq - i*0.08,units=mapf.get_units(func))\n",
    "        \n",
    "        if row == 0:\n",
    "            labely = np.mean(dic[\"anisotropy_errors\"])\n",
    "            lax.plot([-100,-99],[labely,labely],linestyle=\"dotted\",color=\"grey\",label=fit_func.label) # just for the legend label\n",
    "    \n",
    "    if show_actual_standard_errors and fit_bool and func == \"correlation\" and show_true_pearson_standard_error:\n",
    "        for dic in all_dicts:\n",
    "            lax.plot(x_plot,pearson_standard_error(x_plot,dic[\"correlation\"]),color=dic[\"color\"],alpha=0.5,linestyle=\"dotted\")\n",
    "        \n",
    "        lax.plot([0],[0],color=\"grey\",linestyle=\"dotted\",label=pearson_se_label) # for legend\n",
    "    \n",
    "    if True: # labels\n",
    "        if row == nrows-1:\n",
    "            if brokenaxes:\n",
    "#                 lax.set_xlabel(\"Sample size\"); lax.text(s=r\"Total $N$\",x=1.1,y=-0.25,transform=lax.transAxes,size=\"medium\")\n",
    "                lax.text(s=\"Sample size\",x=0.5,y=-0.25,transform=lax.transAxes,size=\"medium\")\n",
    "            else:\n",
    "                lax.set_xlabel(\"Sample size\");\n",
    "                \n",
    "        lax.set_ylabel(ylabel + r\" %s\"%((r\"$[$\" + mapf.get_units(func) + r\"$]$\") if mapf.get_units(func) != \"\" else \"\"))\n",
    "        \n",
    "        fig.align_labels()\n",
    "    \n",
    "    if True: # text\n",
    "        if xlog_bool and ylog_bool:\n",
    "            x_func_text = 0.98\n",
    "        elif xlog_bool:\n",
    "            x_func_text = 0.6 if quantity == \"errors\" else 1.15\n",
    "        else:\n",
    "            x_func_text = 0.2\n",
    "        \n",
    "        func_str = mapf.get_kinematic_titles_dict(\"r\",\"l\")[func.removesuffix(\"_abs\")]\n",
    "            \n",
    "        if not brokenaxes:\n",
    "            x_func_text -= 0.45 if xlog_bool else 0\n",
    "        fig.text(s=func_str,x=x_func_text,y=0.85 if quantity==\"errors\" else 0.8,transform=lax.transAxes,size=\"small\")\n",
    "    \n",
    "    if True: # legend\n",
    "        if row == 0:\n",
    "            if brokenaxes:\n",
    "                fig.legend(loc=(0.65,0.77) if not (xlog_bool and ylog_bool) else (0.16,0.7),framealpha=0 if xlog_bool and ylog_bool else 1)\n",
    "            else:\n",
    "                lax.legend(loc=\"best\" if not ylog_bool else \"lower left\", framealpha=0.5)\n",
    "        elif row == 1:\n",
    "            if show_actual_standard_errors and fit_bool and show_true_pearson_standard_error and func == \"correlation\":\n",
    "                lax.legend(loc=\"lower left\" if xlog_bool and ylog_bool else \"upper right\", framealpha=0.5)\n",
    "        \n",
    "    if True: # fix ylims if needed\n",
    "        if func not in hard_coded_ylims_dict:\n",
    "#             if lax.get_ylim()[0] < 0:\n",
    "            for ax in [lax,cax,rax]:\n",
    "                ax.set_ylim(bottom=min_y[row])\n",
    "        \n",
    "if True: # filename, save and show\n",
    "    \n",
    "    all_spatial_cuts = [dic[\"spatial_cuts\"] for dic in all_dicts]\n",
    "    save_path = get_save_path_spatial_cuts(base_path=base_path,spatial_cuts=all_spatial_cuts)\n",
    "    \n",
    "    filename = quantity\n",
    "    \n",
    "    if list(function_dict.keys()) == [\"anisotropy\",\"correlation\",\"tilt_abs\"]:\n",
    "        filename += \"_anicorr\"\n",
    "    else:\n",
    "        raise ValueError(\"Please specify map list name\")\n",
    "\n",
    "    pop_str = MF.extract_str_from_cuts_dict(all_dicts[0][\"pop_cuts\"])\n",
    "    filename += \"_\"+pop_str\n",
    "    for dic in all_dicts[1:]:\n",
    "        if MF.extract_str_from_cuts_dict(dic[\"pop_cuts\"]) not in filename:\n",
    "            filename += '_'+MF.extract_str_from_cuts_dict(dic[\"pop_cuts\"])\n",
    "    \n",
    "    filename += repeats_str\n",
    "    filename += f\"_{min(sampling_sizes)}size{max(sampling_sizes)}step{len(sampling_sizes)}\"\n",
    "    filename += \"log\" if logSampling else \"\"\n",
    "    \n",
    "    if xlog_bool and ylog_bool:\n",
    "        filename += \"_xylog\"\n",
    "    elif xlog_bool:\n",
    "        filename += \"_xlog\"\n",
    "    elif ylog_bool:\n",
    "        filename += \"_ylog\"\n",
    "    \n",
    "    if quantity == \"errors\":\n",
    "        if show_actual_standard_errors:\n",
    "            if fit_bool:\n",
    "                if all(same_fits_all_dicts.values()):\n",
    "                    filename += \"_sharedFits\"\n",
    "                if fit_params_text_bool:\n",
    "                    filename += \"_fitParams\"\n",
    "            else:\n",
    "                filename += \"_noFit\"\n",
    "        else:\n",
    "            filename += \"_noSE\"\n",
    "        \n",
    "    if not show_sample_bootstrap_errors:\n",
    "        filename += \"_noBoot\"\n",
    "    else:\n",
    "        \n",
    "        filename += \"_boot\"\n",
    "        \n",
    "        nested_bootstrap_strings = [\n",
    "            \"Avg\" if show_bootstrap_mean else \"\",\n",
    "            \"Med\" if show_bootstrap_median else \"\",\n",
    "            \"Std\" if show_nested_bootstrap_std else \"\",\n",
    "            filename_suffix_percentile_bootstrap if show_percentile_sample_bootstrap_errors_surface else \"\"\n",
    "        ]\n",
    "        \n",
    "        joint_boot_strings = str.join(\",\", nested_bootstrap_strings)\n",
    "        while \",,\" in joint_boot_strings:\n",
    "            joint_boot_strings = joint_boot_strings.replace(\",,\",\",\")\n",
    "        \n",
    "        filename += joint_boot_strings.strip(\",\")\n",
    "        \n",
    "    if brokenaxes:\n",
    "        filename += \"_broken\"\n",
    "        \n",
    "        if MC_error_bool:\n",
    "            filename += \"_MC\"\n",
    "        \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        print(\"Saving in\",save_path)\n",
    "        \n",
    "        for fileformat in [\".png\",\".pdf\"]:\n",
    "            plt.savefig(save_path+filename+fileformat,dpi=200,bbox_inches=\"tight\")\n",
    "            print(fileformat)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distributions of standard errors\n",
    "\n",
    "sample_size_indices = np.array([0,len(sampling_sizes)//2,-1])\n",
    "\n",
    "nrows = len(function_dict)\n",
    "\n",
    "fig,axs = plt.subplots(figsize=(20,15),ncols=len(sample_size_indices),nrows=nrows,gridspec_kw={\"hspace\":0.3})#,\"wspace\":0},)\n",
    "\n",
    "for row,func in enumerate(function_dict):\n",
    "    row_axs = axs[row]\n",
    "    \n",
    "    for col,(ax,sample_idx) in enumerate(zip(row_axs,sample_size_indices)):\n",
    "        \n",
    "        for d,dic in enumerate(all_dicts):\n",
    "            \n",
    "            ax.hist(dic[func+\"_bootstrap_errors\"][sample_idx], color=dic[\"color\"],bins=50, label=[\"Young\",\"Old\"][d],alpha=0.5)#alpha=dic[\"alpha\"])\n",
    "            \n",
    "            ax.axvline(np.mean(dic[func+\"_bootstrap_errors\"][sample_idx]), color=dic[\"color\"])\n",
    "            ax.axvline(dic[func+\"_errors\"][sample_idx], color=[\"cyan\",\"orange\"][d],linestyle=\"dotted\",lw=2)\n",
    "        \n",
    "        ax.axvline(x=np.mean(dic[func+\"_bootstrap_errors\"][sample_idx]),ymin=0,ymax=0,color=\"k\",label=\"Mean\")\n",
    "        ax.axvline(x=np.mean(dic[func+\"_bootstrap_errors\"][sample_idx]),ymin=0,ymax=0,color=\"k\",linestyle=\"dotted\",lw=2,label=\"Actual SE\")\n",
    "        \n",
    "        if True: # title, labels\n",
    "            if row == 0:\n",
    "                ax.set_title(f\"Sample size {sampling_sizes[sample_idx]}\")\n",
    "            \n",
    "            if col == 0:\n",
    "                ax.set_ylabel(r\"$N$\",rotation=0,labelpad=20)\n",
    "            ax.set_xlabel([\"Anisotropy bootstrap SE\",\"Correlation bootstrap SE\",r\"Vertex deviation bootstrap SE $[^\\circ]$\"][row])\n",
    "                \n",
    "            if row == len(function_dict)//2 and col == len(sample_size_indices)//2: # center\n",
    "                ax.legend()\n",
    "#             if row == 0 and col == 0:\n",
    "#                 ax.legend()\n",
    "            pass\n",
    "            \n",
    "if True: # filename and save\n",
    "    all_spatial_cuts = [dic[\"spatial_cuts\"] for dic in all_dicts]\n",
    "    save_path = get_save_path_spatial_cuts(base_path=base_path,spatial_cuts=all_spatial_cuts)\n",
    "    \n",
    "    filename = \"bootstrapErrorHists\"\n",
    "    \n",
    "    if list(function_dict.keys()) == [\"anisotropy\",\"correlation\",\"tilt_abs\"]:\n",
    "        filename += \"_anicorr\"\n",
    "    else:\n",
    "        raise ValueError(\"Please specify map list name\")\n",
    "\n",
    "    pop_str = MF.extract_str_from_cuts_dict(all_dicts[0][\"pop_cuts\"])\n",
    "    filename += \"_\"+pop_str\n",
    "    for dic in all_dicts[1:]:\n",
    "        if MF.extract_str_from_cuts_dict(dic[\"pop_cuts\"]) not in filename:\n",
    "            filename += '_'+MF.extract_str_from_cuts_dict(dic[\"pop_cuts\"])\n",
    "\n",
    "    filename += f\"_{repeats}repeats\"\n",
    "    filename += \"_\" + str.join(\",\",sampling_sizes[sample_size_indices].astype(str))\n",
    "        \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        print(\"Saving in\",save_path)\n",
    "        plt.savefig(save_path+filename+\".png\",dpi=200,bbox_inches=\"tight\")\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "218px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 156.852,
   "position": {
    "height": "178.852px",
    "left": "1336px",
    "right": "20px",
    "top": "120px",
    "width": "355px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
