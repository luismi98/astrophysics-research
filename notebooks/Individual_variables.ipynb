{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jt -t onedork -T\n",
    "# !jt -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False # To make auto-complete faster\n",
    "\n",
    "#Reloads imported files automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "from scipy.spatial import KDTree\n",
    "import copy\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import colormaps as mplcmaps\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from matplotlib_param_funcs import set_matplotlib_params,reset_rcParams\n",
    "set_matplotlib_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compute_variables as CV\n",
    "import compute_errors as CE\n",
    "import miscellaneous_functions as MF\n",
    "import mixed_plots as MP\n",
    "import plotting_helpers as PH\n",
    "import variable_values_and_errors as val_err\n",
    "import load_sim\n",
    "import load_data\n",
    "import map_functions as mapf\n",
    "import coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:88% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree_symbol = 'Â°'\n",
    "degree_symbol = \"^\\circ\"\n",
    "\n",
    "mass_density_label = r\"$\\Sigma \\hspace{0.3} [\\rm M_\\odot kpc^{-2}]$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coolwarm = mplcmaps['coolwarm']\n",
    "red = coolwarm(0.95)\n",
    "blue = coolwarm(0.05)\n",
    "green = 'darkgreen'\n",
    "grey = 'lightgrey'\n",
    "\n",
    "plt.rcParams['font.size'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHOOSE\n",
    "\n",
    "x_variable = \"l\"\n",
    "y_variable = \"b\"\n",
    "\n",
    "vel_x_variable = 'r'\n",
    "vel_y_variable = 'l'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_dict = mapf.get_kinematic_symbols_dict(x_variable=x_variable,\n",
    "                                                         y_variable=y_variable,\n",
    "                                                         vel_x_variable=vel_x_variable,\n",
    "                                                         vel_y_variable=vel_y_variable)\n",
    "\n",
    "units_dict = mapf.get_kinematic_units_dict(degree_symbol=degree_symbol)\n",
    "\n",
    "pos_symbols_dict,pos_units_dict = mapf.get_position_symbols_and_units_dict(degree_symbol=r\"$%s$\"%degree_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_dict[\"mean_b\"] = r\"$\\langle |b| \\rangle$\"\n",
    "units_dict[\"mean_b\"] = r\"$[^\\circ]$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_map_string_list,divergent_map_list = mapf.get_map_string_lists()\n",
    "\n",
    "all_maps = False\n",
    "full_map_string_list = [map_string for map_string in full_map_string_list if \"spherical\" not in map_string]\n",
    "\n",
    "print(full_map_string_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_path = '/Users/luismi/Desktop/MRes_UCLan/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_path(single_variable):\n",
    "    save_path = general_path+f'graphs/Observations/Apogee/individual_variable/{single_variable}/'\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "def get_save_path_spatial_cuts(single_variable, spatial_cuts_dict):\n",
    "        \n",
    "    save_path = get_base_path(single_variable)\n",
    "    \n",
    "    orders = {\n",
    "        0: [\"b\",\"z\"],\n",
    "        1: [\"d\",\"R\",\"x\"],\n",
    "        2: [\"l\",\"y\"]\n",
    "    }\n",
    "    \n",
    "    for o in orders:\n",
    "        var = [v for v in spatial_cuts_dict if v in orders[o]]\n",
    "        \n",
    "        if len(var) == 0:\n",
    "            continue\n",
    "        elif len(var) > 1:\n",
    "            raise ValueError(f\"Did not expect more than one variable from `{orders[o]}`. If it was not a mistake, please specify the order.\")\n",
    "            \n",
    "        variable = var[0]\n",
    "            \n",
    "        value_tuple = spatial_cuts_dict[variable]\n",
    "        \n",
    "        save_path += f\"{MF.return_int_or_dec(value_tuple[0],2)}{variable}{MF.return_int_or_dec(value_tuple[1],2)}/\"\n",
    "        MF.create_dir(save_path)\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "def get_save_path_data(save_path_spatial, metal_lowcut, metal_lims):\n",
    "        \n",
    "    save_path = save_path_spatial + \"data/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"metal_lowcut_{metal_lowcut}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{str(MF.return_int_or_dec(metal_lims[0],2))}metal{str(MF.return_int_or_dec(metal_lims[1],2))}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "def get_save_path_sim(save_path_spatial, sim_choice, bar_angle, resampled_likedata_bool, age_lims, random_resampling_N, random_seed):\n",
    "    \n",
    "    save_path = save_path_spatial\n",
    "    \n",
    "    save_path += f\"sim_{sim_choice}/\" if sim_choice != \"708main\" else \"sim/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"bar_angle_{bar_angle}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{MF.return_int_or_dec(age_lims[0],2)}age{MF.return_int_or_dec(age_lims[1],2)}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += \"resampled_likedata/\" if resampled_likedata_bool else \"\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"random_resampling_{random_resampling_N}/\" if random_resampling_N is not None else \"\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    if random_resampling_N is not None:\n",
    "        if random_seed is None:\n",
    "            raise ValueError(\"You should set a random seed if performing random resampling for reproducibility reasons.\")\n",
    "        else:\n",
    "            save_path += f\"random_seed_{random_seed}/\" if random_seed is not None else \"\"\n",
    "            MF.create_dir(save_path)\n",
    "        \n",
    "    return save_path\n",
    "\n",
    "def get_save_path_final(save_path_pop, binning_str, pop_str, error_type, error_repeat, montecarloconfig=None, bootstrapconfig=None):\n",
    "    \n",
    "    save_path = save_path_pop\n",
    "    \n",
    "    save_path += f\"{binning_str}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{pop_str}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path_binning = save_path\n",
    "    \n",
    "    if error_type == \"MC\":\n",
    "        if montecarloconfig is None:\n",
    "            raise ValueError(f\"montecarloconfig was None but it needs to be specified when working with MC errors.\")\n",
    "        \n",
    "        save_path += f\"MC_perturbed_{montecarloconfig.perturbed_var}/\"\n",
    "        MF.create_dir(save_path)\n",
    "        \n",
    "        if montecarloconfig.error_frac is not None:\n",
    "            save_path += f\"error_frac_{montecarloconfig.error_frac}/\"\n",
    "        else:\n",
    "            if \"data\" not in save_path_pop:\n",
    "                raise ValueError(\"error_frac was None and path does not correspond to observational data. Please specify how the MC errors are obtained.\")\n",
    "            save_path += f\"data_uncertainties/\"\n",
    "        MF.create_dir(save_path)\n",
    "        \n",
    "        if montecarloconfig.repeats != 500:\n",
    "            save_path += f\"error_repeat_{montecarloconfig.repeats}/\"\n",
    "            MF.create_dir(save_path)\n",
    "        \n",
    "    elif error_type == \"bootstrap\":\n",
    "        if bootstrapconfig is None:\n",
    "            raise ValueError(f\"bootstrapconfig was None but it needs to be specified when working with bootstrap errors.\")\n",
    "        \n",
    "        save_path += \"bootstrap\"\n",
    "        if bootstrapconfig.replacement is False:\n",
    "            save_path += \"_noReplace\"\n",
    "        if bootstrapconfig.symmetric is False:\n",
    "            save_path += \"_Asymmetric\"\n",
    "        save_path += \"/\"\n",
    "            \n",
    "        MF.create_dir(save_path)\n",
    "        \n",
    "        if bootstrapconfig.bootstrap_size is not None:\n",
    "            save_path += f\"bootsize_{bootstrapconfig.bootstrap_size}/\"\n",
    "            MF.create_dir(save_path)\n",
    "        \n",
    "        if bootstrapconfig.repeats != 500:\n",
    "            save_path += f\"error_repeat_{bootstrapconfig.repeats}/\"\n",
    "            MF.create_dir(save_path)\n",
    "    else:\n",
    "        raise ValueError(f\"error_type `{error_type}` not recognised.\")\n",
    "\n",
    "    return save_path, save_path_binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.DataFrame([[1,2,3],[2,3,1],[6,3,4]], columns=['a','b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zabs = True\n",
    "# zabs = False\n",
    "\n",
    "R0 = 8.1\n",
    "\n",
    "GSR = True\n",
    "# GSR = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_choice = \"708main\"\n",
    "# sim_choice = \"708mainDiff4\"\n",
    "# sim_choice = \"708mainDiff5\"\n",
    "\n",
    "rot_angle = 27\n",
    "axisymmetric = False\n",
    "pos_scaling = 1.7\n",
    "\n",
    "filename = load_sim.build_filename(choice=sim_choice,rot_angle=rot_angle,R0=R0,axisymmetric=axisymmetric,zabs=zabs,pos_factor=pos_scaling,GSR=GSR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_chunk = False\n",
    "\n",
    "if not load_chunk:\n",
    "    np_path = general_path+f\"data/{sim_choice}/numpy_arrays/\"\n",
    "        \n",
    "    df0 = load_sim.load_simulation(path=np_path,filename=filename)\n",
    "else:\n",
    "    if sim_choice == \"708main\" and rot_angle == 27 and not axisymmetric and zabs and sim_scaling == 1.7:\n",
    "        pickle_name = \"df_bulge_zabs.pkl\"\n",
    "        df0 = pd.read_pickle(\"708main_simulation/\"+pickle_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_resampled_likedata_bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_path = \"C:/Users/Luismi/JUPYTER_NOTEBOOKS/MRes_UCLan/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.genfromtxt(general_path + \"Oscar_data/gibs_vvvPMs.dat\", names=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_columns = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['l','b','Vgc','FeH','mul_grs','mub_grs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_columns = delete_columns.drop(columns_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=delete_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_distance = 8 #8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vl']=(fixed_distance*3.086e16)*data.mul_grs.values*((np.pi/(180 * 3600))*10**(-3)/(3.1536e7))\n",
    "data['vb']=(fixed_distance*3.086e16)*data.mub_grs.values*((np.pi/(180 * 3600))*10**(-3)/(3.1536e7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"vr\"] = data[\"Vgc\"]\n",
    "#data[\"vr\"] = np.sqrt(data[\"Vgc\"]**2 - data[\"vl\"]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = ['Vgc','mul_grs','mub_grs'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.l > 180, 'l'] -= 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = general_path+'708main_simulation/graphs/Oscar/GIBS/'\n",
    "print(\"Saving in:\",save_path)\n",
    "\n",
    "save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fullrange = True\n",
    "\n",
    "lim = 1000\n",
    "if not fullrange:\n",
    "    ax.set_xlim(-lim,lim)\n",
    "    bins = np.linspace(-lim,lim,100)\n",
    "else:\n",
    "    bins = 100\n",
    "    ax.text(x=0.03,y=0.06,s=str(len(np.where(data['vl'] < -1000)[0])),color='blue',transform=ax.transAxes)\n",
    "lw = 3\n",
    "alpha = 0.5\n",
    "a_n,a_bins,_ = ax.hist(data['vl'],bins=bins,alpha=alpha, color='blue',label=r'GIBS $v_l$')\n",
    "ax.plot([np.mean(data['vl']),np.mean(data['vl'])],[0,np.max(a_n)],alpha=1,color='blue',lw=lw,linestyle='-.')\n",
    "\n",
    "b_n,_,_ = ax.hist(data['vr'],bins=bins if not fullrange else a_bins,alpha=alpha, color='cyan',label=r'GIBS $v_r$')\n",
    "ax.plot([np.mean(data['vr']),np.mean(data['vr'])],[0,np.max(b_n)],alpha=1,color='cyan',lw=lw,linestyle='-.')\n",
    "\n",
    "ax.set_xlabel(r\"Velocity $[\\mathrm{km \\hspace{0.3} s^{-1}}]$\")\n",
    "ax.set_ylabel(r\"$N$\", rotation=0,labelpad=20)\n",
    "plt.legend(loc='best')\n",
    "if save_bool:\n",
    "    filename = 'velocities_fullrange' if fullrange else 'velocities'\n",
    "    plt.savefig(save_path+filename+'.png',bbox_inches='tight',dpi=150)\n",
    "    print(save_path+filename+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apogee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_errors = True\n",
    "# obs_errors = False\n",
    "\n",
    "data_zabs = True\n",
    "# data_zabs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = general_path+\"data/Observational_data/\"\n",
    "\n",
    "data = load_data.load_and_process_data(data_path=data_path, error_bool=obs_errors, zabs=zabs, R0=R0, GSR=GSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-sample sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10 # number of nearest neighbours to find\n",
    "\n",
    "tree = KDTree(df0[[\"x\",\"y\",\"z\"]].values)\n",
    "\n",
    "already_chosen_indices = set()\n",
    "nearest_simulation_star_indices = []\n",
    "all_distances = []\n",
    "\n",
    "for i, obs_star in enumerate(data[[\"x\",\"y\",\"z\"]].values):\n",
    "    k = K\n",
    "    while True:\n",
    "        distances, indices = tree.query(obs_star, k=k)# + len(already_chosen_indices))\n",
    "        \n",
    "        new_indices = [idx for idx in indices if idx not in already_chosen_indices]\n",
    "        \n",
    "        if len(new_indices) >= K:\n",
    "            chosen_indices = new_indices[:K]\n",
    "            \n",
    "            nearest_simulation_star_indices.append(chosen_indices)            \n",
    "            all_distances.append([dist for idx, dist in zip(indices, distances) if idx in chosen_indices])\n",
    "            \n",
    "            already_chosen_indices.update(chosen_indices)\n",
    "            \n",
    "            break\n",
    "        else:\n",
    "            k += K\n",
    "            \n",
    "#     clear_output(wait=True)\n",
    "#     print(f\"Iteration: {i+1}/{len(data)}\")\n",
    "            \n",
    "nearest_simulation_star_indices = np.array(nearest_simulation_star_indices)\n",
    "all_distances = np.array(all_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_simulation_star_indices.shape, all_distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"{general_path}graphs/other_plots/resampled_sim/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distance distribution\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.hist(all_distances.flatten(),bins=300,log=False)\n",
    "ax.set_xlabel(\"Nearest neighbour distances [kpc]\")\n",
    "ax.set_ylabel(r\"$N$\",rotation=0,labelpad=15)\n",
    "\n",
    "max_distance = max(all_distances.flatten())\n",
    "ax.axvline(x=max_distance,color=\"red\",label=\"Maximum distance: %.2f [kpc]\"%max_distance)\n",
    "ax.legend()\n",
    "\n",
    "if save_bool:\n",
    "    plt.savefig(save_path + \"distance_distribution\",dpi=150,bbox_inches=\"tight\")\n",
    "    print(\"Saved:\",save_path + \"distance_distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # lognormal fit to the distance distribution\n",
    "\n",
    "    from scipy.stats import lognorm, norm, gaussian_kde\n",
    "\n",
    "    # fit lognorm in linear scale\n",
    "    shape, loc, scale = lognorm.fit(all_distances.flatten(), floc=0)\n",
    "    mu, sigma = np.log(scale), shape\n",
    "\n",
    "    plt.figure()\n",
    "    count, bins, ignored = plt.hist(all_distances.flatten(), bins=200, density=True, alpha=0.3, color='b')\n",
    "    pdf = lognorm.pdf(bins, sigma, scale=np.exp(mu))\n",
    "    plt.plot(bins, pdf, color='r')\n",
    "    plt.show()\n",
    "\n",
    "    # fit gaussian in log scale\n",
    "    log_distances = np.log(all_distances.flatten())\n",
    "    mu, std = norm.fit(log_distances)\n",
    "\n",
    "    plt.figure()\n",
    "    count, bins, ignored = plt.hist(log_distances, bins=200, density=True, alpha=0.3, color='b')\n",
    "    pdf = norm.pdf(bins, mu, std)\n",
    "    plt.plot(bins, pdf, color='r')\n",
    "    plt.show()\n",
    "\n",
    "    # check KDE\n",
    "    values = np.linspace(min(all_distances.flatten()), max(all_distances.flatten()), 1000)\n",
    "    kde = gaussian_kde(all_distances.flatten())\n",
    "    kde_values = kde(values)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(all_distances.flatten(), bins=200, density=True, alpha=0.3, color='b')\n",
    "    plt.plot(values, kde_values, color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_resampled = df0.iloc[nearest_simulation_star_indices.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts_dict = {\"R\":[0,3.5],\"age\":[4,10]}#,\"z\":[0.5,2.2]}\n",
    "\n",
    "cumulative = True\n",
    "# cumulative = False\n",
    "\n",
    "if True: # plot age distribution\n",
    "    fig,ax=plt.subplots()\n",
    "\n",
    "    bins = 500 if cumulative else 100\n",
    "\n",
    "    ax.hist(MF.apply_cuts_to_df(df=df0, cuts_dict=cuts_dict)[\"age\"],bins=bins,label=\"Original\",density=True,cumulative=cumulative)\n",
    "    ax.hist(MF.apply_cuts_to_df(df=sim_resampled, cuts_dict=cuts_dict)[\"age\"],bins=bins,alpha=0.7,label=f\"Resampled (k={K})\",density=True,cumulative=cumulative)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Age [Gyr]\")\n",
    "    ax.set_ylabel(\"Probability density\" if not cumulative else \"Fraction\")\n",
    "\n",
    "    filename = \"age_distribution\"\n",
    "    filename += \"_cumulative\" if cumulative else \"\"\n",
    "\n",
    "    for cut_variable in cuts_dict:\n",
    "        if cut_variable != \"age\":\n",
    "            l,r = cuts_dict[cut_variable]\n",
    "            filename += f\"_{l}{cut_variable}{r}\"\n",
    "\n",
    "    if save_bool:\n",
    "        plt.savefig(save_path+filename+\".png\",dpi=150,bbox_inches=\"tight\")\n",
    "        print(\"Saved:\",save_path+filename+\".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False\n",
    "\n",
    "# density_bool = True\n",
    "density_bool = False\n",
    "bins_x = 100\n",
    "\n",
    "if True: # xy and xz views\n",
    "    fig,axs=plt.subplots(figsize=(9,11),nrows=2,gridspec_kw={\"hspace\":0})\n",
    "    c1 = MP.quick_show_xy(sim_resampled,show=False,density=density_bool,bins_x=bins_x)\n",
    "    c2 = MP.quick_show_xz(sim_resampled,show=False,zmin=0,density=density_bool,bins_x=bins_x)\n",
    "\n",
    "    norm = PH.get_norm_from_count_list([c1,c2],log=True)\n",
    "\n",
    "    MP.quick_show_xy(sim_resampled,ax=axs[0],norm=norm, density=density_bool,bins_x=bins_x)\n",
    "    MP.quick_show_xz(sim_resampled,ax=axs[1],norm=norm,zmin=0, density=density_bool,bins_x=bins_x)\n",
    "\n",
    "    cbar = plt.colorbar(cm.ScalarMappable(norm=norm,cmap=\"viridis\"),ax=axs,shrink=0.8)\n",
    "    cbar.set_label(mass_density_label) if density_bool else cbar.set_label(r\"$N$\",rotation=0,labelpad=20)\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    if True: # filename and saving\n",
    "\n",
    "        filename = f\"resampled_sim_xyxz_k{k}\"\n",
    "        filename += f\"_xbins{bins_x}\"\n",
    "        filename += \"_N\" if not density_bool else \"_density\"\n",
    "\n",
    "        print(filename)\n",
    "\n",
    "        if save_bool:\n",
    "            print(\"Saving in:\",save_path)\n",
    "\n",
    "            plt.savefig(save_path+filename+\".png\", dpi=200,bbox_inches=\"tight\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_resampled_bool = True\n",
    "\n",
    "if sim_resampled_bool:\n",
    "    df0 = sim_resampled\n",
    "    \n",
    "    del sim_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_bool = True\n",
    "data_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe\n",
    "\n",
    "if data_bool:\n",
    "    # metal_lowcut = -9999\n",
    "    metal_lowcut = -1\n",
    "\n",
    "    data_trim = data[data['FeH']>=metal_lowcut]\n",
    "\n",
    "    print(f\"Chose minimum metallicity of {metal_lowcut}\" if metal_lowcut != -9999 else \"No minimum metallicity\")\n",
    "\n",
    "    if metal_lowcut != -9999:\n",
    "        print(f\"Removed {len(data)-len(data_trim)} ({MF.return_int_or_dec((len(data)-len(data_trim))/len(data)*100,2)}%) stars. {len(data_trim)} left\")\n",
    "        \n",
    "    metallicity_median = MF.return_int_or_dec(np.median(data_trim[\"FeH\"]),2)\n",
    "    print(\"Median\",metallicity_median,np.sum(data_trim['FeH']<metallicity_median),np.sum(data_trim['FeH']>metallicity_median))\n",
    "    \n",
    "    dataframe = data_trim\n",
    "    \n",
    "else:\n",
    "    dataframe = df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_dict(dic):\n",
    "    if dic[\"error_type\"] == \"MC\" and dic[\"montecarloconfig\"] is None:\n",
    "        raise ValueError(\"The montecarloconfig was None with MC error type.\")\n",
    "    elif dic[\"error_type\"] != \"MC\" and dic[\"montecarloconfig\"] is not None:\n",
    "        raise ValueError(f\"The montecarloconfig was set with `{dic['error_type']}` error type.\")\n",
    "\n",
    "    if dic[\"montecarloconfig\"] is not None and list(dic[\"montecarloconfig\"].affected_cuts_dict.keys())[0] not in dic[\"spatial_cuts\"] | dic[\"pop_cut\"]:\n",
    "        raise ValueError(\"The affected cut in montecarloconfig is not in the spatial or pop dictionaries.\")\n",
    "        \n",
    "    if dic[\"error_type\"] == \"bootstrap\" and dic[\"bootstrapconfig\"] is None:\n",
    "        raise ValueError(\"The bootstrapconfig was None with bootstrap error type.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minmax_ranges(df,x_var,x_min,x_max,binning_type,n_points):\n",
    "    \n",
    "    if binning_type == \"equal_steps\":\n",
    "        x_edges = np.linspace(x_min,x_max,n_points+1)\n",
    "        x_range_min = x_edges[:-1]\n",
    "        x_range_max = x_edges[1:]\n",
    "        \n",
    "        pop_str = f\"{n_points}_bins\"\n",
    "        \n",
    "    elif binning_type == \"equal_N\":\n",
    "        x_edges = PH.get_equal_n_bin_edges(df[x_var], n_points)\n",
    "\n",
    "        x_range_max = x_edges[1:]\n",
    "        x_range_min = x_edges[:-1]\n",
    "        \n",
    "        pop_str = f\"{n_points}_bins\"\n",
    "\n",
    "    elif x_var == \"b\":\n",
    "        \n",
    "        if binning_type == \"equal_number_low\":\n",
    "            \n",
    "            if \"FeH\" not in df:\n",
    "                raise ValueError(\"The equal_number_low latitude binning needs the data to be passed in the df argument.\")\n",
    "           \n",
    "            low_max = np.max(df[df[x_var]<=6.8][x_var])\n",
    "            n_points_low = n_points-2 if x_max == 13 else n_points-1\n",
    "            edges_low = PH.get_equal_n_bin_edges(df[df[x_var]<=low_max][x_var], n_points_low)\n",
    "\n",
    "            high_min = np.min(df[df[x_var]>6.8][x_var])\n",
    "            high_max = np.max(df[df[x_var]<=9][x_var])\n",
    "\n",
    "            x_range_min = list(edges_low[:-1]) + [high_min]\n",
    "            x_range_max = list(edges_low[1:]) + [high_max]\n",
    "\n",
    "            if x_max == 13:\n",
    "                higher_min = np.min(df[df[x_var]>9][x_var])\n",
    "                higher_max = np.max(df[x_var])\n",
    "\n",
    "                x_range_min += [higher_min]\n",
    "                x_range_max += [higher_max]\n",
    "\n",
    "            x_range_min = np.array(x_range_min)\n",
    "            x_range_max = np.array(x_range_max)\n",
    "            \n",
    "        elif binning_type == \"custom_range\":\n",
    "\n",
    "            range_dict = {\n",
    "                '1min': [0.5,  2.5,  4,    7],\n",
    "                '1max': [2.5,  4,    6.1,  9],\n",
    "\n",
    "                '1.5min': [0.5,2.5,4,7],\n",
    "                '1.5max': [2.5,4,6.2,9],\n",
    "\n",
    "                '2min': [1,2.5,4,7.1],\n",
    "                '2max': [2.5,4,6.61,9]\n",
    "            }\n",
    "\n",
    "            if x_max==13:\n",
    "                range_dict[\"2min\"] += [10.4]\n",
    "                range_dict[\"2max\"] += [13]\n",
    "\n",
    "            x_range_min = range_dict[str(x_max)+'min']\n",
    "            x_range_max = range_dict[str(x_max)+'max']\n",
    "\n",
    "            n_points = len(x_range_min)\n",
    "        \n",
    "        pop_str = f\"{n_points}_bins\"\n",
    "    \n",
    "    elif x_var in [\"age\",\"FeH\"]:\n",
    "        \n",
    "        if binning_type == \"0to9in1_oldSplit\":\n",
    "            pop_min_range = np.array([0,4,5,6,7,8, 9,   9.5, 9.8,  9.9,   9.925, 9.95, 9.975])\n",
    "            pop_max_range = np.array([4,5,6,7,8,9, 9.5, 9.8, 10,   9.925, 9.95,  9.975, 10])\n",
    "\n",
    "        if binning_type == \"4to9in1_oldSplit\":\n",
    "            pop_min_range = np.array([4,5,6,7,8, 9,   9.5, 9.8,  9.9,   9.925, 9.95, 9.975])\n",
    "            pop_max_range = np.array([5,6,7,8,9, 9.5, 9.8, 10,   9.925, 9.95,  9.975, 10])\n",
    "\n",
    "        max_age_lim = 9\n",
    "        limit_index = np.where(pop_max_range == max_age_lim)[0][0] + 1\n",
    "        \n",
    "        pop_str = binning_type\n",
    "    \n",
    "    try:\n",
    "        return x_range_min,x_range_max,pop_str\n",
    "    except:\n",
    "        ValueError(f\"Binning type `{binning_type}` not yet implemented, at least for x_var `{x_var}`.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_bool:\n",
    "\n",
    "    all_save_dicts = [\n",
    "        {\n",
    "            \"x_var\": \"FeH\", \n",
    "            \"x_min\": -1, \n",
    "            \"x_max\": 0.61,\n",
    "            \"spatial_cuts\": {\"b\":[2,4],\"R\":[0,3.5],\"l\":[-2,2]},\n",
    "            \"pop_cut\": {\"FeH\":[-1,0.61]},\n",
    "            \"n_points\": 4,\n",
    "            \"vel_freq\": 1,\n",
    "            \"binning_type\": \"equal_N\",\n",
    "            \"error_type\": \"MC\",\n",
    "            \"montecarloconfig\": MonteCarloConfig(perturbed_var=\"d\", affected_cuts_dict={\"R\": [0,3.5]}, error_frac = 0.1)\n",
    "        },\n",
    "        {\n",
    "            \"x_var\": \"FeH\", \n",
    "            \"x_min\": -1, \n",
    "            \"x_max\": 0.61,\n",
    "            \"spatial_cuts\": {\"b\":[2,4],\"R\":[0,3.5],\"l\":[-2,2]},\n",
    "            \"pop_cut\": {\"FeH\":[-1,0.61]},\n",
    "            \"n_points\": 4,\n",
    "            \"vel_freq\": 1,\n",
    "            \"binning_type\": \"equal_N\",\n",
    "            \"error_type\": \"MC\",\n",
    "            \"montecarloconfig\": MonteCarloConfig(perturbed_var=\"d\", affected_cuts_dict={\"R\": [0,3.5]}, error_frac = 0.2)\n",
    "        },\n",
    "        {\n",
    "            \"x_var\": \"FeH\", \n",
    "            \"x_min\": -1, \n",
    "            \"x_max\": 0.61,\n",
    "            \"spatial_cuts\": {\"b\":[2,4],\"R\":[0,3.5],\"l\":[-2,2]},\n",
    "            \"pop_cut\": {\"FeH\":[-1,0.61]},\n",
    "            \"n_points\": 4,\n",
    "            \"vel_freq\": 1,\n",
    "            \"binning_type\": \"equal_N\",\n",
    "            \"error_type\": \"bootstrap\",\n",
    "            \"bootstrapconfig\": BootstrapConfig()\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data_bool:\n",
    "    \n",
    "    all_save_dicts = [\n",
    "#         {\n",
    "#             \"x_var\": \"b\", \n",
    "#             \"x_min\": 1.5, \n",
    "#             \"x_max\": 13,\n",
    "#             \"spatial_cut\": {\"b\":[1.5,13],\"d\":[6.1,10.1],\"l\":[-2,2]},\n",
    "#         },\n",
    "#         {\n",
    "#             \"x_var\": \"age\", \n",
    "#             \"x_min\": 4, \n",
    "#             \"x_max\": 10,\n",
    "#             \"spatial_cuts\": {\"b\":[2,4],\"R\":[0,3.5],\"l\":[-2,2]},\n",
    "#             \"pop_cut\": {\"age\":[4,10]},\n",
    "#             \"n_points\": 8,\n",
    "#             \"vel_freq\": 2,\n",
    "#             \"binning_type\": \"equal_steps\",\n",
    "#             \"error_type\": \"MC\",\n",
    "#             \"montecarloconfig\": MonteCarloConfig(perturbed_var=\"d\", affected_cuts_dict={\"R\": [0,3.5]}, error_frac = 0.1),\n",
    "#             \"random_resampling_N\": 6000\n",
    "#         },\n",
    "#         {\n",
    "#             \"x_var\": \"age\", \n",
    "#             \"x_min\": 4, \n",
    "#             \"x_max\": 10,\n",
    "#             \"spatial_cuts\": {\"b\":[2,4],\"R\":[0,3.5],\"l\":[-2,2]},\n",
    "#             \"pop_cut\": {\"age\":[4,10]},\n",
    "#             \"n_points\": 8,\n",
    "#             \"vel_freq\": 2,\n",
    "#             \"binning_type\": \"equal_steps\",\n",
    "#             \"error_type\": \"MC\",\n",
    "#             \"montecarloconfig\": MonteCarloConfig(perturbed_var=\"d\", affected_cuts_dict={\"R\": [0,3.5]}, error_frac = 0.2),\n",
    "#             \"random_resampling_N\": 6000\n",
    "#         },\n",
    "#         {\n",
    "#             \"x_var\": \"age\", \n",
    "#             \"x_min\": 4, \n",
    "#             \"x_max\": 10,\n",
    "#             \"spatial_cuts\": {\"b\":[2,4],\"R\":[0,3.5],\"l\":[-2,2]},\n",
    "#             \"pop_cut\": {\"age\":[4,10]},\n",
    "#             \"n_points\": 20,\n",
    "#             \"vel_freq\": 4,\n",
    "#             \"binning_type\": \"equal_steps\",\n",
    "#             \"error_type\": \"bootstrap\",\n",
    "#             \"bootstrapconfig\": BootstrapConfig(),\n",
    "#         },\n",
    "        {\n",
    "            \"x_var\": \"age\", \n",
    "            \"x_min\": 4, \n",
    "            \"x_max\": 10,\n",
    "            \"spatial_cuts\": {\"b\":[3,6],\"R\":[0,3.5],\"l\":[-2,2]},\n",
    "            \"pop_cut\": {\"age\":[4,10]},\n",
    "            \"n_points\": 10,\n",
    "            \"binning_type\": \"equal_steps\",\n",
    "            \"error_type\": \"bootstrap\",\n",
    "            \"bootstrapconfig\": BootstrapConfig(repeats=500,replacement=False,bootstrap_size=950,symmetric=False),\n",
    "        },\n",
    "        {\n",
    "            \"x_var\": \"age\", \n",
    "            \"x_min\": 4, \n",
    "            \"x_max\": 10,\n",
    "            \"spatial_cuts\": {\"b\":[3,6],\"R\":[0,3.5],\"l\":[-2,2]},\n",
    "            \"pop_cut\": {\"age\":[4,10]},\n",
    "            \"n_points\": 10,\n",
    "            \"binning_type\": \"equal_steps\",\n",
    "            \"error_type\": \"bootstrap\",\n",
    "            \"bootstrapconfig\": BootstrapConfig(repeats=500,replacement=False,bootstrap_size=850,symmetric=False),\n",
    "        },\n",
    "        {\n",
    "            \"x_var\": \"age\", \n",
    "            \"x_min\": 4, \n",
    "            \"x_max\": 10,\n",
    "            \"spatial_cuts\": {\"b\":[3,6],\"R\":[0,3.5],\"l\":[-2,2]},\n",
    "            \"pop_cut\": {\"age\":[4,10]},\n",
    "            \"n_points\": 10,\n",
    "            \"binning_type\": \"equal_steps\",\n",
    "            \"error_type\": \"bootstrap\",\n",
    "            \"bootstrapconfig\": BootstrapConfig(repeats=500,replacement=False,bootstrap_size=750,symmetric=False),\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in all_save_dicts: # set defaults & validate\n",
    "    if \"random_resampling_N\" not in d:\n",
    "        d[\"random_resampling_N\"] = None\n",
    "    if \"bootstrapconfig\" not in d:\n",
    "        d[\"bootstrapconfig\"] = None\n",
    "    if \"montecarloconfig\" not in d:\n",
    "        d[\"montecarloconfig\"] = None\n",
    "    if \"vel_freq\" not in d:\n",
    "        d[\"vel_freq\"] = None\n",
    "\n",
    "    validate_dict(d)\n",
    "\n",
    "print(\"All dictionaries passed validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_star_number = 50 if data_bool else 50\n",
    "\n",
    "velhist_bins = 50 if data_bool else 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0 # only has effect for dicts with random_resampling_N not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_arrays_bool = True\n",
    "# save_arrays_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dic in all_save_dicts:\n",
    "    \n",
    "    if True: # configure\n",
    "        x_var,x_min,x_max = dic[\"x_var\"],dic[\"x_min\"],dic[\"x_max\"]\n",
    "        spatial_dict, pop_dict = dic[\"spatial_cuts\"], dic[\"pop_cut\"]\n",
    "        n_points, vel_freq, binning_type = dic[\"n_points\"],dic[\"vel_freq\"],dic[\"binning_type\"]\n",
    "        random_resampling_N = dic[\"random_resampling_N\"]\n",
    "        error_type, montecarloconfig, bootstrapconfig = dic[\"error_type\"], dic[\"montecarloconfig\"],dic[\"bootstrapconfig\"]\n",
    "\n",
    "        all_cuts_dict = [spatial_dict, pop_dict]\n",
    "\n",
    "        if True: # x_label\n",
    "            if x_var in pos_symbols_dict:\n",
    "                x_label = pos_symbols_dict[x_var] + f\" [{pos_units_dict[x_var]}]\"\n",
    "            else:\n",
    "                if x_var == \"age\":\n",
    "                    x_label = \"Age [Gyr]\"\n",
    "                elif x_var == \"FeH\":\n",
    "                    x_label = \"[Fe/H]\"\n",
    "                else:\n",
    "                    raise ValueError(\"x_label not defined for the chosen variable\")\n",
    "\n",
    "        df_val = MF.apply_cuts_to_df(dataframe, cuts_dict=all_cuts_dict)\n",
    "\n",
    "        if random_resampling_N is not None:\n",
    "            np.random.seed(random_seed)\n",
    "            df_val = df_val.iloc[np.random.choice(np.arange(len(df_val)), size=random_resampling_N, replace=False)]\n",
    "\n",
    "        range_min,range_max,pop_str = get_minmax_ranges(df_val,x_var,x_min=x_min,x_max=x_max,binning_type=binning_type,n_points=n_points)\n",
    "\n",
    "        # Saving the median because upon plotting we can always compute the mean but for the median we need the dataframe\n",
    "        range_plot = PH.get_range_medians(df_val[x_var], range_min, range_max)\n",
    "\n",
    "        print(f\"Spatial cuts:\",spatial_dict)\n",
    "        if error_type == \"MC\":\n",
    "            print(f\"Post-MC cuts:\",montecarloconfig.affected_cuts_dict)\n",
    "        print(f\"Pop cuts:\",pop_dict)\n",
    "        if random_resampling_N is not None:\n",
    "            print(f\"Random resampling to {random_resampling_N} stars\")\n",
    "        print(f\"{len(df_val)} total stars\")\n",
    "        print(f\"range_min: {range_min}\")\n",
    "        print(f\"range_max: {range_max}\")\n",
    "        print(f\"range_plot: {range_plot}\")\n",
    "        print(\"Star numbers:\",stat.binned_statistic(values=None,x=df_val[x_var].values,bins=np.union1d(range_min,range_max),statistic=\"count\")[0])\n",
    "\n",
    "        save_path_spatial = get_save_path_spatial_cuts(single_variable=x_var,spatial_cuts_dict=spatial_dict)\n",
    "\n",
    "        if data_bool:\n",
    "            save_path_pop = get_save_path_data(save_path_spatial,metal_lims=pop_dict[\"FeH\"],metal_lowcut=metal_lowcut)\n",
    "        else:\n",
    "            save_path_pop = get_save_path_sim(save_path_spatial,sim_choice=sim_choice,age_lims=pop_dict[\"age\"],bar_angle=rot_angle,\\\n",
    "                                              resampled_likedata_bool=sim_resampled_likedata_bool,random_resampling_N=random_resampling_N,random_seed=random_seed)\n",
    "\n",
    "        save_path,save_path_binning = get_save_path_final(save_path_pop, binning_str=binning_type,pop_str=pop_str, error_type=error_type,error_repeat=error_repeat,\\\n",
    "                                                          montecarloconfig=montecarloconfig, bootstrapconfig=bootstrapconfig)\n",
    "\n",
    "        print(\"save_path:\",save_path)\n",
    "        \n",
    "        if not os.path.isfile(save_path_binning+f\"chosenRanges_{str(n_points*5)}bins.png\"):\n",
    "            MP.visualise_1D_binning(df_val[x_var],range_min,bin_edges_max=range_max,save_bool=True,save_path=save_path_binning,xlabel=x_label,log=False,\\\n",
    "                                   hist_bins=n_points*5)\n",
    "\n",
    "        if not data_bool and not os.path.isfile(save_path_binning+f\"chosenRanges_log_{str(n_points*5)}bins.png\"):\n",
    "            MP.visualise_1D_binning(df_val[x_var],range_min,bin_edges_max=range_max,save_bool=True,save_path=save_path_binning,xlabel=x_label,log=True,\\\n",
    "                                   hist_bins=n_points*5)\n",
    "\n",
    "        if d[\"vel_freq\"] is not None:\n",
    "            save_path_hist = save_path_binning + \"vel_histograms/\"\n",
    "            MF.create_dir(save_path_hist)\n",
    "\n",
    "            save_path_hist += f\"{velhist_bins}bins/\"\n",
    "            MF.create_dir(save_path_hist)\n",
    "\n",
    "            print(\"Saving velocity histograms on\\n\",save_path_hist)\n",
    "\n",
    "        df_err = None if error_type != \"MC\" else MF.apply_cuts_to_df(df=dataframe, cuts_dict=montecarloconfig.clean_value_cuts_dict(cuts_dict=all_cuts_dict))\n",
    "\n",
    "    if True: # get arrays\n",
    "        map_dict = {}\n",
    "\n",
    "        for map_string in full_map_string_list:\n",
    "            map_dict[map_string] = np.zeros(shape=(len(range_min)))\n",
    "\n",
    "        for x_index, (xmin, xmax) in enumerate(zip(range_min,range_max)):\n",
    "\n",
    "            print(xmin,xmax,end=\";  \")\n",
    "\n",
    "            include_lims = \"both\" if x_index==len(range_min)-1 else \"min\"\n",
    "            x_lims_dict = {x_var:include_lims}\n",
    "            x_cut_dict = {x_var:[xmin,xmax]}\n",
    "\n",
    "            df_val_x = MF.apply_cuts_to_df(df_val, cuts_dict=x_cut_dict, lims_dict=x_lims_dict)\n",
    "\n",
    "            if vel_freq is not None and x_index % vel_freq == 0:\n",
    "                name_suffix = f\"{str(MF.return_int_or_dec(xmin,dec=2))}{x_var}{str(MF.return_int_or_dec(xmax,dec=2))}\"\n",
    "                MP.plot_velocity_histograms_both_stats(df_val_x,vel_x_variable,vel_y_variable,save_bool=True,save_path=save_path_hist,suffix=name_suffix,verbose=False,bins=velhist_bins)\n",
    "            \n",
    "            if error_type == \"MC\":\n",
    "                MC_config = copy.deepcopy(montecarloconfig)\n",
    "                \n",
    "                if random_resampling_N is not None:\n",
    "                    MC_config.random_resampling_indices = df_val_x.index\n",
    "\n",
    "                if x_var in MC_config.affected_cuts_dict:\n",
    "                    MC_config.affected_cuts_dict[x_var] = x_cut_dict[x_var] # overwrite it using the more stringent cut\n",
    "                    MC_config.affected_cuts_lims_dict[x_var] = x_lims_dict[x_var]\n",
    "\n",
    "                    df_err_x = df_err # cut on x will be applied when performing the MC\n",
    "                else:\n",
    "                    df_err_x = MF.apply_cuts_to_df(df_err, cuts_dict=x_cut_dict, lims_dict=x_lims_dict)\n",
    "            else:\n",
    "                MC_config,df_err_x = None,None\n",
    "\n",
    "            values = val_err.get_all_variable_values_and_errors(df_vals=df_val_x,df_errors=df_err_x,vel_x_var=vel_x_variable,vel_y_var=vel_y_variable,\\\n",
    "                                                                min_number = min_star_number, full_map_string_list=full_map_string_list,\\\n",
    "                                                                error_type=error_type, montecarloconfig=MC_config, bootstrapconfig=bootstrapconfig)\n",
    "\n",
    "            if len(values) != len(full_map_string_list):\n",
    "                raise ValueError(\"The length of the values list does not match the string list!\")\n",
    "\n",
    "            for map_string in full_map_string_list:\n",
    "                map_dict[map_string][x_index] = values[map_string]\n",
    "\n",
    "        print(\"Done computing map_dict\")\n",
    "        \n",
    "    if True: # quick plot correlation\n",
    "        x_plot = PH.get_range_means(minima=range_min,maxima=range_max) if not data_bool else PH.get_range_medians(df_val[x_var], range_min, range_max)\n",
    "\n",
    "        fig,ax=plt.subplots(figsize=(5,5))\n",
    "        ax.errorbar(x=x_plot, y=map_dict[\"correlation\"],yerr=[map_dict[\"correlation_error_low\"],map_dict[\"correlation_error_high\"]],capsize=5)\n",
    "        if not data_bool:\n",
    "            ax.invert_xaxis()\n",
    "        plt.show()\n",
    "\n",
    "    if save_arrays_bool:\n",
    "\n",
    "        array_path = save_path + \"arrays/\"\n",
    "\n",
    "        overwrite = False\n",
    "        if os.path.isdir(array_path):\n",
    "            overwrite_str = input(\"There may be files already in this folder, do you want to overwrite them? Y/N\\n\")\n",
    "            if overwrite_str.upper() == \"Y\":\n",
    "                overwrite = True\n",
    "        else:\n",
    "            MF.create_dir(array_path)\n",
    "            overwrite = True\n",
    "\n",
    "        if overwrite:\n",
    "\n",
    "            if True: # values as .txt and .npy\n",
    "\n",
    "                with open(array_path+'values.txt','w') as f:\n",
    "                    for key in map_dict:\n",
    "                        f.write(key+'\\n')\n",
    "                        np.savetxt(f,map_dict[key],fmt='%.5f')\n",
    "                        f.write('\\n')\n",
    "\n",
    "                for map_string in full_map_string_list:\n",
    "                    np.save(array_path+map_string, map_dict[map_string])\n",
    "\n",
    "            if True: # plot limits as .txt and .npy\n",
    "\n",
    "                with open(array_path+'x_ranges.txt','w') as f:\n",
    "                    f.write(\"x_range_min\\n\")\n",
    "                    for mini in range_min:\n",
    "                        f.write(f\"{mini}\\t\")\n",
    "                    f.write(\"\\n\\nx_range_max\\n\")\n",
    "                    for maxi in range_max:\n",
    "                        f.write(f\"{maxi}\\t\")\n",
    "                    f.write(\"\\n\\nx_range_plot\\n\")\n",
    "                    for p in range_plot:\n",
    "                        f.write(f\"{p}\\t\")\n",
    "\n",
    "                np.save(array_path+\"x_range_min\", range_min)\n",
    "                np.save(array_path+\"x_range_max\", range_max)\n",
    "                np.save(array_path+\"x_range_plot\", range_plot)\n",
    "\n",
    "            print(\"Saved .txt and .npy in\",array_path)\n",
    "    else:\n",
    "        print(\"Not saving\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = \"b\"\n",
    "\n",
    "x_min = 1\n",
    "x_max = 13\n",
    "\n",
    "if True: # x_label\n",
    "    if x_var in pos_symbols_dict:\n",
    "        x_label = pos_symbols_dict[x_var] + f\" [{pos_units_dict[x_var]}]\"\n",
    "    else:\n",
    "        if x_var == \"age\":\n",
    "            x_label = \"Age [Gyr]\"\n",
    "        elif x_var == \"FeH\":\n",
    "            x_label = \"[Fe/H]\"\n",
    "        else:\n",
    "            raise ValueError(\"x_label not defined for the chosen variable\")\n",
    "    \n",
    "MP.show_text(x_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_cuts_dict = {}\n",
    "\n",
    "if x_var in pos_symbols_dict:\n",
    "    spatial_cuts_dict[x_var] = [x_min,x_max]\n",
    "\n",
    "spatial_cuts_dict[\"R\"] = [0,2.5]\n",
    "spatial_cuts_dict[\"l\"] = [-2,2]\n",
    "\n",
    "for variable in spatial_cuts_dict:\n",
    "    print(variable, spatial_cuts_dict[variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_spatial = get_save_path_spatial_cuts(single_variable=x_var,cuts_dict=spatial_cuts_dict)\n",
    "\n",
    "print(save_path_spatial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age_lims = [4,7]\n",
    "age_lims = [9.5,10]\n",
    "\n",
    "df = MF.apply_cuts_to_df(df=df0,cuts_dict=[spatial_cuts_dict,{\"age\":age_lims}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_steps = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if equal_steps:\n",
    "    if x_var == \"b\":\n",
    "        n_edges = 7 if x_max == 9 else 8\n",
    "        n_points = n_edges - 1\n",
    "    else:\n",
    "        raise ValueError(f\"Number of points not implemented for {x_var} yet.\")\n",
    "\n",
    "    x_edges = np.linspace(x_min,x_max,n_edges)\n",
    "\n",
    "    x_range_min = x_edges[:-1]\n",
    "    x_range_max = x_edges[1:]\n",
    "    \n",
    "    binning_str = \"equal_steps\"\n",
    "    pop_str = f\"{n_points}_bins\"\n",
    "    \n",
    "# Saving the median because upon plotting we can always compute the mean but for the median we need the dataframe\n",
    "x_range_plot = PH.get_range_medians(df[x_var], x_range_min, x_range_max)\n",
    "\n",
    "print(\"Plotting at:\",x_range_plot)\n",
    "print(\"Number of datapoints:\",n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(10,2))\n",
    "\n",
    "ax.errorbar(x=x_range_plot,xerr=PH.get_xerr(minima=x_range_min,maxima=x_range_max,plot=x_range_plot,frac=1),y=[0]*n_points,fmt=\"d\",capsize=20)\n",
    "ax.set_xlim(x_min-(x_max-x_min)/30,x_max+(x_max-x_min)/30)\n",
    "ax.minorticks_on()\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of stars per bin\n",
    "stat.binned_statistic(values=None,x=df[x_var].values,bins=x_edges,statistic=\"count\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = get_save_path_sim(save_path_spatial, bar_angle=rot_angle,resampled_sim_bool=sim_resampled_bool, age_lims=age_lims,\\\n",
    "                              binning_str=binning_str, pop_str=pop_str)\n",
    "\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metal_lowcut = -9999\n",
    "metal_lowcut = -1\n",
    "\n",
    "data_trim = data[data['FeH']>=metal_lowcut]\n",
    "\n",
    "print(f\"Chose minimum metallicity of {metal_lowcut}\" if metal_lowcut != -9999 else \"No minimum metallicity\")\n",
    "\n",
    "if metal_lowcut != -9999:\n",
    "    print(f\"Removed {len(data)-len(data_trim)} ({MF.return_int_or_dec((len(data)-len(data_trim))/len(data)*100,2)}%) stars. {len(data_trim)} left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metallicity_median = MF.return_int_or_dec(np.median(data_trim[\"FeH\"]),2)\n",
    "print(metallicity_median,np.sum(data_trim['FeH']<metallicity_median),np.sum(data_trim['FeH']>metallicity_median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metal_lims = [min(data_trim[\"FeH\"]), metallicity_median]\n",
    "# metal_lims = [metallicity_median, max(data_trim[\"FeH\"])]\n",
    "\n",
    "df = MF.apply_cuts_to_df(df=data_trim,cuts_dict=[spatial_cuts_dict,{\"FeH\":metal_lims}])\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "alpha=0.7\n",
    "xmin = data_trim[x_var].min()\n",
    "xmax = data_trim[x_var].max()\n",
    "bins = np.linspace(xmin,xmax,50)\n",
    "\n",
    "ax.hist(data_trim[x_var],bins=bins,label=fr'${str(MF.return_int_or_dec(min(data_trim[\"FeH\"]),2))}\\leq$[Fe/H]$\\leq{str(MF.return_int_or_dec(max(data_trim[\"FeH\"]),2))}$',\\\n",
    "        alpha=alpha,color='grey')\n",
    "\n",
    "if len(data_trim) != len(df):\n",
    "    ax.hist(df[x_var],bins=bins,label=fr'${str(MF.return_int_or_dec(metal_lims[0],2))}\\leq$[Fe/H]$\\leq{str(MF.return_int_or_dec(metal_lims[1],2))}$',\\\n",
    "            alpha=alpha,color='orange')\n",
    "\n",
    "ax.set_xlim(xmin,xmax)\n",
    "ax.axvline(x_min,color=\"orange\");ax.axvline(x_max,color=\"orange\")\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(r\"$N$\",rotation=0,labelpad=20)\n",
    "ax.legend()\n",
    "\n",
    "plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(20,5))\n",
    "ax.hist(df[x_var],bins=500)\n",
    "ticksss = np.arange(x_min,x_max,0.2)\n",
    "ax.set_xticks(ticksss)\n",
    "ax.set_xticklabels(labels=[str(np.float32(t)) for t in ticksss],size=8)\n",
    "ax.set_xlabel(x_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_number = False # divide in equal-number bins across all b\n",
    "equal_number_low = True # divide in equal-number bins below |b|<6.61Ë\n",
    "custom_range = False\n",
    "equal_steps = False # divide in constant latitude steps\n",
    "\n",
    "plot_median_bool = True\n",
    "# plot_median_bool = False # mid-point of bin\n",
    "\n",
    "if x_var == \"b\":\n",
    "    n_points = 3\n",
    "    n_points += 1 if x_max == 13 else 0\n",
    "else:\n",
    "    raise ValueError(f\"Number of points not implemented for {x_var} yet.\")\n",
    "\n",
    "print(f\"{n_points} total points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert equal_number+equal_number_low+custom_range+equal_steps == 1, \"Choose a single range selection\"\n",
    "\n",
    "if x_var == \"b\":\n",
    "    if equal_number:\n",
    "        x_edges = PH.get_equal_n_bin_edges(df[x_var], n_points)\n",
    "\n",
    "        x_range_max = x_edges[1:]\n",
    "        x_range_min = x_edges[:-1]\n",
    "\n",
    "        range_path = \"\"\n",
    "    if equal_number_low:\n",
    "        low_max = np.max(df[df[x_var]<6.8][x_var])\n",
    "        n_points_low = n_points-2 if x_max == 13 else n_points-1\n",
    "        edges_low = PH.get_equal_n_bin_edges(df[df[x_var]<=low_max][x_var], n_points_low)\n",
    "\n",
    "    #     print(edges_low)\n",
    "\n",
    "        high_min = np.min(df[df[x_var]>6.8][x_var])\n",
    "        high_max = np.max(df[df[x_var]<9][x_var])\n",
    "\n",
    "        x_range_min = list(edges_low[:-1]) + [high_min]\n",
    "        x_range_max = list(edges_low[1:]) + [high_max]\n",
    "\n",
    "    #     print(x_range_min,x_range_max)\n",
    "\n",
    "        if x_max == 13:\n",
    "            higher_min = np.min(df[df[x_var]>9][x_var])\n",
    "            higher_max = np.max(df[x_var])\n",
    "\n",
    "            x_range_min += [higher_min]\n",
    "            x_range_max += [higher_max]\n",
    "\n",
    "        x_range_min = np.array(x_range_min)\n",
    "        x_range_max = np.array(x_range_max)\n",
    "    elif custom_range:\n",
    "        range_dict = {\n",
    "            '1min': [0.5,  2.5,  4,    7],\n",
    "            '1max': [2.5,  4,    6.1,  9],\n",
    "\n",
    "            '1.5min': [0.5,2.5,4,7],\n",
    "            '1.5max': [2.5,4,6.2,9],\n",
    "\n",
    "            '2min': [1,2.5,4,7.1],\n",
    "            '2max': [2.5,4,6.61,9]\n",
    "        }\n",
    "\n",
    "        if x_max==13:\n",
    "            range_dict[\"2min\"] += [10.4]\n",
    "            range_dict[\"2max\"] += [13]\n",
    "\n",
    "        x_range_min = range_dict[str(lmax)+'min']\n",
    "        x_range_max = range_dict[str(lmax)+'max']\n",
    "\n",
    "        n_points = len(x_range_plot)    \n",
    "    elif equal_steps:\n",
    "        x_edges = np.linspace(x_min,x_max,n_points)\n",
    "        x_range_min = x_edges[:-1]\n",
    "        x_range_max = x_edges[1:]\n",
    "else:\n",
    "    raise ValueError(f\"Binning not implemented for {x_var} yet.\")\n",
    "\n",
    "# Saving the median because upon plotting we can always compute the mean but for the median we need the dataframe\n",
    "x_range_plot = PH.get_range_medians(df[x_var], x_range_min, x_range_max)\n",
    "\n",
    "binning_str = np.array([\"equal_number\",\"equal_number_low\",\"custom_range\",\"equal_steps\"])[np.array([equal_number,equal_number_low,custom_range,equal_steps])][0]\n",
    "pop_str = f\"{n_points}_bins\"\n",
    "\n",
    "print(\"Plotting at:\",x_range_plot,\"\\n\")\n",
    "print(f\"{n_points} datapoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = get_save_path_data(save_path_spatial, metal_lowcut, metal_lims, binning_str, pop_str)\n",
    "\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_bool = True\n",
    "save_bool = False\n",
    "\n",
    "if True: # visualise bulge cut\n",
    "    \n",
    "    fig,axs=plt.subplots(figsize=(15,10),nrows=2,sharex=True,gridspec_kw={\"hspace\":-0.43})\n",
    "    \n",
    "    MP.visualise_bulge_selection(given_axs=axs,cuts_dict=spatial_cuts_dict,y_max_plot=3)\n",
    "\n",
    "#     MP.plot_circle(radius=2.5,ax=axs[0],linestyle=\"--\",label=r\"$R_\\mathrm{GC}\\leq2.5$ kpc\")\n",
    "#     axs[1].axvline(-2.5,color=\"k\",linestyle=\"--\")\n",
    "#     axs[1].axvline(2.5,color=\"k\",linestyle=\"--\")\n",
    "\n",
    "    if data_bool:\n",
    "        axs[0].scatter(df[\"x\"],df[\"y\"],color=\"grey\",s=1)\n",
    "        axs[1].scatter(df[\"x\"],df[\"z\"],color=\"grey\",s=1)\n",
    "    else:\n",
    "        MP.quick_show_xy(df=df,axs=axs[0])\n",
    "        MP.quick_show_xz(df=df,axs=axs[1])\n",
    "    \n",
    "    if x_var in units_dict and units_dict[x_var] in [\"$^\\circ$\",\"deg\"]:\n",
    "        for m,M in zip(x_range_min,x_range_max):\n",
    "            MP.plot_angled_line(axs[1 if x_var == \"b\" else 0],xmin=-R0,ymin=0,xmax=4,angle=m,color=\"red\",linestyle=\"--\")\n",
    "            MP.plot_angled_line(axs[1 if x_var == \"b\" else 0],xmin=-R0,ymin=0,xmax=4,angle=M,color=\"blue\",linestyle=\"--\")\n",
    "\n",
    "    _ = [ax.legend(fontsize=\"x-small\") for ax in axs]\n",
    "    \n",
    "#     fig.delaxes(axs[0])\n",
    "    \n",
    "    axs[1].set_xlim(-R0-0.1)\n",
    "\n",
    "    filename = \"illustrate_cuts\"\n",
    "    print(filename)\n",
    "    if save_bool:\n",
    "        print(\"Saving in:\",save_path)\n",
    "        plt.savefig(save_path+filename+\".png\",dpi=200,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MP.visualise_1D_binning(df[x_var],x_range_min,bin_edges_max=x_range_max,save_bool=True,save_path=save_path,xlabel=x_label,log=False,\\\n",
    "                       hist_bins=400 if not data_bool else 100)\n",
    "\n",
    "if not data_bool:\n",
    "    MP.visualise_1D_binning(df[x_var],x_range_min,bin_edges_max=x_range_max,save_bool=True,save_path=save_path,xlabel=x_label,log=True,\\\n",
    "                           hist_bins=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_hist_bool = True\n",
    "# vel_hist_bool = False\n",
    "\n",
    "velhist_bins = 100 if not data_bool else 50\n",
    "\n",
    "if vel_hist_bool:\n",
    "    save_path_hist = save_path + \"vel_histograms/\"\n",
    "    MF.create_dir(save_path_hist)\n",
    "    \n",
    "    save_path_hist += f\"{velhist_bins}bins/\"\n",
    "    MF.create_dir(save_path_hist)\n",
    "    \n",
    "    print(\"Saving velocity histograms on\\n\",save_path_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # example vel hist\n",
    "    MP.plot_velocity_histograms_both_stats(df[(df[x_var]>=min(x_range_min))&(df[x_var]<=min(x_range_max))],vel_x_variable,vel_y_variable,\\\n",
    "                                               bins=velhist_bins,colour_var=\"x\",save_bool=False,suffix=\"example\",verbose=True,show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_repeat = 500\n",
    "\n",
    "min_star_number = 100 if not data_bool else 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = {}\n",
    "for map_string in full_map_string_list:\n",
    "    map_dict[map_string] = np.zeros(shape=(len(x_range_min)))\n",
    "\n",
    "for x_index, (xmin, xmax) in enumerate(zip(x_range_min,x_range_max)):\n",
    "\n",
    "    print(xmin,xmax)\n",
    "    \n",
    "    include_lims = \"both\" if x_index==len(x_range_min)-1 else \"min\"\n",
    "    df_x = MF.apply_cuts_to_df(df, cuts_dict={x_var:[xmin,xmax]}, lims_dict={x_var:include_lims})\n",
    "\n",
    "    if vel_hist_bool:\n",
    "        name_suffix = f\"{str(MF.return_int_or_dec(xmin,dec=2))}{x_var}{str(MF.return_int_or_dec(xmax,dec=2))}\"\n",
    "        MP.plot_velocity_histograms_both_stats(df_x,vel_x_variable,vel_y_variable,save_bool=True,save_path=save_path_hist,suffix=name_suffix,verbose=x_index==0,bins=velhist_bins)\n",
    "\n",
    "    values = val_err.get_all_variable_values_and_errors(df_x[f\"v{vel_x_variable}\"].values,df_x[f\"v{vel_y_variable}\"].values, full_map_string_list,\\\n",
    "                                                            repeat=bootstrap_repeat, min_number = min_star_number)   \n",
    "\n",
    "    if len(values) != len(full_map_string_list):\n",
    "        raise ValueError(\"The length of the values list does not match the string list!\")\n",
    "\n",
    "    for map_string in full_map_string_list:\n",
    "        map_dict[map_string][x_index] = values[map_string]\n",
    "    \n",
    "del df,df_x\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict[\"number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save arrays\n",
    "\n",
    "array_path = save_path + \"arrays/\"\n",
    "MF.create_dir(array_path)\n",
    "\n",
    "if True: # values as .txt and .npy\n",
    "            \n",
    "    with open(array_path+'values.txt','w') as f:\n",
    "        for key in map_dict:\n",
    "            f.write(key+'\\n')\n",
    "            np.savetxt(f,map_dict[key],fmt='%.5f')\n",
    "            f.write('\\n')\n",
    "    \n",
    "    for map_string in full_map_string_list:\n",
    "        np.save(array_path+map_string, map_dict[map_string])\n",
    "        \n",
    "if True: # plot limits as .txt and .npy\n",
    "\n",
    "    with open(array_path+'x_ranges.txt','w') as f:\n",
    "        f.write(\"x_range_min\\n\")\n",
    "        for mini in x_range_min:\n",
    "            f.write(f\"{mini}\\t\")\n",
    "        f.write(\"\\n\\nx_range_max\\n\")\n",
    "        for maxi in x_range_max:\n",
    "            f.write(f\"{maxi}\\t\")\n",
    "        f.write(\"\\n\\nx_range_plot\\n\")\n",
    "        for p in x_range_plot:\n",
    "            f.write(f\"{p}\\t\")\n",
    "    \n",
    "    np.save(array_path+\"x_range_min\", x_range_min)\n",
    "    np.save(array_path+\"x_range_max\", x_range_max)\n",
    "    np.save(array_path+\"x_range_plot\", x_range_plot)\n",
    "    \n",
    "print(\"Saved .txt and .npy in\",array_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With distance division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_range = np.linspace(dmin,dmax,5)[:-1]\n",
    "d_step = np.diff(d_range)[0]\n",
    "\n",
    "# d_range = [6]\n",
    "# d_step = 4\n",
    "\n",
    "print(d_range,d_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_arrays = np.zeros(shape=(7,len(b_range),len(df_ages)))\n",
    "variables = [\"vertex_abs\", \"anisotropy\", \"correlation\"]\n",
    " \n",
    "for b_index,latitude in enumerate(b_range):\n",
    "    for age_index,df in enumerate(df_ages):\n",
    "        df_b = df[(df['b']>latitude)&(df['b']<latitude+b_step)]\n",
    "        df_b = df[(df['b']>latitude)&(df['b']<latitude+b_step)]\n",
    "        \n",
    "        values_d = []\n",
    "        for d_index, distance in enumerate(d_range):\n",
    "            vr = df_b[(df_b['d']>distance)&(df_b['d']<distance+d_step)].vr.values\n",
    "            vl = df_b[(df_b['d']>distance)&(df_b['d']<distance+d_step)].vl.values\n",
    "\n",
    "            values_d.append(get_all_variable_values_and_errors(vr,vl,bootstrap_repeat=100,min_number=min_number_sim))\n",
    "        \n",
    "        values_d = np.array(values_d)\n",
    "        values = []\n",
    "        \n",
    "        for var in variables:\n",
    "            val_index = np.where(full_map_string_list == var)[0][0]\n",
    "            err_index = np.where(full_map_string_list == (var+\"_error\"))[0][0]\n",
    "            \n",
    "            mean_variance = 1/np.sum(1/values_d[:,err_index]**2)\n",
    "            mean = mean_variance*np.sum(values_d[:,val_index]/values_d[:,err_index]**2)\n",
    "            values.append(mean)\n",
    "            values.append(np.sqrt(mean_variance))\n",
    "                \n",
    "        for index, val in enumerate(values):\n",
    "            all_arrays[index, b_index, age_index] = val\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_d_variables = []\n",
    "for i in variables:\n",
    "    full_d_variables.append(i)\n",
    "    full_d_variables.append(i+'_error')\n",
    "\n",
    "d_map_dict = {}\n",
    "for variable, array in zip(full_d_variables,all_arrays):\n",
    "    d_map_dict[variable] = array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'vertex_abs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "if var == 'vertex_abs':\n",
    "    ax.set_ylim(-45,45)\n",
    "else:\n",
    "    max_val = np.max(np.abs(map_dict[var])) + 0.05\n",
    "#     ax.set_ylim(-max_val,max_val)\n",
    "    ax.set_ylim(-0.7,0.5)\n",
    "ax.fill_between(x=b_range_plot,y1=map_dict[var][:,0]-map_dict[var+'_error'][:,0],y2=map_dict[var][:,0]+map_dict[var+'_error'][:,0],color='blue',alpha=0.6,label='Young')\n",
    "ax.fill_between(x=b_range_plot,y1=map_dict[var][:,1]-map_dict[var+'_error'][:,1],y2=map_dict[var][:,1]+map_dict[var+'_error'][:,1],color='red',alpha=0.6,label='Old')\n",
    "ax.axhline(y=0,color='black',linestyle='dotted')\n",
    "ax.set_title(var)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save_path_arrays = save_path + \"arrays/\"\n",
    "if not os.path.isdir(save_path_arrays):\n",
    "    os.mkdir(save_path_arrays)\n",
    "    \n",
    "    for map_string in full_map_string_list:\n",
    "        np.save(save_path_arrays+\"708main_\"+map_string, map_dict[map_string])\n",
    "    print(\"Arrays saved in\",save_path_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BT repeat\n",
    "The standard deviation is the deviation from the mean. We are not calculating the vertex deviation's standard deviation from the mean bootstrap vertex, but from the true vertex instead.\n",
    "Therefore, let's analyse how much these two values, $l_\\mathrm{v}$ and $\\langle l_{\\mathrm{v}}^\\mathrm{bootstrap}\\rangle$, differ for different choices of bootstrap repetitions.\n",
    "\n",
    "To run the code below, you first have to change the definition of get_std_bootstrap() and get_vertex_std_bootstrap() so that they return the list of bootstrap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_number = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_repeats = np.array([100,500,1000,5000,10000,50000])\n",
    "ani_diff,corr_diff,vertex_diff = [[] for repeat in bootstrap_repeats],[[] for repeat in bootstrap_repeats],[[] for repeat in bootstrap_repeats]\n",
    "\n",
    "df = df_ages[1] ###\n",
    "for b_index,latitude in enumerate(b_range):\n",
    "    start = time.time()\n",
    "    #for age_index,df in enumerate(df_ages):\n",
    "    \n",
    "    vr = df[(df['b']>latitude)&(df['b']<latitude+b_step)].vr.values\n",
    "    vl = df[(df['b']>latitude)&(df['b']<latitude+b_step)].vl.values\n",
    "\n",
    "    number = len(vr)\n",
    "\n",
    "    if number > min_number:\n",
    "\n",
    "        cov = np.cov(vr,vl)\n",
    "\n",
    "        true_anisotropy = 1-cov[1,1]/cov[0,0]\n",
    "        true_correlation = cov[0,1]/np.sqrt(cov[0,0]*cov[1,1])\n",
    "        true_vertex = np.degrees(np.arctan2(2.*cov[0,1], cov[0,0]-cov[1,1])/2.)\n",
    "\n",
    "        for repeat_index, bootstrap_repeat in enumerate(bootstrap_repeats):\n",
    "\n",
    "            anisotropy_boot_values,_ = get_std_bootstrap(vr,vl,calculate_anisotropy,repeat=bootstrap_repeat)\n",
    "            correlation_boot_values,_ = get_std_bootstrap(vr,vl,calculate_correlation,repeat=bootstrap_repeat)\n",
    "            vertex_boot_values,_ = get_vertex_std_bootstrap(vr, vl, repeat=bootstrap_repeat)\n",
    "\n",
    "            ani_diff[repeat_index].append(np.abs(true_anisotropy-np.mean(anisotropy_boot_values)))\n",
    "            corr_diff[repeat_index].append(np.abs(true_correlation-np.mean(correlation_boot_values)))\n",
    "            vertex_diff[repeat_index].append(np.abs(true_vertex-np.mean(vertex_boot_values)))\n",
    "\n",
    "            print(\"Done with repeat\",bootstrap_repeat)\n",
    "                \n",
    "    print(\"Done with latitude index\",b_index)\n",
    "    end = time.time()\n",
    "    print(\"Took\",(end-start)/60,\"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_variable = \"vertex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs_dict = {\n",
    "    \"anisotropy\": ani_diff,\n",
    "    \"correlation\": corr_diff,\n",
    "    \"vertex\": vertex_diff\n",
    "}\n",
    "\n",
    "ylabel_dict = {\n",
    "    \"anisotropy\": r\"abs($a_{rl} - \\langle a_{rl}^{\\mathrm{bootstrap}} \\rangle$)\",\n",
    "    \"correlation\": r\"abs($\\rho_{rl}-\\langle \\rho_{rl}^{\\mathrm{bootstrap}} \\rangle$)\",\n",
    "    \"vertex\": r\"abs($l_\\mathrm{v}-\\langle l_{\\mathrm{v}}^{\\mathrm{bootstrap}} \\rangle$) [Â°]\"\n",
    "}\n",
    "\n",
    "diffs = diffs_dict[diff_variable]\n",
    "ylabel = ylabel_dict[diff_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for diff_variable in [\"anisotropy\",\"correlation\",\"vertex\"]:\n",
    "    \n",
    "    diffs = diffs_dict[diff_variable]\n",
    "    ylabel = ylabel_dict[diff_variable]\n",
    "    \n",
    "    diffs_mean = [np.mean(np.abs(array)) for array in diffs]\n",
    "    diffs_95_percentile = [np.percentile(np.abs(array),95) for array in diffs]\n",
    "    diffs_max = [np.max(np.abs(array)) for array in diffs]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    bar_width = 0.1\n",
    "    transparency = 0.6\n",
    "\n",
    "    x_ticks = np.arange(len(bootstrap_repeats))+1\n",
    "    x_ticklabels = [str(repeat) for repeat in bootstrap_repeats]\n",
    "\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels(x_ticklabels)\n",
    "\n",
    "    ax.bar(x_ticks-bar_width,diffs_mean, width=bar_width, label=\"Mean\",alpha=transparency,color='blue')\n",
    "    ax.bar(x_ticks,diffs_95_percentile, width=bar_width, label=\"95 percentile\",alpha=transparency,color='red')\n",
    "    ax.bar(x_ticks+bar_width,diffs_max, width=bar_width, label=\"Maximum\",alpha=transparency,color='green')\n",
    "\n",
    "    linewidth = 0.5\n",
    "    for index in range(len(bootstrap_repeats)):\n",
    "        ax.hlines(diffs_mean[index], xmin=0, xmax=x_ticks[index]-bar_width, color='blue',linestyle='-',lw=linewidth)\n",
    "        ax.hlines(diffs_95_percentile[index], xmin=0, xmax=x_ticks[index], color='red',linestyle='-',lw=linewidth)\n",
    "        ax.hlines(diffs_max[index], xmin=0, xmax=x_ticks[index]+bar_width, color='green',linestyle='-',lw=linewidth)\n",
    "\n",
    "    #ax.legend(bbox_to_anchor=[0.535,0.8])\n",
    "    ax.set_xlabel(\"Bootstrap repeats\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    #ax.set_yticks(np.arange(0,15))\n",
    "    #ax.set_xticks([100,500,1000])\n",
    "    ax.set_xlim(0.75,x_ticks[-1]+0.25)\n",
    "    #ax.set_ylim(0,13)\n",
    "\n",
    "    #ax.set_aspect(50)\n",
    "    filename = f\"old_{bootstrap_repeats[-1]}_{diff_variable}\"\n",
    "    plt.savefig(general_path+\"bootstrap_repeats/\"+filename+\".png\",bbox_inches='tight',dpi=150)\n",
    "    print(\"Saved:\",filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number_bar(barax, plot_range, number_array,color,fill_bool=True,alpha=1,zorder=0, bar_width=50,bar_log=True,show_hist=False):\n",
    "    if show_hist:\n",
    "        # needs passing df\n",
    "        barax.hist(df[x_var].values,bins=100,color=\"k\",histtype=\"step\")\n",
    "    \n",
    "    barax.bar(plot_range,number_array,width=bar_width,log=bar_log,color=color,edgecolor=color,alpha=alpha,zorder=zorder,fill=fill_bool,\\\n",
    "             linewidth=1.5 if not fill_bool else 0)\n",
    "        \n",
    "def plot_values_scatter_with_errors(ax, val_array, err_array, plot_range, min_range, max_range, color, label,line_alpha=1,zorder=0,\\\n",
    "                                    lines_bool=True,x_error_bool=True,marker=\".\",marker_size=5):\n",
    "    xerror = PH.get_xerr(min_range,max_range,plot_range)\n",
    "\n",
    "    ax.errorbar(plot_range,val_array,yerr=err_array,xerr=xerror if x_error_bool else None,capsize=capsize,color=color,label=label,\\\n",
    "                linestyle=None if lines_bool else '',alpha=line_alpha,zorder=zorder,marker=marker,markersize=marker_size)\n",
    "\n",
    "def plot_values_surface(ax, val_array, err_array, plot_range,surface_color,line_color,label,surface_alpha=0.75,line_alpha=1,linestyle=\"-\",zorder=0):\n",
    "    \n",
    "    if np.array(err_array).ndim == 2:\n",
    "        ax.fill_between(plot_range,val_array-err_array[0],val_array+err_array[1],label=label,color=surface_color,alpha=surface_alpha,linewidth=0,zorder=zorder)\n",
    "    else: # backwards compatibility\n",
    "        ax.fill_between(plot_range,val_array-err_array,val_array+err_array,label=label,color=surface_color,alpha=surface_alpha,linewidth=0,zorder=zorder)\n",
    "        \n",
    "    ax.plot(plot_range,val_array,color=line_color,alpha=line_alpha,linestyle=linestyle,zorder=zorder)\n",
    "        \n",
    "def set_number_bar_axis_settings(barax,min_n,max_n,labels_on=True,min_shift_bool=True,max_shift_bool=True,hardcoded_lims=None):\n",
    "    \n",
    "    if hardcoded_lims is None:\n",
    "        final_min = 10**MF.get_exponent(min_n) - (min_n/3 if min_shift_bool else 0)\n",
    "        final_max = max_n + (10**MF.get_exponent(max_n) if max_shift_bool else 0)\n",
    "    else:\n",
    "        final_min,final_max = hardcoded_lims\n",
    "    \n",
    "    exponent_ticks = np.arange(MF.get_exponent(final_min),MF.get_exponent(final_max)+1,1)\n",
    "    barax.set_yticks([10**i for i in exponent_ticks])\n",
    "    \n",
    "    barax.set_ylim(final_min,final_max)\n",
    "            \n",
    "    barax.yaxis.set_tick_params(which='minor', right=True,left=False)\n",
    "\n",
    "    barax.tick_params(which='both',labelleft=False,labelright=labels_on)\n",
    "    barax.tick_params(which='minor',labelright=False)\n",
    "\n",
    "    if labels_on:\n",
    "        barax.set_ylabel(r\"$N$\",rotation=0,labelpad=20)\n",
    "        barax.yaxis.set_label_position(\"right\")\n",
    "    \n",
    "def set_xaxis_settings(ax,xmin,xmax,xlabel,label_size=\"medium\",xticks=None,xtick_labels=None, labels_on=True):\n",
    "#     ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.25))\n",
    "    \n",
    "    ax.set_xlim(xmin,xmax)\n",
    "    \n",
    "    if xticks is not None:\n",
    "        ax.set_xticks(xticks, labels=xtick_labels)\n",
    "    \n",
    "    if labels_on:\n",
    "        ax.set_xlabel(xlabel,fontsize=label_size)\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "        \n",
    "def set_yaxis_settings(ax, map_string, label_size=\"medium\",map_dict=None, labels_on=True,y_shift_dict={},symmetric_ylims_bool=False,\\\n",
    "                       set_ylims=True, hard_coded_ylims_bool=False, hard_coded_ylims_dict={}):\n",
    "    \n",
    "    if map_string == 'tilt_abs':\n",
    "#         ax.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "        ax.yaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "    elif map_string == 'anisotropy':# or map_string == 'correlation':\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(0.1))\n",
    "        ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.05))\n",
    "        \n",
    "#         ax.yaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "#         ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.25))\n",
    "    elif map_string == \"correlation\":\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(0.10))\n",
    "        ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.05))\n",
    "#         ax.yaxis.set_major_locator(ticker.MultipleLocator(0.15))\n",
    "    elif map_string in [\"mean_vy\"]:\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "    elif map_string in [\"std_vx\",\"std_vy\"]:\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "    \n",
    "    if labels_on:\n",
    "        ax.set_ylabel(symbol_dict[map_string]+units_dict[map_string],fontsize=label_size)\n",
    "    else:\n",
    "        ax.set_yticklabels([])\n",
    "    \n",
    "    def compute_ylims(map_dict, map_string):\n",
    "        minimum = np.nanmin(map_dict[map_string]-map_dict[map_string+\"_error_low\"])\n",
    "        maximum = np.nanmax(map_dict[map_string]+map_dict[map_string+\"_error_high\"])\n",
    "\n",
    "        if map_string in yshift_dict:\n",
    "            minimum -= yshift_dict[map_string]\n",
    "            maximum += yshift_dict[map_string]\n",
    "\n",
    "        if symmetric_ylims_bool:\n",
    "            maxabs = np.nanmax(np.abs([minimum,maximum]))\n",
    "            ax.set_ylim(-maxabs,maxabs)\n",
    "        else:\n",
    "            ax.set_ylim(minimum,maximum)\n",
    "    \n",
    "    if set_ylims:\n",
    "        if hard_coded_ylims_bool and map_string in hard_coded_ylims_dict:\n",
    "            ax.set_ylim(hard_coded_ylims_dict[map_string])\n",
    "        else:\n",
    "            if map_dict is None:\n",
    "                raise ValueError(\"Cannot compute ylims if `map_dict` is None.\")\n",
    "            compute_ylims(map_dict, map_string)\n",
    "\n",
    "def get_kinematic_label(map_string):\n",
    "    return symbol_dict[map_string]+units_dict[map_string]\n",
    "\n",
    "def get_legend_label(var_tuple,variable):\n",
    "    if variable in pos_symbols_dict:\n",
    "        var_symbol = pos_symbols_dict[variable]\n",
    "        var_units = pos_units_dict[variable]\n",
    "    else:\n",
    "        if variable == \"age\":\n",
    "            var_symbol = \"Age\"\n",
    "            var_units = \"Gyr\"\n",
    "        elif variable == \"FeH\":\n",
    "            var_symbol = \"[Fe/H]\"\n",
    "            var_units = \"\"\n",
    "        else:\n",
    "            raise ValueError(\"legend label not defined for the chosen variable\")\n",
    "    \n",
    "    if variable == \"R\" and var_tuple[0] == 0:\n",
    "        return var_symbol + fr\"$\\leq {var_tuple[1]}~$\"+var_units\n",
    "    else:\n",
    "        return r\"$%s\\leq$\"%str(var_tuple[0]) + var_symbol + (r\"$/\\mathrm{%s}$\"%var_units if var_units!=\"\" else \"\") + fr\"$\\leq{var_tuple[1]}$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_values_and_plot_ranges(path,full_map_string_list):\n",
    "    \n",
    "    map_dict = {}\n",
    "    for m in full_map_string_list:\n",
    "        map_dict[m] = np.load(f\"{path}{m}.npy\")\n",
    "    \n",
    "    min_range = np.load(path + f\"x_range_min.npy\")\n",
    "    max_range = np.load(path + f\"x_range_max.npy\")\n",
    "    plot_range = np.load(path + f\"x_range_plot.npy\")\n",
    "    \n",
    "    return map_dict, min_range, max_range, plot_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some reference values\n",
    "\n",
    "l_cuts = [-2,2]\n",
    "y_cuts = MF.return_int_or_dec_for_array([coordinates.ang_to_rect_1D(ang=l_cut,x=coordinates.get_solar_radius()) for l_cut in l_cuts])\n",
    "\n",
    "R_variations = [[0,3.5],[0,2]]\n",
    "\n",
    "print(\"l\",l_cuts)\n",
    "print(\"y\",y_cuts)\n",
    "print(\"R\",R_variations)\n",
    "\n",
    "try: # b and z based on data_trim\n",
    "    b_range_min,b_range_max = PH.get_equal_n_minmax_b_ranges(data_trim)\n",
    "    b_variations = [[MF.return_int_or_dec(m,2),MF.return_int_or_dec(M,2)] for (m,M) in zip(b_range_min,b_range_max)]\n",
    "\n",
    "    z_range_min = [coordinates.ang_to_rect(ang=bmin,x=coordinates.get_solar_radius()) for bmin in b_range_min]\n",
    "    z_range_max = [coordinates.ang_to_rect(ang=bmax,x=coordinates.get_solar_radius()) for bmax in b_range_max]\n",
    "    z_variations = [[MF.return_int_or_dec(m,2),MF.return_int_or_dec(M,2)] for (m,M) in zip(z_range_min,z_range_max)]\n",
    "\n",
    "    print(\"b\",b_variations)\n",
    "    print(\"z\",z_variations)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_alpha = 0.9\n",
    "surface_alpha = 0.75\n",
    "alpha_reduction_factor = 0.25\n",
    "\n",
    "number_alpha = 0.75\n",
    "number_alpha_reduction_factor = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spatial variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_units_dict[\"b\"] = r\"$^\\circ$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = \"b\"\n",
    "\n",
    "x_label = pos_symbols_dict[x_var] + f\" [{pos_units_dict[x_var]}]\"\n",
    "\n",
    "MP.show_text(x_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_size = 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mplcmaps[\"coolwarm\"]\n",
    "\n",
    "strong_colors = [\n",
    "    cmap(0),\n",
    "    cmap(cmap.N)\n",
    "]\n",
    "\n",
    "weak_colors = [\n",
    "    cmap(int(cmap.N/3)),\n",
    "    cmap(int(cmap.N*(1-1/3)))\n",
    "]\n",
    "\n",
    "for s,w in zip(strong_colors,weak_colors):\n",
    "    MP.show_color(s)\n",
    "    MP.show_color(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude 1b13; data & sim equalSteps; 1 column\n",
    "\n",
    "bar_angle = 27\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + \"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + \"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + \"1.5b13/0R2/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + \"1.5b13/0R2/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R2/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R2/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"\",\n",
    "        \"labels\": [fr'[Fe/H]-rich ($-0.21$ to $0.61$)',fr'[Fe/H]-poor ($-1$ to $-0.21$)',\"Young\",\"Old\"]+4*[None],\n",
    "        \"plot_ranges_str\": 2*(2*[\"median\"]+2*[\"mean\"]),\n",
    "        \"surface_bools\": 2*(2*[False]+2*[True]),\n",
    "        \"invert_xaxis\": False,\n",
    "        \"xaxis_label\": x_label,\n",
    "        \"x_ticks\": np.arange(2,13+1,1),\n",
    "        \"x_lims\": [1.5,13],\n",
    "        \"bar_widths\": 8*[0.3]\n",
    "    }   \n",
    "}\n",
    "\n",
    "save_path_plot = get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5_0R2/-2l2/both/data_equalN/data_n4_n4/sim_bar_angle_{bar_angle}/sim_equalSteps/sim_n8_n8/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [8,7,6,5,4,3,2,1]\n",
    "    all_dicts[key][\"zorderNs\"] = [8,7,4,3,5,6,2,1]\n",
    "    all_dicts[key][\"colors\"] = 2*strong_colors+2*weak_colors\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = nplots*[line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = nplots*[surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    all_dicts[key][\"number_filled\"] = 2*(2*[False]+2*[True])\n",
    "    \n",
    "    all_dicts[key][\"number_bools\"] = nplots*[True]\n",
    "    \n",
    "    all_dicts[key][\"scatter_markers\"] = 2*([\"$\\u25EF$\",\"$\\u25A1$\"] + 2*[None])\n",
    "    \n",
    "surface_linestyle = \"--\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude 1b13; data & sim equalN; 1 column\n",
    "\n",
    "bar_angle = 27\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + \"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + \"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_N/50_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_N/50_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + \"1.5b13/0R2/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + \"1.5b13/0R2/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R2/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_N/50_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R2/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_N/50_bins/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"\",\n",
    "        \"labels\": [fr'[Fe/H]-rich ($-0.21$ to $0.61$)',fr'[Fe/H]-poor ($-1$ to $-0.21$)',\"Young\",\"Old\"]+4*[None],\n",
    "        \"plot_ranges_str\": 2*(2*[\"median\"]+2*[\"mean\"]),\n",
    "        \"surface_bools\": 2*(2*[False]+2*[True]),\n",
    "        \"invert_xaxis\": False,\n",
    "        \"xaxis_label\": x_label,\n",
    "        \"x_ticks\": np.arange(2,13+1,1),\n",
    "        \"x_lims\": [1.5,13],\n",
    "        \"bar_widths\": 2*(2*[0.3]+2*[0.01])\n",
    "    }   \n",
    "}\n",
    "\n",
    "save_path_plot = get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5_0R2.5/-2l2/both/data_equal_number_low/data_n4_n4/sim_bar_angle_{bar_angle}/sim_equalN/sim_n50_n50/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [8,7,6,5,4,3,2,1]\n",
    "    all_dicts[key][\"zorderNs\"] = [8,7,4,3,5,6,2,1]\n",
    "    all_dicts[key][\"colors\"] = 2*strong_colors+2*weak_colors\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = nplots*[line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = nplots*[surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    all_dicts[key][\"number_filled\"] = 2*(2*[False]+2*[True])\n",
    "    \n",
    "    all_dicts[key][\"number_bools\"] = 4*[True] + 4*[False]\n",
    "    \n",
    "    all_dicts[key][\"scatter_markers\"] = 2*([\"$\\u25EF$\",\"$\\u25A1$\"] + 2*[None])\n",
    "    \n",
    "surface_linestyle = \"--\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude 1b13; sim -Î± and Î± bar angles; 1 column\n",
    "\n",
    "bar_angle = 27\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + f\"1b13/0R3.5/-2l2/sim/bar_angle_{-bar_angle}/4age7/equal_steps/7_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1b13/0R3.5/-2l2/sim/bar_angle_{-bar_angle}/9.5age10/equal_steps/7_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/7_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/7_bins/arrays/\"\n",
    "        ],\n",
    "        \"title\": \"\",\n",
    "        \"labels\": [fr\"Young ($\\alpha={-bar_angle}$)\",fr\"Old ($\\alpha={-bar_angle}$)\",fr\"Young ($\\alpha={bar_angle}$)\",fr\"Young ($\\alpha={bar_angle}$)\"],\n",
    "        \"plot_ranges_str\": 4*[\"mean\"],\n",
    "        \"surface_bools\": 4*[True],\n",
    "        \"invert_xaxis\": False,\n",
    "        \"xaxis_label\": x_label,\n",
    "        \"x_ticks\": np.arange(1,13+1,1),\n",
    "        \"x_lims\": [1,13],\n",
    "        \"bar_width\": 0.3\n",
    "    }   \n",
    "}\n",
    "\n",
    "save_path_plot = get_base_path(single_variable=\"b\") + \"1b13/0R3.5/-2l2/sim/bar_angles_-27,27/sim_equalSteps/sim_n7/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [8,7,6,5]\n",
    "    all_dicts[key][\"zorderNs\"] = [6,5,8,7]\n",
    "    all_dicts[key][\"colors\"] = strong_colors+weak_colors\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = nplots*[line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = nplots*[surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    all_dicts[key][\"number_filled\"] = 2*[True]+2*[False]\n",
    "    \n",
    "    all_dicts[key][\"number_bools\"] = nplots*[True]\n",
    "    \n",
    "surface_linestyle = \"--\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude 1b13; 708mainDiff4 and 708mainDiff5 (with 708main as fiducial); 2 columns\n",
    "\n",
    "bar_angle = 27\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim_708mainDiff4/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim_708mainDiff4/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\"\n",
    "        ],\n",
    "        \"title\": \"Weak bar\",\n",
    "        \"labels\": 4*[None],\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim_708mainDiff5/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim_708mainDiff5/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\"\n",
    "        ],\n",
    "        \"title\": \"Oval\",\n",
    "        \"labels\": [\"Young\",\"Old\",\"Young (fiducial, strong bar)\",\"Old (fiducial, strong bar)\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "save_path_plot = get_base_path(single_variable=\"b\") + \"1.5b13/0R3.5/-2l2/sim_708mainDiff4__708mainDiff5/bar_angle_27/sim_equalSteps/sim_n8__n8/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [8,7,6,5]\n",
    "    all_dicts[key][\"zorderNs\"] = [6,5,8,7]\n",
    "    all_dicts[key][\"colors\"] = strong_colors+weak_colors\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = 2*[line_alpha]+2*[0.8*line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 2*[surface_alpha]+2*[0.8*surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    all_dicts[key][\"number_filled\"] = 2*[True]+2*[False]\n",
    "    \n",
    "    all_dicts[key][\"plot_ranges_str\"] = 4*[\"mean\"]\n",
    "    all_dicts[key][\"surface_bools\"] = 4*[True]\n",
    "    all_dicts[key][\"invert_xaxis\"] =  False\n",
    "    all_dicts[key][\"xaxis_label\"] = x_label\n",
    "    all_dicts[key][\"x_ticks\"] = np.arange(2,13+1,1)\n",
    "    all_dicts[key][\"x_lims\"] = [1.5,13]\n",
    "    all_dicts[key][\"bar_widths\"] = nplots*[0.3]\n",
    "    \n",
    "    all_dicts[key][\"number_bools\"] = nplots*[True]\n",
    "    \n",
    "surface_linestyle = \"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude 1b13; 708main Rgc and d cuts; symmetric & asymmetric; 4 columns\n",
    "\n",
    "bar_angle = 27\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R2/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R2/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\"\n",
    "        ],\n",
    "        \"title\": r\"$R<2~$kpc\",\n",
    "        \"labels\": 4*[None],\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/6.1d10.1/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/6.1d10.1/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\"\n",
    "        ],\n",
    "        \"title\": r\"$6.1<d/$kpc\"+r\"$<10.1$\",\n",
    "        \"labels\": [\"Young\",\"Old\",r\"Young ($R<3.5~$kpc)\",r\"Old ($R<3.5~$kpc)\"]\n",
    "    },\n",
    "    2: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/6.1d9.1/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/6.1d9.1/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\"\n",
    "        ],\n",
    "        \"title\": r\"$6.1<d/$kpc\"+r\"$<9.1$\",\n",
    "        \"labels\": 4*[None]\n",
    "    },\n",
    "    3: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/7.1d10.1/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/7.1d10.1/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\"\n",
    "        ],\n",
    "        \"title\": r\"$7.1<d/$kpc\"+r\"$<10.1$\",\n",
    "        \"labels\": 4*[None]\n",
    "    }\n",
    "}\n",
    "\n",
    "save_path_plot = get_base_path(single_variable=\"b\") + \"1.5b13/0R2__6.1d10.1__6.1d9.1__7.1d10.1/-2l2/sim/bar_angle_27/4age7_9.5age10/sim_equalSteps/sim_n8/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [8,7,6,5]\n",
    "    all_dicts[key][\"zorderNs\"] = [6,5,8,7]\n",
    "    all_dicts[key][\"colors\"] = strong_colors+weak_colors\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = 2*[line_alpha]+2*[0.8*line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 2*[surface_alpha]+2*[0.8*surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    all_dicts[key][\"number_filled\"] = 2*[True]+2*[False]\n",
    "    \n",
    "    all_dicts[key][\"plot_ranges_str\"] = 4*[\"mean\"]\n",
    "    all_dicts[key][\"surface_bools\"] = 4*[True]\n",
    "    all_dicts[key][\"invert_xaxis\"] =  False\n",
    "    all_dicts[key][\"xaxis_label\"] = x_label\n",
    "    all_dicts[key][\"x_ticks\"] = np.arange(2,13+1,1)\n",
    "    all_dicts[key][\"x_lims\"] = [1.5,13]\n",
    "    all_dicts[key][\"bar_widths\"] = nplots*[0.3]\n",
    "    \n",
    "    all_dicts[key][\"number_bools\"] = nplots*[True]\n",
    "    \n",
    "surface_linestyle = \"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude 1b13; data Rgc and d cuts; symmetric & asymmetric; 4 columns\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R2/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R2/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\"\n",
    "        ],\n",
    "        \"title\": r\"$R<2~$kpc\",\n",
    "        \"labels\": 4*[None],\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/6.1d10.1/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/6.1d10.1/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\"\n",
    "        ],\n",
    "        \"title\": r\"$6.1<d/$kpc\"+r\"$<10.1$\",\n",
    "        \"labels\": [fr'[Fe/H]-rich ($-0.21$ to $0.61$)',fr'[Fe/H]-poor ($-1$ to $-0.21$)',\\\n",
    "                   fr'[Fe/H]-rich ($-0.21$ to $0.61$, $R<3.5~$kpc)',fr'[Fe/H]-poor ($-1$ to $-0.21$, $R<3.5~$kpc)'],\n",
    "    },\n",
    "    2: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/6.1d9.1/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/6.1d9.1/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\"\n",
    "        ],\n",
    "        \"title\": r\"$6.1<d/$kpc\"+r\"$<9.1$\",\n",
    "        \"labels\": 4*[None]\n",
    "    },\n",
    "    3: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/7.1d10.1/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/7.1d10.1/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\"\n",
    "        ],\n",
    "        \"title\": r\"$7.1<d/$kpc\"+r\"$<10.1$\",\n",
    "        \"labels\": 4*[None]\n",
    "    }\n",
    "}\n",
    "\n",
    "save_path_plot = get_base_path(single_variable=\"b\") +\\\n",
    "                 \"1.5b13/0R2__6.1d10.1__6.1d9.1__7.1d10.1/-2l2/data/metal_lowcut_-1/-1metal-0.21_-0.21metal0.61/data_equal_number_low/data_n4/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [8,7,6,5]\n",
    "    all_dicts[key][\"zorderNs\"] = [6,5,8,7]\n",
    "    all_dicts[key][\"colors\"] = strong_colors+weak_colors\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = 2*[line_alpha]+2*[0.8*line_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    all_dicts[key][\"number_filled\"] = 2*[True]+2*[False]\n",
    "    \n",
    "    all_dicts[key][\"plot_ranges_str\"] = 4*[\"median\"]\n",
    "    all_dicts[key][\"surface_bools\"] = 4*[False]\n",
    "    all_dicts[key][\"invert_xaxis\"] =  False\n",
    "    all_dicts[key][\"xaxis_label\"] = x_label\n",
    "    all_dicts[key][\"x_ticks\"] = np.arange(2,13+1,1)\n",
    "    all_dicts[key][\"x_lims\"] = [1.5,13]\n",
    "    all_dicts[key][\"bar_widths\"] = nplots*[0.3]\n",
    "    \n",
    "    all_dicts[key][\"scatter_markers\"] = 2*[\"$\\u25EF$\",\"$\\u25A1$\"]\n",
    "    \n",
    "    all_dicts[key][\"number_bools\"] = nplots*[True]\n",
    "    \n",
    "surface_linestyle = \"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitude 1b13; data & 708main Rgc and d cuts; symmetric & asymmetric; 4 columns\n",
    "\n",
    "bar_angle = 27\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R2/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R2/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R2/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R2/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\"\n",
    "        ],\n",
    "        \"title\": r\"$R<2~$kpc\",\n",
    "        \"labels\": 8*[None],\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/6.1d10.1/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/6.1d10.1/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/6.1d10.1/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/6.1d10.1/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\"\n",
    "        ],\n",
    "        \"title\": r\"$6.1<d/$kpc\"+r\"$<10.1$\",\n",
    "        \"labels\": [\"Young\",\"Old\",r\"Young ($R<3.5~$kpc)\",r\"Old ($R<3.5~$kpc)\",\\\n",
    "                   fr'[Fe/H]-rich ($-0.21$ to $0.61$)',fr'[Fe/H]-poor ($-1$ to $-0.21$)',\\\n",
    "                   fr'[Fe/H]-rich ($-0.21$ to $0.61$, $R<3.5~$kpc)',fr'[Fe/H]-poor ($-1$ to $-0.21$, $R<3.5~$kpc)']\n",
    "    },\n",
    "    2: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/6.1d9.1/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/6.1d9.1/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/6.1d9.1/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/6.1d9.1/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\"\n",
    "        ],\n",
    "        \"title\": r\"$6.1<d/$kpc\"+r\"$<9.1$\",\n",
    "        \"labels\": 8*[None]\n",
    "    },\n",
    "    3: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/7.1d10.1/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/7.1d10.1/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age7/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/sim/bar_angle_{bar_angle}/9.5age10/equal_steps/8_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/7.1d10.1/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/7.1d10.1/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-0.21metal0.61/equal_number_low/4_bins/arrays/\",\n",
    "            get_base_path(single_variable=\"b\") + f\"1.5b13/0R3.5/-2l2/data/metal_lowcut_-1/-1metal-0.21/equal_number_low/4_bins/arrays/\"\n",
    "        ],\n",
    "        \"title\": r\"$7.1<d/$kpc\"+r\"$<10.1$\",\n",
    "        \"labels\": 8*[None]\n",
    "    }\n",
    "}\n",
    "\n",
    "save_path_plot = get_base_path(single_variable=\"b\") +\\\n",
    "\"1.5b13/0R2__6.1d10.1__6.1d9.1__7.1d10.1/-2l2/both/metal_lowcut_-1/-1metal-0.21_-0.21metal0.61/data_equal_number_low/data_n4/sim_bar_angle_27/4age7_9.5age10/sim_equalSteps/sim_n8/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [6,5,2,1,8,7,4,3]\n",
    "    all_dicts[key][\"zorderNs\"] = [6,5,2,1,8,7,4,3]\n",
    "    all_dicts[key][\"colors\"] = 2*(strong_colors+weak_colors)\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = 2*(2*[line_alpha]+2*[0.8*line_alpha])\n",
    "    all_dicts[key][\"surface_alphas\"] = 2*(2*[surface_alpha]+2*[0.8*surface_alpha])\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    all_dicts[key][\"number_filled\"] = 4*[True]+4*[False]\n",
    "    \n",
    "    all_dicts[key][\"plot_ranges_str\"] = 4*[\"mean\"]+4*[\"median\"]\n",
    "    all_dicts[key][\"surface_bools\"] = 4*[True]+4*[False]\n",
    "    all_dicts[key][\"invert_xaxis\"] =  False\n",
    "    all_dicts[key][\"xaxis_label\"] = x_label\n",
    "    all_dicts[key][\"x_ticks\"] = np.arange(2,13+1,1)\n",
    "    all_dicts[key][\"x_lims\"] = [1.5,13]\n",
    "    all_dicts[key][\"bar_widths\"] = nplots*[0.3]\n",
    "    \n",
    "    all_dicts[key][\"number_bools\"] = nplots*[True]\n",
    "    \n",
    "    all_dicts[key][\"scatter_markers\"] = 4*[\"$\\u25EF$\",\"$\\u25A1$\"]\n",
    "    \n",
    "surface_linestyle = \"--\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kinpop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_units_dict[\"b\"] = \"deg\"\n",
    "\n",
    "surface_linestyle = \"-\"\n",
    "\n",
    "marker_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://colorbrewer2.org/#type=qualitative&scheme=Dark2&n=3\n",
    "\n",
    "# colors = [\"blue\",\"blue\",\"blue\"]\n",
    "colors = [\"#1b9e77\",\"#d95f02\",\"#7570b3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim 10% and 20% distance errors, and bootstrap errors. 3 columns\n",
    "\n",
    "bar_angle = 27\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"age\") + f\"3b6/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age10/equal_steps/20_bins/MC_perturbed_d/error_frac_0.1/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"10% distance errors\",\n",
    "        \"number_colors\": [\"blue\"],\n",
    "        \"surface_colors\": [\"cyan\"],\n",
    "        \"line_colors\": [\"blue\"],\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"age\") + f\"3b6/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age10/equal_steps/20_bins/MC_perturbed_d/error_frac_0.2/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"20% distance errors\",\n",
    "        \"number_colors\": [\"blue\"],\n",
    "        \"surface_colors\": [\"cyan\"],\n",
    "        \"line_colors\": [\"blue\"],\n",
    "    },\n",
    "    2: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"age\") + f\"3b6/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age10/equal_steps/20_bins/bootstrap/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Bootstrap errors\",\n",
    "        \"surface_colors\": [\"grey\"],\n",
    "        \"line_colors\": [\"k\"],\n",
    "        \"number_colors\": [\"k\"]\n",
    "    },\n",
    "}\n",
    "\n",
    "save_path_plot = get_base_path(single_variable=\"age\") + \\\n",
    "            f\"3b6/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age10/equal_steps/20_bins/bootstrap__MCd0.1__MCd0.2/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [0]\n",
    "    all_dicts[key][\"line_alphas\"] = [line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = [surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = [number_alpha]\n",
    "    all_dicts[key][\"zorderNs\"] = [0]\n",
    "    \n",
    "    all_dicts[key][\"plot_ranges_str\"] = nplots*[\"mean\"]\n",
    "    all_dicts[key][\"surface_bools\"] = nplots*[True]\n",
    "    all_dicts[key][\"scatter_join_bools\"] = nplots*[True]\n",
    "    all_dicts[key][\"number_bools\"] = [True]\n",
    "    all_dicts[key][\"labels\"] = [None]\n",
    "    all_dicts[key][\"bar_widths\"] = nplots*[0.1]\n",
    "    all_dicts[key][\"number_filled\"] = [True]\n",
    "    \n",
    "    all_dicts[key][\"invert_xaxis\"] = True\n",
    "    all_dicts[key][\"xaxis_label\"] = \"Age [Gyr]\"\n",
    "    all_dicts[key][\"x_ticks\"] = np.arange(4,11,1) #np.arange(-0.9,0.6+0.3,0.3)\n",
    "    all_dicts[key][\"x_lims\"] = [4,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim bootstrap errors without replacement, 350,250,150,50 resampling sizes. 4 columns\n",
    "\n",
    "bar_angle = 27\n",
    "b_range = \"2b4\"\n",
    "n_bins = 20\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"age\") + f\"{b_range}/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age10/equal_steps/{n_bins}_bins/bootstrap/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Bootstrap\",\n",
    "        \"number_colors\": [\"k\"],\n",
    "        \"surface_colors\": [\"grey\"],\n",
    "        \"line_colors\": [\"k\"],\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"age\") + f\"{b_range}/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age10/equal_steps/{n_bins}_bins/bootstrap_no_replacement/bootsize_350/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"350-star samples\",\n",
    "        \"number_colors\": [\"blue\"],\n",
    "        \"surface_colors\": [\"cyan\"],\n",
    "        \"line_colors\": [\"blue\"],\n",
    "    },\n",
    "    2: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"age\") + f\"{b_range}/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age10/equal_steps/{n_bins}_bins/bootstrap_no_replacement/bootsize_250/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"250-star samples\",\n",
    "        \"number_colors\": [\"blue\"],\n",
    "        \"surface_colors\": [\"cyan\"],\n",
    "        \"line_colors\": [\"blue\"],\n",
    "    },\n",
    "    3: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"age\") + f\"{b_range}/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age10/equal_steps/{n_bins}_bins/bootstrap_no_replacement/bootsize_150/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"150-star samples\",\n",
    "        \"number_colors\": [\"blue\"],\n",
    "        \"surface_colors\": [\"cyan\"],\n",
    "        \"line_colors\": [\"blue\"],\n",
    "    },\n",
    "    4: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"age\") + f\"{b_range}/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age10/equal_steps/{n_bins}_bins/bootstrap_no_replacement/bootsize_50/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"50-star samples\",\n",
    "        \"number_colors\": [\"blue\"],\n",
    "        \"surface_colors\": [\"cyan\"],\n",
    "        \"line_colors\": [\"blue\"],\n",
    "    }\n",
    "}\n",
    "\n",
    "save_path_plot = get_base_path(single_variable=\"age\") + \\\n",
    "            f\"{b_range}/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age10/equal_steps/{n_bins}_bins/bootstrap_normal_and_no_replacement/bootsize_None__350__250__150__50/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [0]\n",
    "    all_dicts[key][\"line_alphas\"] = [line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = [surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = [number_alpha]\n",
    "    all_dicts[key][\"zorderNs\"] = [0]\n",
    "    \n",
    "    all_dicts[key][\"plot_ranges_str\"] = nplots*[\"mean\"]\n",
    "    all_dicts[key][\"surface_bools\"] = nplots*[True]\n",
    "    all_dicts[key][\"scatter_join_bools\"] = nplots*[True]\n",
    "    all_dicts[key][\"number_bools\"] = [True]\n",
    "    all_dicts[key][\"labels\"] = [None]\n",
    "    all_dicts[key][\"bar_widths\"] = nplots*[0.1]\n",
    "    all_dicts[key][\"number_filled\"] = [True]\n",
    "    \n",
    "    all_dicts[key][\"invert_xaxis\"] = True\n",
    "    all_dicts[key][\"xaxis_label\"] = \"Age [Gyr]\"\n",
    "    all_dicts[key][\"x_ticks\"] = np.arange(4,11,1) #np.arange(-0.9,0.6+0.3,0.3)\n",
    "    all_dicts[key][\"x_lims\"] = [4,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim randomly resampled - 10% and 20% distance errors, and bootstrap errors. 3 columns\n",
    "\n",
    "bar_angle = 27\n",
    "random_resample_N = 6000\n",
    "random_seed = 0\n",
    "error_repeat = 2000\n",
    "b_range = \"3b6\"\n",
    "n_bins = 6\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"age\") + f\"{b_range}/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age10/random_resampling_{random_resample_N}\"+\\\n",
    "            f\"/random_seed_{random_seed}/equal_steps/{n_bins}_bins/MC_perturbed_d/error_frac_0.1/error_repeat_{error_repeat}/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"10% distance errors\",\n",
    "        \"number_colors\": [\"blue\"],\n",
    "        \"surface_colors\": [\"cyan\"],\n",
    "        \"line_colors\": [\"blue\"],\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"age\") + f\"{b_range}/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age10/random_resampling_{random_resample_N}\"+\\\n",
    "            f\"/random_seed_{random_seed}/equal_steps/{n_bins}_bins/MC_perturbed_d/error_frac_0.2/error_repeat_{error_repeat}/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"20% distance errors\",\n",
    "        \"number_colors\": [\"blue\"],\n",
    "        \"surface_colors\": [\"cyan\"],\n",
    "        \"line_colors\": [\"blue\"],\n",
    "    },\n",
    "    2: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"age\") + f\"{b_range}/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age10/random_resampling_{random_resample_N}\"+\\\n",
    "            f\"/random_seed_{random_seed}/equal_steps/{n_bins}_bins/bootstrap/error_repeat_{error_repeat}/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Bootstrap errors\",\n",
    "        \"surface_colors\": [\"grey\"],\n",
    "        \"line_colors\": [\"k\"],\n",
    "        \"number_colors\": [\"k\"]\n",
    "    },\n",
    "}\n",
    "\n",
    "save_path_plot = get_base_path(single_variable=\"age\") + f\"{b_range}/0R3.5/-2l2/sim/bar_angle_{bar_angle}/4age10/random_resampling_{random_resample_N}/\"+\\\n",
    "                f\"random_seed_{random_seed}/equal_steps/{n_bins}_bins/MCd0.1__MCd0.2__bootstrap/error_repeat_{error_repeat}/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [0]\n",
    "    all_dicts[key][\"line_alphas\"] = [line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = [surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = [number_alpha]\n",
    "    all_dicts[key][\"zorderNs\"] = [0]\n",
    "    \n",
    "    all_dicts[key][\"plot_ranges_str\"] = nplots*[\"mean\"]\n",
    "    all_dicts[key][\"surface_bools\"] = nplots*[True]\n",
    "    all_dicts[key][\"scatter_join_bools\"] = nplots*[True]\n",
    "    all_dicts[key][\"number_bools\"] = [True]\n",
    "    all_dicts[key][\"labels\"] = [None]\n",
    "    all_dicts[key][\"bar_widths\"] = nplots*[0.1]\n",
    "    all_dicts[key][\"number_filled\"] = [True]\n",
    "    \n",
    "    all_dicts[key][\"invert_xaxis\"] = True\n",
    "    all_dicts[key][\"xaxis_label\"] = \"Age [Gyr]\"\n",
    "    all_dicts[key][\"x_ticks\"] = np.arange(4,11,1) #np.arange(-0.9,0.6+0.3,0.3)\n",
    "    all_dicts[key][\"x_lims\"] = [4,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data intrinsic, 10% and 20% distance errors, and bootstrap errors. 4 columns\n",
    "\n",
    "x_ticks_FeH = np.arange(-0.9,0.6+0.3,0.3).astype(np.float16)\n",
    "x_tick_labels_FeH = [str(MF.return_int_or_dec(i,2)).replace(\"-\",\"â\") if i!=0 else '0.0' for i in x_ticks_FeH]\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"FeH\") + f\"3b6/0R3.5/-2l2/data/metal_lowcut_-1/-1metal0.61/equal_N/4_bins/MC_perturbed_d/data_uncertainties/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Data distance errors (median 4%)\",\n",
    "        \"number_colors\": [\"teal\"],\n",
    "        \"line_colors\": [\"teal\"],\n",
    "        \"x_tick_labels\": x_tick_labels_FeH[:-1] + [\"\"]\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"FeH\") + f\"3b6/0R3.5/-2l2/data/metal_lowcut_-1/-1metal0.61/equal_N/4_bins/MC_perturbed_d/error_frac_0.1/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"10% distance errors\",\n",
    "        \"number_colors\": [\"blue\"],\n",
    "        \"line_colors\": [\"blue\"],\n",
    "        \"x_tick_labels\": x_tick_labels_FeH[:-1] + [\"\"]\n",
    "    },\n",
    "    2: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"FeH\") + f\"3b6/0R3.5/-2l2/data/metal_lowcut_-1/-1metal0.61/equal_N/4_bins/MC_perturbed_d/error_frac_0.2/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"20% distance errors\",\n",
    "        \"number_colors\": [\"blue\"],\n",
    "        \"line_colors\": [\"blue\"],\n",
    "        \"x_tick_labels\": x_tick_labels_FeH[:-1] + [\"\"]\n",
    "    },\n",
    "    3: {\n",
    "        \"load_paths\": [\n",
    "            get_base_path(single_variable=\"FeH\") + f\"3b6/0R3.5/-2l2/data/metal_lowcut_-1/-1metal0.61/equal_N/4_bins/bootstrap/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Bootstrap errors\",\n",
    "        \"line_colors\": [\"k\"],\n",
    "        \"number_colors\": [\"k\"],\n",
    "        \"x_tick_labels\": x_tick_labels_FeH\n",
    "    },\n",
    "}\n",
    "\n",
    "save_path_plot = get_base_path(single_variable=\"FeH\") + \\\n",
    "            f\"3b6/0R3.5/-2l2/data/metal_lowcut_-1/-1metal0.61/equal_N/4_bins/MCdData__MCd0.1__MCd0.2__bootstrap/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [0]\n",
    "    all_dicts[key][\"line_alphas\"] = [line_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = [number_alpha]\n",
    "    all_dicts[key][\"zorderNs\"] = [0]\n",
    "    \n",
    "    all_dicts[key][\"plot_ranges_str\"] = nplots*[\"median\"]\n",
    "    all_dicts[key][\"surface_bools\"] = nplots*[False]\n",
    "    all_dicts[key][\"scatter_join_bools\"] = nplots*[True]\n",
    "    all_dicts[key][\"number_bools\"] = [True]\n",
    "    all_dicts[key][\"labels\"] = [None]\n",
    "    all_dicts[key][\"bar_widths\"] = nplots*[0.1]\n",
    "    all_dicts[key][\"number_filled\"] = [True]\n",
    "    all_dicts[key][\"scatter_markers\"] = [\"x\"]\n",
    "    \n",
    "    all_dicts[key][\"invert_xaxis\"] = False\n",
    "    all_dicts[key][\"xaxis_label\"] = \"FeH\"\n",
    "    all_dicts[key][\"x_lims\"] = [-1,0.61]\n",
    "    all_dicts[key][\"x_ticks\"] = x_ticks_FeH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in all_dicts:\n",
    "    print(key)\n",
    "    for path in all_dicts[key][\"load_paths\"]:\n",
    "        print(path)\n",
    "        if not os.path.isdir(path):\n",
    "            raise ValueError(\"Path did not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(save_path_plot,exist_ok=True)\n",
    "\n",
    "print(save_path_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsize = 5\n",
    "\n",
    "scatter_join_bool = True\n",
    "# scatter_join_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_line_color = \"grey\"\n",
    "zero_line_alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_legend_params(ncols, all_dicts,number_bool):\n",
    "    \n",
    "    if ncols != len(all_dicts):\n",
    "        raise ValueError(\"Expected the `ncols` to match the length of `all_dicts`.\")\n",
    "    \n",
    "    legend_cols = []\n",
    "    for k in all_dicts.keys():\n",
    "        if any(all_dicts[k][\"labels\"]):\n",
    "            legend_cols.append(k)\n",
    "    \n",
    "    if ncols > 1 and len(legend_cols) == 1:\n",
    "        ncols_leg = len(np.unique(all_dicts[legend_cols[0]][\"colors\"], axis=0)) \n",
    "    else:\n",
    "        ncols_leg = 1\n",
    "    \n",
    "    if ncols > 1 and len(legend_cols) == 1:\n",
    "        # Legend above the plot\n",
    "        \n",
    "        if ncols == 2:\n",
    "            loc_x = -0.65\n",
    "        elif ncols == 3:\n",
    "            loc_x = -0.6 if len(legend_cols) == 1 else 0.16\n",
    "        elif ncols == 1:\n",
    "            loc_x = -0.25\n",
    "        else:\n",
    "            loc_x = 0\n",
    "\n",
    "        legend_loc = [loc_x, 1.65]\n",
    "\n",
    "        if not any(any(all_dicts[k][\"number_bools\"]) for k in all_dicts.keys()):\n",
    "            legend_loc[1] -= 0.4\n",
    "\n",
    "        if not any(all_dicts[k][\"title\"] for k in all_dicts.keys()):\n",
    "            legend_loc[1] -= 0.15\n",
    "    else:\n",
    "        legend_loc = \"lower left\"\n",
    "    \n",
    "    return legend_cols, legend_loc, ncols_leg\n",
    "\n",
    "# legend_bool = True\n",
    "legend_bool = False\n",
    "\n",
    "legend_row = 1\n",
    "# legend_row = len(map_list)\n",
    "\n",
    "legend_cols, legend_loc, ncols_leg = get_legend_params(ncols, all_dicts,number_bool)\n",
    "\n",
    "# legend_loc = (0.1,1.3); ncols_leg=2\n",
    "# legend_loc = (-0.4,1.4); ncols_leg=2\n",
    "# legend_loc = (-0.4,1.5); ncols_leg=2\n",
    "# legend_loc = (-0.4,1.65); ncols_leg=2\n",
    "legend_loc = (-0.6,1.56); ncols_leg=4\n",
    "# legend_loc = (-1.03,1.56); ncols_leg=4\n",
    "# legend_loc = \"upper center\"; ncols_leg=2\n",
    "# legend_cols = [1]\n",
    "\n",
    "if legend_bool: # print and check there are actually any labels to be plotted\n",
    "    \n",
    "    any_legend_bool = False\n",
    "    for key in all_dicts:\n",
    "        any_legend_bool = any_legend_bool or any(all_dicts[key][\"labels\"])\n",
    "        \n",
    "    if not any_legend_bool:\n",
    "        legend_bool = False\n",
    "        print(\"No plot with label, setting legend_bool=False\")\n",
    "    else:\n",
    "        print(f\"Showing a legend in these plot columns: {legend_cols}\\n placed at loc: {legend_loc}\\n with {ncols_leg} cols.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 22\n",
    "plt.rcParams[\"figure.titlesize\"] = \"medium\"\n",
    "axis_labels_size = \"large\"\n",
    "# legend_fontsize = 14.3\n",
    "legend_fontsize = 15.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_x = 20\n",
    "\n",
    "# figsize_y = 1.41*figsize_x # aspect ratio of A4\n",
    "# figsize_y = 1.5*figsize_x\n",
    "# figsize_y = 2*figsize_x\n",
    "# figsize_y = 1.2*figsize_x\n",
    "# figsize_y = 0.75*figsize_x\n",
    "figsize_y = 0.9*figsize_x\n",
    "\n",
    "figsize_x /= 2 if ncols == 1 else 1\n",
    "\n",
    "# barax_height_ratio = 0.4\n",
    "barax_height_ratio = 0.32\n",
    "# barax_height_ratio = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number bar stuff\n",
    "\n",
    "number_bool = True\n",
    "# number_bool = False\n",
    "\n",
    "number_variations_bool = True # This boolean is only used for the filename - ensure it matches with how you constructed all_dicts\n",
    "# number_variations_bool = False\n",
    "\n",
    "bar_log = True\n",
    "# bar_log = False\n",
    "\n",
    "number_min_shift_bool = True\n",
    "# number_min_shift_bool = False\n",
    "\n",
    "number_max_shift_bool = True\n",
    "# number_max_shift_bool = False\n",
    "\n",
    "# hardcoded_number_ylims = None\n",
    "hardcoded_number_ylims = [10,5000]\n",
    "# hardcoded_number_ylims = [80,3500]\n",
    "# hardcoded_number_ylims = [1000,220000]\n",
    "\n",
    "if number_bool: # check there are actually any to be plotted\n",
    "    \n",
    "    any_number_bool = False\n",
    "    for key in all_dicts:\n",
    "        any_number_bool = any_number_bool or any(all_dicts[key][\"number_bools\"])\n",
    "        \n",
    "    if not any_number_bool:\n",
    "        number_bool = False\n",
    "        print(\"No plot with number bool to draw, setting number_bool=False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ylims\n",
    "\n",
    "hard_coded_ylims_bool = True # currently needed to ensure the y axis is shared correctly when there is more than 1 column\n",
    "# hard_coded_ylims_bool = False\n",
    "\n",
    "# symmetric_ylims_bool = True\n",
    "symmetric_ylims_bool = False\n",
    "\n",
    "hard_coded_ylims = {\n",
    "    \"tilt_abs\": [-45,3],\n",
    "#     \"tilt_abs\": [-45,7],\n",
    "#     \"correlation\": [-0.48,0.03]\n",
    "}\n",
    "\n",
    "yshift_dict = {\n",
    "    \"tilt_abs\": 2,\n",
    "    \"anisotropy\": 0.01,\n",
    "    \"correlation\": 0.005,\n",
    "    \"mean_vx\": 1,\n",
    "    \"mean_vy\": 1,\n",
    "    \"std_vx\": 2,\n",
    "    \"std_vy\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\",\"anisotropy\",\"correlation\",\"tilt_abs\"]; map_list_string = \"all\"\n",
    "map_list = [\"anisotropy\",\"correlation\",\"tilt_abs\"]; map_list_string = \"anicorrtilt\"\n",
    "# map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\"]; map_list_string = \"velmeanstd\"\n",
    "# map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\",\"anisotropy\"]; map_list_string = \"meanstdani\"\n",
    "# map_list = [\"std_vx\",\"std_vy\",\"anisotropy\"]; map_list_string = \"stdani\"\n",
    "# map_list = [\"mean_vx\",\"mean_vy\"]; map_list_string = \"velmeans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_suffix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_ticklabels = {\n",
    "#     0: \"bottom\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "fig,axs = plt.subplots(figsize=(figsize_x,figsize_y),nrows=len(map_list)+1,ncols=ncols, facecolor='w',\\\n",
    "                       gridspec_kw={'hspace':0,'wspace':0,'height_ratios':[barax_height_ratio]+len(map_list)*[1]})\n",
    "\n",
    "if number_bool: # number and title\n",
    "    bar_n_min,bar_n_max = [10**30],[0]\n",
    "\n",
    "    for col in all_dicts:\n",
    "        dic = all_dicts[col]\n",
    "        \n",
    "        barax = axs[0] if ncols==1 else axs[0,col]\n",
    "        \n",
    "        barax.set_title(dic[\"title\"])\n",
    "\n",
    "        for i in range(len(dic[\"load_paths\"])):\n",
    "            if dic[\"number_bools\"][i]:\n",
    "                map_dict,min_range,max_range,plot_range = load_values_and_plot_ranges(dic[\"load_paths\"][i],full_map_string_list)\n",
    "                \n",
    "                if dic[\"plot_ranges_str\"][i] == \"mean\":\n",
    "                    plot_range = PH.get_range_means(min_range,max_range)\n",
    "\n",
    "                plot_number_bar(barax, plot_range, map_dict[\"number\"],color=dic[\"number_colors\"][i],alpha=dic[\"number_alphas\"][i],\\\n",
    "                                   zorder=dic[\"zorderNs\"][i], bar_width=dic[\"bar_widths\"][i], fill_bool=dic[\"number_filled\"][i],bar_log=bar_log)\n",
    "\n",
    "                bar_n_min = min(bar_n_min, np.min(map_dict[\"number\"]))\n",
    "                bar_n_max = max(bar_n_max, np.max(map_dict[\"number\"]))\n",
    "    \n",
    "    for col in all_dicts:\n",
    "        \n",
    "        barax = axs[0] if ncols==1 else axs[0,col]\n",
    "        \n",
    "        set_number_bar_axis_settings(barax,min_n=bar_n_min,max_n=bar_n_max,labels_on=col==ncols-1,\\\n",
    "                                     min_shift_bool=number_min_shift_bool,max_shift_bool=number_max_shift_bool,hardcoded_lims=hardcoded_number_ylims)        \n",
    "else:\n",
    "    for col in all_dicts:\n",
    "        barax = axs[0] if ncols==1 else axs[0,col]\n",
    "        fig.delaxes(barax)\n",
    "        \n",
    "        first_ax = axs[1] if ncols==1 else axs[1,col]\n",
    "        \n",
    "        first_ax.set_title(all_dicts[col])\n",
    "\n",
    "for row,map_string in enumerate(map_list): # plot\n",
    "    \n",
    "    ymin,ymax = [float(\"inf\")],[float(\"-inf\")]\n",
    "    \n",
    "    for col in all_dicts:\n",
    "        \n",
    "        ax = axs[row+1] if ncols==1 else axs[row+1,col]\n",
    "        \n",
    "        set_yaxis_settings(ax,map_string,label_size=axis_labels_size, set_ylims=False,labels_on=col==0)\n",
    "        ax.axhline(y=0,linestyle='--',color=zero_line_color,alpha=zero_line_alpha,zorder=0)\n",
    "        \n",
    "        dic = all_dicts[col]\n",
    "        for i in range(len(dic[\"load_paths\"])):\n",
    "            \n",
    "            map_dict,min_range,max_range,plot_range = load_values_and_plot_ranges(dic[\"load_paths\"][i],full_map_string_list)\n",
    "            \n",
    "            plot_range = plot_range if dic[\"plot_ranges_str\"][i]==\"median\" else PH.get_range_means(min_range,max_range)\n",
    "            label = dic[\"labels\"][i] if row == legend_row-1 else None\n",
    "            \n",
    "            try:\n",
    "                error_array = [map_dict[map_string+\"_error_low\"], map_dict[map_string+\"_error_high\"]]\n",
    "            except: # backwards compatibility\n",
    "                error_array = map_dict[map_string+\"_error\"]\n",
    "            \n",
    "            if dic[\"surface_bools\"][i]:\n",
    "                plot_values_surface(ax,map_dict[map_string],error_array,plot_range,surface_color=dic[\"surface_colors\"][i],line_color=dic[\"line_colors\"][i],\\\n",
    "                                    label=label, surface_alpha=dic[\"surface_alphas\"][i],line_alpha=dic[\"line_alphas\"][i],linestyle=surface_linestyle,\\\n",
    "                                    zorder=dic[\"zorders\"][i])\n",
    "            else:\n",
    "                plot_values_scatter_with_errors(ax,map_dict[map_string],error_array,plot_range,min_range,max_range,color=dic[\"line_colors\"][i],\\\n",
    "                                                label=label,lines_bool=scatter_join_bool,line_alpha=dic[\"line_alphas\"][i],zorder=dic[\"zorders\"][i],\\\n",
    "                                                marker=dic[\"scatter_markers\"][i],marker_size=marker_size)\n",
    "            \n",
    "            try:\n",
    "                ymin = min(ymin, np.nanmin(map_dict[map_string]-map_dict[map_string+\"_error_low\"]))\n",
    "                ymax = max(ymax, np.nanmax(map_dict[map_string]+map_dict[map_string+\"_error_high\"]))\n",
    "            except: # backwards compatibility\n",
    "                print(\"Using symmetric errors\")\n",
    "                ymin = min(ymin, np.nanmin(map_dict[map_string]-map_dict[map_string+\"_error\"]))\n",
    "                ymax = max(ymax, np.nanmax(map_dict[map_string]+map_dict[map_string+\"_error\"]))\n",
    "    \n",
    "    if map_string in yshift_dict:\n",
    "        ymin -= yshift_dict[map_string]\n",
    "        ymax += yshift_dict[map_string]\n",
    "    \n",
    "    if hard_coded_ylims_bool and map_string in hard_coded_ylims:\n",
    "        ymin_hard,ymax_hard = hard_coded_ylims[map_string]\n",
    "        \n",
    "#         ymin = max(ymin,ymin_hard)\n",
    "#         ymax = min(ymax,ymax_hard)\n",
    "        \n",
    "        ymin = ymin_hard\n",
    "        ymax = ymax_hard\n",
    "    \n",
    "    for col in all_dicts:\n",
    "        ax = axs[row+1] if ncols==1 else axs[row+1,col]\n",
    "        \n",
    "        ax.set_ylim(ymin,ymax)\n",
    "        \n",
    "        if row in remove_ticklabels and col == 0:\n",
    "            yticks = ax.get_yticks()\n",
    "            mapf.remove_ticklabel(ax=ax,ticks=yticks[(yticks>=ymin)&(yticks<=ymax)],which_axis=\"y\",which_tick=remove_ticklabels[row])\n",
    "        \n",
    "if legend_bool: # legend\n",
    "    for col in all_dicts:\n",
    "        if col in legend_cols:\n",
    "            \n",
    "            ax = axs[legend_row] if ncols==1 else axs[legend_row,col]\n",
    "            \n",
    "            ax.legend(loc=legend_loc,fontsize=legend_fontsize,ncols=ncols_leg)#,loc=\"lower left\")\n",
    "    \n",
    "if True: # x-axis\n",
    "        \n",
    "    for col in all_dicts:\n",
    "        \n",
    "        dic = all_dicts[col]\n",
    "    \n",
    "        for row in range(len(map_list)+1): # include number bars\n",
    "            \n",
    "            ax = axs[row] if ncols==1 else axs[row,col]\n",
    "            \n",
    "            labels_on = row==len(map_list)\n",
    "            \n",
    "            x_ticks = dic[\"x_ticks\"]\n",
    "            \n",
    "            if \"x_tick_labels\" in dic:\n",
    "                xtick_labels = dic[\"x_tick_labels\"]\n",
    "            else:\n",
    "                xtick_labels = [str(MF.return_int_or_dec(i,2)).replace(\"-\",\"â\") if i!=0 else '0.0' for i in x_ticks]\n",
    "            \n",
    "                if labels_on and ncols > 1:\n",
    "\n",
    "                    if col > 0:\n",
    "                        left_tick_idx = 0 if not dic[\"invert_xaxis\"] else -1\n",
    "                        left_lim_idx = 0 if not dic[\"invert_xaxis\"] else 1\n",
    "                        left_tick_on_edge = dic[\"x_lims\"][left_lim_idx] == dic[\"x_ticks\"][left_tick_idx]\n",
    "\n",
    "                        previous_right_tick_idx = -1 if not all_dicts[col-1][\"invert_xaxis\"] else 0\n",
    "                        previous_right_lim_idx = 1 if not all_dicts[col-1][\"invert_xaxis\"] else 0\n",
    "                        previous_right_tick_on_edge = all_dicts[col-1][\"x_lims\"][previous_right_lim_idx] == all_dicts[col-1][\"x_ticks\"][previous_right_tick_idx]\n",
    "\n",
    "                        if left_tick_on_edge and previous_right_tick_on_edge:\n",
    "                            xtick_labels[left_tick_idx] = \"\"\n",
    "\n",
    "                    if col < ncols - 1:\n",
    "                        right_tick_idx = -1 if not dic[\"invert_xaxis\"] else 0\n",
    "                        right_lim_idx = 1 if not dic[\"invert_xaxis\"] else 0\n",
    "                        right_tick_on_edge = dic[\"x_lims\"][right_lim_idx] == dic[\"x_ticks\"][right_tick_idx]\n",
    "\n",
    "                        previous_left_tick_idx = 0 if not all_dicts[col+1][\"invert_xaxis\"] else -1\n",
    "                        previous_left_lim_idx = 0 if not all_dicts[col+1][\"invert_xaxis\"] else 1\n",
    "                        previous_left_tick_on_edge = all_dicts[col+1][\"x_lims\"][previous_left_lim_idx] == all_dicts[col+1][\"x_ticks\"][previous_left_tick_idx]\n",
    "\n",
    "                        if right_tick_on_edge and previous_left_tick_on_edge:\n",
    "                            xtick_labels[right_tick_idx] = \"\"\n",
    "                    \n",
    "            set_xaxis_settings(ax,xmin=dic[\"x_lims\"][0],xmax=dic[\"x_lims\"][1],xlabel=dic[\"xaxis_label\"],xticks=x_ticks,xtick_labels=xtick_labels,\\\n",
    "                               labels_on=labels_on, label_size=axis_labels_size)\n",
    "\n",
    "            if dic[\"invert_xaxis\"]:\n",
    "                ax.invert_xaxis()\n",
    "    \n",
    "fig.align_labels()\n",
    "    \n",
    "if True: # save\n",
    "    \n",
    "    filename = \"kinpop\" if x_var not in pos_symbols_dict else f\"{x_var}_\" + map_list_string\n",
    "    \n",
    "    filename += \"_noN\" if not number_bool else \"\"\n",
    "    \n",
    "    filename += \"_noNvar\" if number_bool and not number_variations_bool else \"\"\n",
    "    \n",
    "    filename += \"_noLeg\" if nplots > 1 and not legend_bool else \"\"\n",
    "    \n",
    "    any_scatter_bool = False\n",
    "    for key in all_dicts:\n",
    "        any_scatter_bool = any(~np.array(all_dicts[key][\"surface_bools\"]))\n",
    "    if any_scatter_bool and not scatter_join_bool:\n",
    "        filename += \"_noLines\"\n",
    "    \n",
    "    filename += filename_suffix\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        print(\"Saving in\",save_path_plot)\n",
    "        for formatting in ['.png','.pdf']:\n",
    "            plt.savefig(save_path_plot+filename+formatting, bbox_inches='tight', dpi=300)\n",
    "            print(\"Saved\",formatting)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stellar populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_POPPLOT_path(resampled_sim_bool=False):\n",
    "    save_path = general_path+'graphs/Observations/Apogee/individual_variable/age_metal/'\n",
    "    \n",
    "    save_path += \"resampled_sim/\" if resampled_sim_bool else \"\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "def get_save_path_POPPLOT_spatial_cuts(resampled_sim_bool,extra_variable,extra_min,extra_max,depth_var,depth_min,depth_max,height_var,height_min,height_max):\n",
    "    \"\"\"\n",
    "    Expected values:\n",
    "    \n",
    "    extra_variable = \"R\" or \"d\"\n",
    "    depth_var = \"l\" or \"y\"\n",
    "    height_var = \"b\" or \"z\"\n",
    "    \"\"\"\n",
    "    \n",
    "    save_path = get_base_POPPLOT_path(resampled_sim_bool)\n",
    "\n",
    "    save_path += f\"{MF.return_int_or_dec(extra_min,2)}{extra_variable}{MF.return_int_or_dec(extra_max,2)}/\"\n",
    "    MF.create_dir(save_path)\n",
    "\n",
    "    save_path += f\"{MF.return_int_or_dec(depth_min,2)}{depth_var}{MF.return_int_or_dec(depth_max,2)}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{MF.return_int_or_dec(height_min,2)}{height_var}{MF.return_int_or_dec(height_max,2)}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "def get_save_path_POPPLOT_data(save_path_spatial, binning_str, pop_str):\n",
    "        \n",
    "    save_path = save_path_spatial + \"data/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{binning_str}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{pop_str}/\"\n",
    "    MF.create_dir(save_path)\n",
    "        \n",
    "    return save_path\n",
    "\n",
    "def get_save_path_POPPLOT_sim(save_path_spatial, binning_str, pop_str):\n",
    "        \n",
    "    save_path = save_path_spatial + \"sim/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{binning_str}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{pop_str}/\"\n",
    "    MF.create_dir(save_path)\n",
    "        \n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metal_lowcut = -9999\n",
    "metal_lowcut = -1\n",
    "\n",
    "try:\n",
    "    data_trim = data[data['FeH']>=metal_lowcut]\n",
    "    print(f\"Chose minimum metallicity of {metal_lowcut}\" if metal_lowcut != -9999 else \"No minimum metallicity\")\n",
    "except NameError:\n",
    "    print(\"Working with simulation only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently chosen according to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_variable_lims = {\n",
    "    \"l\": [-2,2],\n",
    "    \"y\": [-0.1,0.1]\n",
    "}\n",
    "\n",
    "overall_height_variable_lims = {\n",
    "    \"b\": [1.5,9],\n",
    "    \"z\": [0.2,2]\n",
    "}\n",
    "\n",
    "extra_variable_lims = {\n",
    "    \"d\": [6.1,10.1],\n",
    "    \"R\": [0,3.5]\n",
    "}\n",
    "\n",
    "# CHOOSE\n",
    "# extra_variable = \"d\"\n",
    "extra_variable = \"R\"\n",
    "depth_var = \"l\"\n",
    "height_var = \"b\"\n",
    "\n",
    "if True: # print\n",
    "    depth_min,depth_max = depth_variable_lims[depth_var]\n",
    "    overall_height_min,overall_height_max = overall_height_variable_lims[height_var]\n",
    "    extra_min,extra_max = extra_variable_lims[extra_variable]\n",
    "    \n",
    "    print(depth_var,depth_min,depth_max)\n",
    "    print(height_var,overall_height_min,overall_height_max)\n",
    "    print(extra_variable,extra_min,extra_max)\n",
    "    \n",
    "if True: # assert\n",
    "    assert depth_min == -2 and depth_max == 2, \"Are you sure you don't want to have l between -2 and 2?\"\n",
    "    assert extra_min == 0 and extra_max == 3.5, \"Are you sure you don't want to have R between 0 and 3.5?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if height_var == \"b\":\n",
    "    o_b_range_min,o_b_range_max = PH.get_equal_n_minmax_b_ranges(data_trim, n_points=3,\\\n",
    "                                                                 extra_variable=extra_variable,extra_min=extra_min,extra_max=extra_max,\\\n",
    "                                                                 depth_min=depth_min,depth_max=depth_max,\\\n",
    "                                                                 overall_bmin=overall_height_min,overall_bmax=overall_height_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_bin_idx = 0\n",
    "\n",
    "if height_var == \"b\":\n",
    "    bmin = o_b_range_min[lat_bin_idx]\n",
    "    bmax = o_b_range_max[lat_bin_idx]\n",
    "\n",
    "    print(bmin, MF.return_int_or_dec(bmin,2))\n",
    "    print(bmax, MF.return_int_or_dec(bmax,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will apply the same latitude binning (using 0R3.5) for the different radial variations (eg 0R2, for which the equal-number latitude binning would change slightly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In bulk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_variable_lims = {\n",
    "    \"l\": [-2,2],\n",
    "    \"y\": [coordinates.ang_to_rect(ang=-2,x=coordinates.get_solar_radius()), coordinates.ang_to_rect(ang=2,x=coordinates.get_solar_radius())]\n",
    "}\n",
    "\n",
    "height_variable_lims = {\n",
    "    \"b\": [bmin,bmax],\n",
    "    \"z\": [coordinates.ang_to_rect(bmin,x=R0), coordinates.ang_to_rect(bmax,x=R0)]\n",
    "} if \"bmin\" in globals() and \"bmax\" in globals() else {\n",
    "    \"b\": [1.5,9],\n",
    "    \"z\": [0.2,2]\n",
    "}\n",
    "\n",
    "z_range_min = [coordinates.ang_to_rect(bmin,x=R0) for bmin in o_b_range_min]\n",
    "z_range_max = [coordinates.ang_to_rect(bmax,x=R0) for bmax in o_b_range_max]\n",
    "\n",
    "extra_variable_lims = {\n",
    "    \"d\": [6.1,10.1],\n",
    "    \"R\": [0,3.5]\n",
    "}\n",
    "\n",
    "# CHOOSE\n",
    "# extra_variable = \"d\"\n",
    "extra_variable = \"R\"\n",
    "depth_var = \"l\"\n",
    "height_var = \"b\"\n",
    "\n",
    "if True: # print\n",
    "    depth_min,depth_max = depth_variable_lims[depth_var]\n",
    "    height_min,height_max = height_variable_lims[height_var]\n",
    "    extra_min,extra_max = extra_variable_lims[extra_variable]\n",
    "    \n",
    "    print(depth_var,depth_min,depth_max)\n",
    "    print(height_var,height_min,height_max)\n",
    "    print(extra_variable,extra_min,extra_max)\n",
    "    \n",
    "    print(\"\\nz ranges:\")\n",
    "    print(z_range_min)\n",
    "    print(z_range_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_ranges(df_extra, binning_type=\"equalN\", n_points=20, plot_median_bool=False):\n",
    "    if binning_type == \"manual\":\n",
    "\n",
    "        if old_subplots:\n",
    "    #         pop_str_sim = \"0to9in1_oldSplit\"\n",
    "    #         pop_min_range = np.array([0,4,5,6,7,8, 9,   9.5, 9.8,  9.9,   9.925, 9.95, 9.975])\n",
    "    #         pop_max_range = np.array([4,5,6,7,8,9, 9.5, 9.8, 10,   9.925, 9.95,  9.975, 10])\n",
    "\n",
    "            pop_str_sim = \"4to9in1_oldSplit\"\n",
    "            pop_min_range = np.array([4,5,6,7,8, 9,   9.5, 9.8,  9.9,   9.925, 9.95, 9.975])\n",
    "            pop_max_range = np.array([5,6,7,8,9, 9.5, 9.8, 10,   9.925, 9.95,  9.975, 10])\n",
    "\n",
    "            max_age_lim = 9\n",
    "\n",
    "            limit_index = np.where(pop_max_range == max_age_lim)[0][0] + 1\n",
    "        else:\n",
    "            pop_str_sim = \"4to10in1\"\n",
    "            pop_min_range = np.array([min_age,5,6,7,8, 9])\n",
    "            pop_max_range = np.array([5,6,7,8,9, max_age])\n",
    "\n",
    "    elif binning_type == \"equalN\":\n",
    "        all_age_bins = PH.get_equal_n_bin_edges(val_array=df_extra[\"age\"].values,n_bins=n_points,pandas_way=True)\n",
    "\n",
    "        pop_min_range = all_age_bins[:-1]\n",
    "        pop_max_range = all_age_bins[1:]\n",
    "\n",
    "        pop_str_sim = f\"{n_points}_datapoints\"\n",
    "\n",
    "    elif binning_type == \"equalSteps\":\n",
    "\n",
    "        all_age_bins = np.linspace(min_age,max_age,n_points+1)\n",
    "        pop_min_range = all_age_bins[:-1]\n",
    "        pop_max_range = all_age_bins[1:]\n",
    "\n",
    "        pop_str_sim = f\"{n_points}_datapoints\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown binning method.\")\n",
    "\n",
    "    assert len(pop_min_range) == len(pop_max_range), \"Lengths need to be equal\"\n",
    "\n",
    "    if plot_median_bool:\n",
    "        \"\"\"\n",
    "        If I show the values as a surface (with fill_between) I'd rather plot at the mean (i.e. mid-point of the bin) because otherwise I need to give some other indication\n",
    "        of the width of each bin, and I don't want to show x-error bars as I imagine they'd overlap in an ugly way with the surface (although I have not tried).\n",
    "        \"\"\"\n",
    "\n",
    "        pop_plot_range = PH.get_range_medians(df_extra[\"age\"],pop_min_range,pop_max_range)\n",
    "    else:\n",
    "        pop_plot_range = PH.get_range_means(pop_min_range,pop_max_range)\n",
    "        \n",
    "    return pop_min_range,pop_max_range,pop_plot_range,pop_str_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do everything up to saving the arrays in a loop\n",
    "\n",
    "save_arrays_bool = True\n",
    "# save_arrays_bool = False\n",
    "\n",
    "min_pop,max_pop = 4,10\n",
    "pop_var = \"age\"\n",
    "xlabel = \"Age [Gyr]\" # needed in visualise_1D_binning\n",
    "\n",
    "bootstrap_repeat = 500\n",
    "min_star_number = 50\n",
    "\n",
    "vel_hist_bool = True\n",
    "velhist_bins = 50\n",
    "\n",
    "binning_type_list = len(n_points_list)*[\"equalSteps\"]\n",
    "plot_median_list = len(n_points_list)*[True]\n",
    "\n",
    "cuts_dict_list = [\n",
    "    {depth_var:[depth_min,depth_max],height_var:[o_b_range_min[0],o_b_range_max[0]],extra_variable:[0,3.5],pop_var:[min_pop,max_pop]},\n",
    "    {depth_var:[depth_min,depth_max],height_var:[o_b_range_min[0],o_b_range_max[0]],extra_variable:[0,2],pop_var:[min_pop,max_pop]},\n",
    "    {depth_var:[depth_min,depth_max],height_var:[o_b_range_min[1],o_b_range_max[1]],extra_variable:[0,3.5],pop_var:[min_pop,max_pop]},\n",
    "    {depth_var:[depth_min,depth_max],height_var:[o_b_range_min[1],o_b_range_max[1]],extra_variable:[0,2],pop_var:[min_pop,max_pop]},\n",
    "    {depth_var:[depth_min,depth_max],height_var:[o_b_range_min[2],o_b_range_max[2]],extra_variable:[0,3.5],pop_var:[min_pop,max_pop]},\n",
    "    {depth_var:[depth_min,depth_max],height_var:[o_b_range_min[2],o_b_range_max[2]],extra_variable:[0,2],pop_var:[min_pop,max_pop]}\n",
    "]\n",
    "\n",
    "n_points_list = [\n",
    "    40,\n",
    "    40,\n",
    "    20,\n",
    "    20,\n",
    "    10,\n",
    "    10\n",
    "]\n",
    "\n",
    "n_points_list_resampled = [\n",
    "    8, # or 7\n",
    "    8, # or 7\n",
    "    6,\n",
    "    5,\n",
    "    4, # or 5\n",
    "    3\n",
    "]\n",
    "\n",
    "vel_freq_list = [\n",
    "    4,\n",
    "    4,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    1\n",
    "]\n",
    "\n",
    "n_points_list = n_points_list_resampled if sim_resampled_bool else n_points_list\n",
    "vel_freq_list = [1]*len(n_points_list) if sim_resampled_bool else vel_freq_list\n",
    "\n",
    "assert len(cuts_dict_list)==len(n_points_list)==len(vel_freq_list)==len(binning_type_list)==len(plot_median_list), \"All lists must have the same length\"\n",
    "\n",
    "for i in range(len(cuts_dict_list)):\n",
    "    df_extra = MF.apply_cuts_to_df(df0,cuts_dict=cuts_dict_list[i])\n",
    "    \n",
    "    pop_min_range,pop_max_range,pop_plot_range,pop_str_sim = get_plot_ranges(df_extra, binning_type=binning_type_list[i],\\\n",
    "                                                                 n_points=n_points_list[i],plot_median_bool=plot_median_list[i])\n",
    "    \n",
    "    print(cuts_dict_list[i])\n",
    "    print(f\"{len(df_extra)} total stars\")\n",
    "    print(f\"pop_plot_range: {pop_plot_range}\")\n",
    "    print(\"Star numbers:\",stat.binned_statistic(values=None,x=df_extra[pop_var].values,bins=np.union1d(pop_min_range,pop_max_range),statistic=\"count\")[0])\n",
    "    \n",
    "    extra_min,extra_max = cuts_dict_list[i][extra_variable]\n",
    "    depth_min,depth_max = cuts_dict_list[i][depth_var]\n",
    "    height_min,height_max = cuts_dict_list[i][height_var]\n",
    "    \n",
    "    save_path_spatial = get_save_path_POPPLOT_spatial_cuts(sim_resampled_bool,extra_variable,extra_min,extra_max,depth_var,depth_min,depth_max,height_var,height_min,height_max)\n",
    "    save_path = get_save_path_POPPLOT_sim(save_path_spatial, binning_type_list[i], pop_str_sim)\n",
    "    \n",
    "    print(\"save_path:\",save_path)\n",
    "    \n",
    "    MP.visualise_1D_binning(df_extra[pop_var].values, pop_min_range, pop_max_range, hist_bins=100, log=True,\\\n",
    "                            save_bool=True,save_path=save_path,filename_prefix=pop_var,xlabel=xlabel,show_bool=True)\n",
    "\n",
    "    if vel_hist_bool:\n",
    "        save_path_hist = save_path + \"vel_histograms/\"\n",
    "        MF.create_dir(save_path_hist)\n",
    "\n",
    "        save_path_hist += f\"{velhist_bins}bins/\"\n",
    "        MF.create_dir(save_path_hist)\n",
    "\n",
    "        print(\"Saving velocity histograms on\\n\",save_path_hist)\n",
    "        \n",
    "    if True: # get arrays\n",
    "        map_dict = {}\n",
    "        for map_string in full_map_string_list:\n",
    "            map_dict[map_string] = np.zeros(shape=(len(pop_min_range)))\n",
    "\n",
    "        for pop_index, (popmin, popmax) in enumerate(zip(pop_min_range,pop_max_range)):\n",
    "\n",
    "            print(popmin,popmax,end=\";  \")\n",
    "\n",
    "            include_lims = \"both\" if pop_index==len(pop_min_range)-1 else \"min\"\n",
    "            df_pop = MF.apply_cuts_to_df(df_extra, cuts_dict={pop_var:[popmin,popmax]}, lims_dict={pop_var:include_lims})\n",
    "\n",
    "            if vel_hist_bool and pop_index % vel_freq_list[i] == 0:\n",
    "                name_suffix = f\"{str(MF.return_int_or_dec(popmin,dec=2))}pop{str(MF.return_int_or_dec(popmax,dec=2))}\"\n",
    "                MP.plot_velocity_histograms_both_stats(df_pop,vel_x_variable,vel_y_variable,save_bool=True,save_path=save_path_hist,suffix=name_suffix,verbose=pop_index==0,bins=velhist_bins)\n",
    "\n",
    "            values = val_err.get_all_variable_values_and_errors(df_pop[f\"v{vel_x_variable}\"].values,df_pop[f\"v{vel_y_variable}\"].values, full_map_string_list,\\\n",
    "                                                                    repeat=bootstrap_repeat, min_number = min_star_number)   \n",
    "\n",
    "            if len(values) != len(full_map_string_list):\n",
    "                raise ValueError(\"The length of the values list does not match the string list!\")\n",
    "\n",
    "            for map_string in full_map_string_list:\n",
    "                map_dict[map_string][pop_index] = values[map_string]\n",
    "\n",
    "        del df_pop\n",
    "        print(\"Done\")\n",
    "    \n",
    "    if save_arrays_bool:\n",
    "\n",
    "        array_path = save_path + \"arrays/\"\n",
    "        \n",
    "        overwrite = False\n",
    "        if os.path.isdir(array_path):\n",
    "            overwrite_str = input(\"There may be files already in this folder, do you want to overwrite them? Y/N\\n\")\n",
    "            if overwrite_str.upper() == \"Y\":\n",
    "                overwrite = True\n",
    "        else:\n",
    "            MF.create_dir(array_path)\n",
    "            overwrite = True\n",
    "            \n",
    "        if overwrite:\n",
    "\n",
    "            if True: # values as .txt and .npy\n",
    "\n",
    "                with open(array_path+'values.txt','w') as f:\n",
    "                    for key in map_dict:\n",
    "                        f.write(key+'\\n')\n",
    "                        np.savetxt(f,map_dict[key],fmt='%.5f')\n",
    "                        f.write('\\n')\n",
    "\n",
    "                for map_string in full_map_string_list:\n",
    "                    np.save(array_path+map_string, map_dict[map_string])\n",
    "\n",
    "            if True: # plot limits as .txt and .npy\n",
    "\n",
    "                with open(array_path+'pop_ranges.txt','w') as f:\n",
    "                    f.write(\"pop_min_range\\n\")\n",
    "                    for mini in pop_min_range:\n",
    "                        f.write(f\"{mini}\\t\")\n",
    "                    f.write(\"\\n\\npop_max_range\\n\")\n",
    "                    for maxi in pop_max_range:\n",
    "                        f.write(f\"{maxi}\\t\")\n",
    "                    f.write(\"\\n\\npop_plot_range\\n\")\n",
    "                    for p in pop_plot_range:\n",
    "                        f.write(f\"{p}\\t\")\n",
    "\n",
    "                np.save(array_path+\"pop_min_range\", pop_min_range)\n",
    "                np.save(array_path+\"pop_max_range\", pop_max_range)\n",
    "                np.save(array_path+\"pop_plot_range\", pop_plot_range)\n",
    "\n",
    "            print(\"Saved .txt and .npy in\",array_path)\n",
    "    else:\n",
    "        print(\"Not saving\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_variable_lims = {\n",
    "    \"l\": [-2,2],\n",
    "    \"y\": [coordinates.ang_to_rect(ang=-2,x=coordinates.get_solar_radius()), coordinates.ang_to_rect(ang=2,x=coordinates.get_solar_radius())]\n",
    "}\n",
    "\n",
    "height_variable_lims = {\n",
    "    \"b\": [bmin,bmax],\n",
    "    \"z\": [coordinates.ang_to_rect(bmin,x=R0), coordinates.ang_to_rect(bmax,x=R0)]\n",
    "} if \"bmin\" in globals() and \"bmax\" in globals() else {\n",
    "    \"b\": [1.5,9],\n",
    "    \"z\": [0.2,2]\n",
    "}\n",
    "\n",
    "extra_variable_lims = {\n",
    "    \"d\": [6.1,10.1],\n",
    "    \"R\": [0,2]\n",
    "}\n",
    "\n",
    "# CHOOSE\n",
    "# extra_variable = \"d\"\n",
    "extra_variable = \"R\"\n",
    "depth_var = \"l\"\n",
    "height_var = \"b\"\n",
    "\n",
    "if True: # print\n",
    "    depth_min,depth_max = depth_variable_lims[depth_var]\n",
    "    height_min,height_max = height_variable_lims[height_var]\n",
    "    extra_min,extra_max = extra_variable_lims[extra_variable]\n",
    "    \n",
    "    print(depth_var,depth_min,depth_max)\n",
    "    print(height_var,height_min,height_max)\n",
    "    print(extra_variable,extra_min,extra_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # xz young-old density plot\n",
    "    \n",
    "    # save_bool = True\n",
    "    save_bool = False\n",
    "\n",
    "    # projection = \"xy\"\n",
    "    projection = \"xz\"\n",
    "\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "\n",
    "    if True: # visualise cuts for young and old\n",
    "\n",
    "        xymax = 3.5\n",
    "\n",
    "        zmax = 2.2\n",
    "        zmin = (0 if zabs else -zmax) if projection == \"xz\" else 0.5\n",
    "\n",
    "        bins_x=70\n",
    "        density_bool=False\n",
    "\n",
    "        young_ages,old_ages = [4,7],[9.5,10]\n",
    "\n",
    "        if True:\n",
    "\n",
    "            aspect_ratio = 2*(zmax-zmin)/(1.5*xymax) if projection == \"xz\" else 1\n",
    "\n",
    "            fig,axs=plt.subplots(figsize=(10,aspect_ratio*10),nrows=2,gridspec_kw={\"hspace\":0})\n",
    "\n",
    "            if True: # quick show & colorbar\n",
    "\n",
    "                spatial_cut_dict = { depth_var:[depth_min,depth_max] } if projection == \"xz\" else { \"z\":[zmin,zmax]}\n",
    "                young_cut_dict,old_cut_dict = {\"age\":young_ages}, {\"age\":old_ages}\n",
    "\n",
    "                if projection == \"xz\":\n",
    "                    c1 = MP.quick_show_xz(MF.apply_cuts_to_df(df0,[spatial_cut_dict,young_cut_dict]),bins_x=bins_x,zmin=zmin,zmax=zmax,xmin=-xymax,xmax=xymax,show=False,density=density_bool)\n",
    "                    c2 = MP.quick_show_xz(MF.apply_cuts_to_df(df0,[spatial_cut_dict,old_cut_dict]),bins_x=bins_x,zmin=zmin,zmax=zmax,xmin=-xymax,xmax=xymax,show=False,density=density_bool)\n",
    "                elif projection == \"xy\":\n",
    "                    c1 = MP.quick_show_xy(MF.apply_cuts_to_df(df0,[spatial_cut_dict,young_cut_dict]),bins_x=bins_x,ymin=-xymax,ymax=xymax,xmin=-xymax,xmax=xymax,show=False,density=density_bool)\n",
    "                    c2 = MP.quick_show_xy(MF.apply_cuts_to_df(df0,[spatial_cut_dict,old_cut_dict]),bins_x=bins_x,ymin=-xymax,ymax=xymax,xmin=-xymax,xmax=xymax,show=False,density=density_bool)\n",
    "                else:\n",
    "                    raise ValueError(\"Only xy and xz currently supported\")\n",
    "\n",
    "                norm = PH.get_norm_from_count_list([c1,c2],log=True)\n",
    "\n",
    "                if projection == \"xz\":\n",
    "                    _ = MP.quick_show_xz(MF.apply_cuts_to_df(df0,[spatial_cut_dict,young_cut_dict]),bins_x=bins_x,zmin=zmin,zmax=zmax,xmin=-xymax,xmax=xymax,ax=axs[0],norm=norm,density=density_bool)\n",
    "                    _ = MP.quick_show_xz(MF.apply_cuts_to_df(df0,[spatial_cut_dict,old_cut_dict]),bins_x=bins_x,zmin=zmin,zmax=zmax,xmin=-xymax,xmax=xymax,ax=axs[1],norm=norm,density=density_bool)\n",
    "                elif projection == \"xy\":\n",
    "                    _ = MP.quick_show_xy(MF.apply_cuts_to_df(df0,[spatial_cut_dict,young_cut_dict]),bins_x=bins_x,ymin=-xymax,ymax=xymax,xmin=-xymax,xmax=xymax,ax=axs[0],norm=norm,density=density_bool)\n",
    "                    _ = MP.quick_show_xy(MF.apply_cuts_to_df(df0,[spatial_cut_dict,old_cut_dict]),bins_x=bins_x,ymin=-xymax,ymax=xymax,xmin=-xymax,xmax=xymax,ax=axs[1],norm=norm,density=density_bool)\n",
    "                else:\n",
    "                    raise ValueError(\"Only xy and xz currently supported\")\n",
    "\n",
    "                cbar = plt.colorbar(cm.ScalarMappable(norm=norm,cmap=\"viridis\"),ax=axs,shrink=0.8)\n",
    "                cbar.set_label(mass_density_label) if density_bool else cbar.set_label(r\"$N$\",rotation=0,labelpad=20)\n",
    "\n",
    "            if True: # visualise cuts & legend\n",
    "\n",
    "                cuts_to_visualise = {depth_var:[depth_max],height_var:[height_min,height_max],\"R\":[2,3.5],\"l\":[2]}\n",
    "                if height_var == \"z\":\n",
    "                    cuts_to_visualise[\"b\"] = [bmin,bmax]\n",
    "\n",
    "                filename,_ = MP.visualise_bulge_selection(given_axs=axs[::-1],projection=projection,cuts_dict=cuts_to_visualise,R0=R0)\n",
    "                _,_ = MP.visualise_bulge_selection(given_axs=axs,projection=projection,cuts_dict=cuts_to_visualise,R0=R0)\n",
    "\n",
    "                axs[0].legend(loc=\"upper right\" if projection==\"xy\" else \"upper left\",framealpha=0.8,ncols=1 if projection==\"xy\" else 2)\n",
    "\n",
    "            for i,ax in enumerate(axs): # lims, aspect, titles\n",
    "                ax.set_xlim(-xymax,xymax)\n",
    "                ax.set_ylim(zmin,zmax) if projection == \"xz\" else ax.set_ylim(-xymax,xymax)\n",
    "                ax.set_aspect(\"equal\")\n",
    "\n",
    "                if projection == \"xy\":\n",
    "                    ax.text(x=0.03,y=0.97,s=[\"Young\",\"Old\"][i],transform=ax.transAxes,bbox={\"facecolor\":\"w\",\"alpha\":0.9},ha=\"left\",va=\"top\")\n",
    "                if projection == \"xz\":\n",
    "                    ax.set_title([\"Young\",\"Old\"][i])\n",
    "\n",
    "            if True: # filename and saving\n",
    "\n",
    "                filename += f\"_{projection}\" if projection != \"both\" else \"\"\n",
    "\n",
    "                filename += f\"_{MF.return_int_or_dec(depth_min,2)}{depth_var}{MF.return_int_or_dec(depth_max,2)}\" if projection == \"xz\" \\\n",
    "                            else f\"_{MF.return_int_or_dec(zmin,2)}z{MF.return_int_or_dec(zmax,2)}\"\n",
    "\n",
    "                print(filename)\n",
    "\n",
    "                save_path = f\"{general_path}graphs/other_plots/visualise_bulge_cuts/youngold_cbar/{projection}/\"\n",
    "                save_path += \"resampled/\" if sim_resampled_bool else \"\"\n",
    "\n",
    "                if save_bool:\n",
    "                    print(\"Saving in:\",save_path)\n",
    "                    plt.savefig(save_path+filename+\".png\", dpi=200,bbox_inches=\"tight\")\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_age,max_age = 4,10\n",
    "\n",
    "df_extra = MF.apply_cuts_to_df(df0,cuts_dict={depth_var:[depth_min,depth_max],height_var:[height_min,height_max],\\\n",
    "                                              extra_variable:[extra_min,extra_max],\"age\":[min_age,max_age]})\n",
    "\n",
    "print(len(df_extra),\"stars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_plot_median = True\n",
    "sim_plot_median = False\n",
    "\n",
    "equal_number = False\n",
    "equal_steps = True\n",
    "manual_ages = False\n",
    "\n",
    "n_points_sim = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning\n",
    "\n",
    "assert manual_ages + equal_steps + equal_number == 1, \"Select a single option\"\n",
    "binning_str_sim = np.array([\"custom_range\",\"equalSteps\",\"equalN\"])[np.array([manual_ages,equal_steps,equal_number])][0]\n",
    "print(\"Using\",binning_str_sim)\n",
    "\n",
    "if manual_ages:\n",
    "    \n",
    "    if old_subplots:\n",
    "#         pop_str_sim = \"0to9in1_oldSplit\"\n",
    "#         pop_min_range = np.array([0,4,5,6,7,8, 9,   9.5, 9.8,  9.9,   9.925, 9.95, 9.975])\n",
    "#         pop_max_range = np.array([4,5,6,7,8,9, 9.5, 9.8, 10,   9.925, 9.95,  9.975, 10])\n",
    "\n",
    "        pop_str_sim = \"4to9in1_oldSplit\"\n",
    "        pop_min_range = np.array([4,5,6,7,8, 9,   9.5, 9.8,  9.9,   9.925, 9.95, 9.975])\n",
    "        pop_max_range = np.array([5,6,7,8,9, 9.5, 9.8, 10,   9.925, 9.95,  9.975, 10])\n",
    "        \n",
    "        max_age_lim = 9\n",
    "        \n",
    "        limit_index = np.where(pop_max_range == max_age_lim)[0][0] + 1\n",
    "    else:\n",
    "        pop_str_sim = \"4to10in1\"\n",
    "        pop_min_range = np.array([min_age,5,6,7,8, 9])\n",
    "        pop_max_range = np.array([5,6,7,8,9, max_age])\n",
    "\n",
    "elif equal_number:\n",
    "    all_age_bins = PH.get_equal_n_bin_edges(val_array=df_extra[\"age\"].values,n_bins=n_points_sim,pandas_way=True)\n",
    "    \n",
    "    pop_min_range = all_age_bins[:-1]\n",
    "    pop_max_range = all_age_bins[1:]\n",
    "    \n",
    "    pop_str_sim = f\"{n_points_sim}_datapoints\"\n",
    "    \n",
    "elif equal_steps:\n",
    "    \n",
    "    all_age_bins = np.linspace(min_age,max_age,n_points_sim+1)\n",
    "    pop_min_range = all_age_bins[:-1]\n",
    "    pop_max_range = all_age_bins[1:]\n",
    "    \n",
    "    pop_str_sim = f\"{n_points_sim}_datapoints\"\n",
    "    \n",
    "else:\n",
    "    raise ValueError(\"Unknown binning method.\")\n",
    "    \n",
    "assert len(pop_min_range) == len(pop_max_range), \"Lengths need to be equal\"\n",
    "\n",
    "if sim_plot_median:\n",
    "    \"\"\"\n",
    "    If I show the values as a surface (with fill_between) I'd rather plot at the mean (i.e. mid-point of the bin) because otherwise I need to give some other indication\n",
    "    of the width of each bin, and I don't want to show x-error bars as I imagine they'd overlap in an ugly way with the surface (although I have not tried).\n",
    "    \"\"\"\n",
    "    \n",
    "    pop_plot_range = PH.get_range_medians(df_extra[\"age\"],pop_min_range,pop_max_range)\n",
    "    print(\"Plotting at the median\\n\",pop_plot_range)\n",
    "else:\n",
    "    pop_plot_range = PH.get_range_means(pop_min_range,pop_max_range)\n",
    "    print(\"Plotting at the mean\\n\",pop_plot_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(10,2))\n",
    "\n",
    "ax.errorbar(x=pop_plot_range,xerr=PH.get_xerr(minima=pop_min_range,maxima=pop_max_range,plot=pop_plot_range,frac=1),y=[0]*n_points_sim,fmt=\"d\",capsize=20)\n",
    "ax.set_xlim(3.95,10.05)\n",
    "ax.minorticks_on()\n",
    "ax.set_yticks([])\n",
    "ax.invert_xaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of stars per bin\n",
    "stat.binned_statistic(values=None,x=df_extra[\"age\"].values,bins=all_age_bins,statistic=\"count\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lengths = []\n",
    "for individual_age in ages_range:\n",
    "    age_step = age_step_young if individual_age < age_limit_oldyoung else age_step_old\n",
    "    \n",
    "    age_max = individual_age + age_step\n",
    "    age_min = individual_age\n",
    "    df = df_extra[(df_extra.age>=age_min)&(df_extra.age<age_max)]\n",
    "    lengths.append(len(df))\n",
    "    print(\"Age interval\", np.float16(age_min), \"to\", np.float16(age_max),\"has\",len(df),\"stars\")\n",
    "print(\"Total number of stars selected across time:\",np.sum(lengths))\n",
    "print(\"Which is \"+str(np.float16(100*np.sum(lengths)/len(df0)))+\"% of the total\")\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_variable_lims = {\n",
    "    \"l\": [-2,2],\n",
    "    \"y\": [-0.1,0.1]\n",
    "}\n",
    "\n",
    "height_variable_lims = {\n",
    "    \"b\": [bmin,bmax],\n",
    "    \"z\": [np.tan(bmin*np.pi/180)*R0, np.tan(bmax*np.pi/180)*R0]\n",
    "} if \"bmin\" in globals() and \"bmax\" in globals() else {\n",
    "    \"b\": [1.5,9],\n",
    "    \"z\": [0.2,2]\n",
    "}\n",
    "\n",
    "extra_variable_lims = {\n",
    "    \"d\": [6.1,10.1],\n",
    "    \"R\": [0,3.5]\n",
    "}\n",
    "\n",
    "# CHOOSE\n",
    "# extra_variable = \"d\"\n",
    "extra_variable = \"R\"\n",
    "depth_var = \"l\"\n",
    "height_var = \"b\"\n",
    "\n",
    "if True: # print\n",
    "    depth_min,depth_max = depth_variable_lims[depth_var]\n",
    "    height_min,height_max = height_variable_lims[height_var]\n",
    "    extra_min,extra_max = extra_variable_lims[extra_variable]\n",
    "    \n",
    "    print(depth_var,depth_min,depth_max)\n",
    "    print(height_var,height_min,height_max)\n",
    "    print(extra_variable,extra_min,extra_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_extra = MF.apply_cuts_to_df(data_trim,cuts_dict={depth_var:[depth_min,depth_max],height_var:[height_min,height_max],\\\n",
    "                                              extra_variable:[extra_min,extra_max]})\n",
    "\n",
    "print(len(data_extra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_number = True # divide in equal-number bins across all metallicities\n",
    "manual_metal = False\n",
    "equal_steps = False # divide in constant metallicity steps\n",
    "\n",
    "plot_median_bool = True\n",
    "# plot_median_bool = False # mid-point of bin\n",
    "\n",
    "n_points_data = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert manual_metal + equal_steps + equal_number == 1, \"Select a single option\"\n",
    "binning_str_data = np.array([\"custom_range\",\"equalSteps\",\"equalN\"])[np.array([manual_metal,equal_steps,equal_number])][0]\n",
    "\n",
    "if manual_metal:\n",
    "    min_metal,max_metal = min(data_extra[\"FeH\"]),max(data_extra['FeH'])\n",
    "    \n",
    "    pop_str_data = \"metal_cuts_equal\"\n",
    "    pop_min_range = np.array([min_metal, -0.55, -0.25, 0.15])\n",
    "    pop_max_range = np.array([-0.55,-0.25,0.15,max_metal])\n",
    "\n",
    "#     pop_str_data = \"metal_cuts_A\"\n",
    "#     pop_min_range = np.array([min_metal, -0.7, -0.4, -0.1, 0.3])\n",
    "#     pop_max_range = np.array([-0.7,-0.4,0.1,0.3,max_metal])\n",
    "    \n",
    "#     pop_str_data = \"metal_cuts_B\"\n",
    "#     pop_min_range = np.array([min_metal, -1, -0.5, 0,0.3])\n",
    "#     pop_max_range = np.array([-1,-0.5,0,0.3,max_metal])\n",
    "    \n",
    "#     pop_str_data = \"all_poor\"\n",
    "#     pop_max_range = np.array([-1.3,-1.2,-1.1,-1.0,-0.9,-0.8,-0.7])\n",
    "#     pop_min_range = np.array([min_metal]*len(pop_max_range))\n",
    "\n",
    "#     pop_str_data = \"axisymmetric\"\n",
    "#     pop_min_range = np.array([-1.2, -1.2, -1.2, -1.1,-1.1, -1,-1,-1])\n",
    "#     pop_max_range = np.array([-0.9,-0.8,-0.7,-0.9,-0.8,-0.7, -0.6,-0.5])\n",
    "\n",
    "#     pop_str_data = \"all_rich\"\n",
    "#     pop_min_range = np.array([-0.9,-0.8,-0.7,-0.6,-0.5,-0.4,-0.3,-0.2,-0.1,0])\n",
    "#     pop_max_range = np.array([max_metal]*len(pop_min_range))\n",
    "    \n",
    "    pass\n",
    "elif equal_steps:\n",
    "    min_metal = data_extra['FeH'].min()\n",
    "    metal_step = 0.1\n",
    "    pop_min_range = np.arange(min_metal,data_extra['FeH'].max(),metal_step)\n",
    "    pop_max_range = pop_min_range + metal_step\n",
    "    \n",
    "    pop_str_data = f\"{metal_step}step\"  \n",
    "elif equal_number:\n",
    "    \n",
    "    pop_str_data = f\"{n_points_data}_datapoints\"\n",
    "    \n",
    "    metal_edges = PH.get_equal_n_bin_edges(data_extra.FeH.values, n_points_data)\n",
    "    pop_max_range = metal_edges[1:]\n",
    "    pop_min_range = metal_edges[:-1]\n",
    "\n",
    "if True: # pop_plot_range\n",
    "    if manual_metal and range_str in [\"all_rich\",\"all_poor\"]:\n",
    "        if range_str == \"all_rich\":\n",
    "            pop_plot_range = pop_min_range\n",
    "        if range_str == \"all_poor\":\n",
    "            pop_plot_range = pop_max_range\n",
    "    elif plot_median_bool:\n",
    "        pop_plot_range = PH.get_range_medians(data_extra.FeH.values, pop_min_range, pop_max_range)\n",
    "    else:\n",
    "        pop_plot_range = np.array([np.mean([m,M]) for m,M in zip(pop_min_range,pop_max_range)])\n",
    "    \n",
    "assert len(pop_min_range) == len(pop_max_range), \"Lengths need to be equal\"\n",
    "print(pop_plot_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_spatial = get_save_path_POPPLOT_spatial_cuts(sim_resampled_bool,extra_variable,extra_min,extra_max,depth_var,depth_min,depth_max,height_var,height_min,height_max)\n",
    "\n",
    "if data_bool:\n",
    "    save_path = get_save_path_POPPLOT_data(save_path_spatial, binning_str_data, pop_str_data)\n",
    "else:\n",
    "    save_path = get_save_path_POPPLOT_sim(save_path_spatial, binning_str_sim, pop_str_sim)\n",
    "    \n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_extra if data_bool else df_extra\n",
    "pop_var = \"FeH\" if data_bool else \"age\"\n",
    "xlabel = \"[Fe/H]\" if data_bool else \"Age [Gyr]\"\n",
    "\n",
    "MP.visualise_1D_binning(df[pop_var].values, pop_min_range, pop_max_range, hist_bins=100, log=False,\\\n",
    "                        save_bool=True,save_path=save_path,filename_prefix=pop_var,xlabel=xlabel)\n",
    "\n",
    "if not data_bool:\n",
    "    MP.visualise_1D_binning(df[pop_var].values, pop_min_range, pop_max_range, hist_bins=100, log=True,\\\n",
    "                            save_bool=True,save_path=save_path,filename_prefix=pop_var,xlabel=xlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_repeat = 500\n",
    "min_star_number = 50 if not data_bool else 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_hist_bool = True\n",
    "# vel_hist_bool = False\n",
    "\n",
    "velhist_bins = 50 if not data_bool else 20\n",
    "\n",
    "if vel_hist_bool:\n",
    "    save_path_hist = save_path + \"vel_histograms/\"\n",
    "    MF.create_dir(save_path_hist)\n",
    "    \n",
    "    save_path_hist += f\"{velhist_bins}bins/\"\n",
    "    MF.create_dir(save_path_hist)\n",
    "    \n",
    "    print(\"Saving velocity histograms on\\n\",save_path_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if vel_hist_bool:\n",
    "    MP.plot_velocity_histograms_both_stats(df[(df[pop_var]>=min(pop_min_range))&(df[pop_var]<=min(pop_max_range))],vel_x_variable,vel_y_variable,\\\n",
    "                                           bins=velhist_bins,colour_var=\"x\",save_bool=False,suffix=\"example\",verbose=True,show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = {}\n",
    "for map_string in full_map_string_list:\n",
    "    map_dict[map_string] = np.zeros(shape=(len(pop_min_range)))\n",
    "    \n",
    "map_dict[\"mean_b\"] = np.zeros(shape=(len(pop_min_range)))\n",
    "map_dict[\"std_b\"] = np.zeros(shape=(len(pop_min_range)))\n",
    "\n",
    "for pop_index, (popmin, popmax) in enumerate(zip(pop_min_range,pop_max_range)):\n",
    "\n",
    "    print(popmin,popmax)\n",
    "    \n",
    "    include_lims = \"both\" if pop_index==len(pop_min_range)-1 else \"min\"\n",
    "    df_pop = MF.apply_cuts_to_df(df, cuts_dict={pop_var:[popmin,popmax]}, lims_dict={pop_var:include_lims})\n",
    "        \n",
    "    if vel_hist_bool:\n",
    "        name_suffix = f\"{str(MF.return_int_or_dec(popmin,dec=2))}pop{str(MF.return_int_or_dec(popmax,dec=2))}\"\n",
    "        MP.plot_velocity_histograms_both_stats(df_pop,vel_x_variable,vel_y_variable,save_bool=True,save_path=save_path_hist,suffix=name_suffix,verbose=pop_index==0,bins=velhist_bins)\n",
    "        \n",
    "    values = val_err.get_all_variable_values_and_errors(df_pop[f\"v{vel_x_variable}\"].values,df_pop[f\"v{vel_y_variable}\"].values, full_map_string_list,\\\n",
    "                                                            repeat=bootstrap_repeat, min_number = min_star_number)   \n",
    "\n",
    "    if len(values) != len(full_map_string_list):\n",
    "        raise ValueError(\"The length of the values list does not match the string list!\")\n",
    "\n",
    "    for map_string in full_map_string_list:\n",
    "        map_dict[map_string][pop_index] = values[map_string]\n",
    "        \n",
    "    map_dict[\"mean_b\"][pop_index] = np.mean(df_pop[\"b\"])\n",
    "    map_dict[\"std_b\"][pop_index] = np.std(df_pop[\"b\"])\n",
    "    \n",
    "del df_pop\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(map_dict['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save arrays\n",
    "\n",
    "array_path = save_path + \"arrays/\"\n",
    "MF.create_dir(array_path)\n",
    "\n",
    "if True: # values as .txt and .npy\n",
    "            \n",
    "    with open(array_path+'values.txt','w') as f:\n",
    "        for key in map_dict:\n",
    "            f.write(key+'\\n')\n",
    "            np.savetxt(f,map_dict[key],fmt='%.5f')\n",
    "            f.write('\\n')\n",
    "    \n",
    "    for map_string in full_map_string_list:\n",
    "        np.save(array_path+map_string, map_dict[map_string])\n",
    "        \n",
    "if True: # plot limits as .txt and .npy\n",
    "\n",
    "    with open(array_path+'pop_ranges.txt','w') as f:\n",
    "        f.write(\"pop_min_range\\n\")\n",
    "        for mini in pop_min_range:\n",
    "            f.write(f\"{mini}\\t\")\n",
    "        f.write(\"\\n\\npop_max_range\\n\")\n",
    "        for maxi in pop_max_range:\n",
    "            f.write(f\"{maxi}\\t\")\n",
    "        f.write(\"\\n\\npop_plot_range\\n\")\n",
    "        for p in pop_plot_range:\n",
    "            f.write(f\"{p}\\t\")\n",
    "    \n",
    "    np.save(array_path+\"pop_min_range\", pop_min_range)\n",
    "    np.save(array_path+\"pop_max_range\", pop_max_range)\n",
    "    np.save(array_path+\"pop_plot_range\", pop_plot_range)\n",
    "    \n",
    "print(\"Saved .txt and .npy in\",array_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POPPLOT functions\n",
    "\n",
    "# Takes global: bar_log, bar_width\n",
    "def POPPLOT_number_bar(barax, plot_range, number_array,color,alpha=1,zorder=0, bar_width=50):\n",
    "    barax.bar(plot_range,number_array,width=bar_width,log=bar_log,color=color,alpha=alpha,zorder=zorder)\n",
    "        \n",
    "def POPPLOT_values_scatter(ax, val_array, err_array, plot_range, min_range, max_range, color, label,line_alpha=1,zorder=0,lines_bool=True,x_error_bool=True):\n",
    "    xerror = PH.get_xerr(min_range,max_range,plot_range)\n",
    "\n",
    "    ax.errorbar(plot_range,val_array,yerr=err_array,xerr=xerror if x_error_bool else None,capsize=capsize,marker='.',color=color,\\\n",
    "                label=label,linestyle=None if lines_bool else '',alpha=line_alpha,zorder=zorder)\n",
    "\n",
    "def POPPLOT_values_surface(ax, val_array, err_array, plot_range,color,label,line_alpha=1,surface_alpha=0.75,zorder=0):\n",
    "    ax.plot(plot_range,val_array,color=color,alpha=line_alpha,zorder=zorder)\n",
    "    ax.fill_between(plot_range,val_array-err_array,val_array+err_array,label=label,color=color,alpha=surface_alpha,linewidth=0,zorder=zorder)\n",
    "        \n",
    "def POPPLOT_number_bar_axis_settings(barax,min_n,max_n,bar_log=True,labels_on=True,min_shift_bool=True,max_shift_bool=True):\n",
    "    if bar_log:\n",
    "        exponent_ticks = np.arange(MF.get_exponent(min_n),MF.get_exponent(max_n)+1,1)\n",
    "        barax.set_yticks([10**i for i in exponent_ticks])\n",
    "        barax.set_ylim(bottom = 10**min(exponent_ticks) - (min_n/3 if min_shift_bool else 0))\n",
    "        barax.set_ylim(top = max_n + (10**MF.get_exponent(max_n) if max_shift_bool else 0))\n",
    "    elif equal_number:\n",
    "        barax.set_yticks([0,max_n])\n",
    "            \n",
    "    barax.yaxis.set_tick_params(which='minor', right=True,left=False)\n",
    "\n",
    "    barax.tick_params(which='both',labelleft=False,labelright=labels_on)\n",
    "    barax.tick_params(which='minor',labelright=False)\n",
    "\n",
    "    if labels_on:\n",
    "        barax.set_ylabel(r\"$N$\",rotation=0,labelpad=20)\n",
    "        barax.yaxis.set_label_position(\"right\")\n",
    "    \n",
    "def POPPLOT_xaxis_settings(ax,xmin,xmax,xlabel,xticks=None,labels_on=True):\n",
    "#     ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.25))\n",
    "    \n",
    "    ax.set_xlim(xmin,xmax)\n",
    "    \n",
    "    if xticks is not None:\n",
    "        ax.set_xticks(xticks)\n",
    "    \n",
    "    if labels_on:\n",
    "        ax.set_xlabel(xlabel)\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "def _POPPLOT_compute_ylims(map_dict, map_string, error_string, var1_bool=False):\n",
    "    minimum = np.nanmin(map_dict[map_string]-map_dict[error_string])\n",
    "    maximum = np.nanmax(map_dict[map_string]+map_dict[error_string])\n",
    "\n",
    "    if var1_bool:\n",
    "        minimum1 = np.nanmin(map_dict[var1]-map_dict[err1])\n",
    "        maximum1 = np.nanmax(map_dict[var1]+map_dict[err1])\n",
    "\n",
    "        minimum = min([minimum,minimum1])\n",
    "        maximum = max([maximum,maximum1])\n",
    "    \n",
    "    if map_string in yshift_dict:\n",
    "        minimum -= yshift_dict[map_string]\n",
    "        maximum += yshift_dict[map_string]\n",
    "\n",
    "    if symmetric_ylims_bool:\n",
    "        maxabs = np.nanmax(np.abs([minimum,maximum]))\n",
    "        ax.set_ylim(-maxabs,maxabs)\n",
    "    else:\n",
    "        ax.set_ylim(minimum,maximum)\n",
    "        \n",
    "def POPPLOT_yaxis_settings(ax, map_string, error_string, map_dict=None, labels_on=True,var1_bool=False, set_ylims=True):\n",
    "    \n",
    "    if map_string == 'tilt_abs':# or \"mean\" in map_string or \"std\" in map_string:\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "        #ax.yaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "    elif map_string == 'anisotropy':# or map_string == 'correlation':\n",
    "#         ax.yaxis.set_major_locator(ticker.MultipleLocator(0.25))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "        ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.25))\n",
    "    elif map_string == \"correlation\":\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(0.15))\n",
    "#     elif map_string in [\"mean_vx\",\"mean_vy\"]:\n",
    "#         ax.yaxis.set_major_locator(ticker.MultipleLocator(15))\n",
    "    elif map_string in [\"std_vx\",\"std_vy\"]:\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "    \n",
    "    if not var1_bool and labels_on:\n",
    "        ax.set_ylabel(symbol_dict[map_string]+units_dict[map_string],fontsize=ylabel_size)\n",
    "    \n",
    "    if set_ylims:\n",
    "        if hard_coded_ylims_bool and map_string in hard_coded_ylims:\n",
    "            ax.set_ylim(hard_coded_ylims[map_string])\n",
    "        else:\n",
    "            if map_dict is None:\n",
    "                raise ValueError(\"Cannot compute ylims if `map_dict` is None.\")\n",
    "            _POPPLOT_compute_ylims(map_dict, map_string, error_string, var1_bool=var1_bool)\n",
    "        \n",
    "    if not labels_on:\n",
    "        ax.set_yticklabels([])\n",
    "        \n",
    "def get_label(map_string):\n",
    "    return symbol_dict[map_string]+units_dict[map_string]\n",
    "\n",
    "def get_legend_label(var_tuple,variable):\n",
    "    var_symbol = pos_symbols_dict[variable]\n",
    "    var_units = pos_units_dict[variable]\n",
    "    \n",
    "    if var_tuple[0] == 0:\n",
    "        return var_symbol + fr\"$< {var_tuple[1]}~$\"+var_units\n",
    "    else:\n",
    "        return r\"$%s<$\"%str(var_tuple[0]) + var_symbol + r\"$/\\mathrm{%s}$\"%var_units + fr\"$<{var_tuple[1]}$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_values_and_plot_ranges(path,full_map_string_list):\n",
    "    \n",
    "    map_dict = {}\n",
    "    for m in full_map_string_list:\n",
    "        map_dict[m] = np.load(f\"{path}{m}.npy\")\n",
    "    \n",
    "    min_range = np.load(path + f\"pop_min_range.npy\")\n",
    "    max_range = np.load(path + f\"pop_max_range.npy\")\n",
    "    plot_range = np.load(path + f\"pop_plot_range.npy\")\n",
    "    \n",
    "    return map_dict, min_range, max_range, plot_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_units_dict[\"b\"] = \"deg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some reference values\n",
    "\n",
    "l_cuts = [-2,2]\n",
    "y_cuts = MF.return_int_or_dec_for_array([coordinates.ang_to_rect(ang=l_cut,x=coordinates.get_solar_radius()) for l_cut in l_cuts])\n",
    "\n",
    "b_range_min,b_range_max = PH.get_equal_n_minmax_b_ranges(data_trim)\n",
    "b_variations = [[MF.return_int_or_dec(m,2),MF.return_int_or_dec(M,2)] for (m,M) in zip(b_range_min,b_range_max)]\n",
    "\n",
    "z_range_min = [coordinates.ang_to_rect(ang=bmin,x=coordinates.get_solar_radius()) for bmin in b_range_min]\n",
    "z_range_max = [coordinates.ang_to_rect(ang=bmax,x=coordinates.get_solar_radius()) for bmax in b_range_max]\n",
    "z_variations = [[MF.return_int_or_dec(m,2),MF.return_int_or_dec(M,2)] for (m,M) in zip(z_range_min,z_range_max)]\n",
    "\n",
    "R_variations = [[0,3.5],[0,2]]\n",
    "\n",
    "print(\"l\",l_cuts)\n",
    "print(\"y\",y_cuts)\n",
    "print(\"b\",b_variations)\n",
    "print(\"z\",z_variations)\n",
    "print(\"R\",R_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://colorbrewer2.org/#type=qualitative&scheme=Dark2&n=3\n",
    "\n",
    "# colors = [\"blue\",\"blue\",\"blue\"]\n",
    "colors = [\"#1b9e77\",\"#d95f02\",\"#7570b3\"]\n",
    "\n",
    "line_alpha = 0.9\n",
    "surface_alpha = 0.75\n",
    "alpha_reduction_factor = 0.25\n",
    "\n",
    "number_alpha = 0.75\n",
    "number_alpha_reduction_factor = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim galactic vs rectangular 3 columns\n",
    "\n",
    "# binning_type = \"equalN\"\n",
    "binning_type = \"equalSteps\"\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/1.5b3.51/sim/{binning_type}/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-0.28y0.28/0.21z0.5/sim/{binning_type}/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/1.5b3.51/sim/{binning_type}/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-0.28y0.28/0.21z0.5/sim/{binning_type}/40_datapoints/arrays/\"\n",
    "        ],\n",
    "        \"labels\": [None,None,get_legend_label([1.5,3.51],\"b\"),get_legend_label([0.21,0.5],\"z\")],\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/3.51b6.6/sim/{binning_type}/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-0.28y0.28/0.5z0.94/sim/{binning_type}/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/3.51b6.6/sim/{binning_type}/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-0.28y0.28/0.5z0.94/sim/{binning_type}/20_datapoints/arrays/\"\n",
    "        ],\n",
    "        \"labels\": [None,None,get_legend_label([3.51, 6.6],\"b\"),get_legend_label([0.5,0.94],\"z\")],\n",
    "    },\n",
    "    2: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/7.13b8.85/sim/{binning_type}/10_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-0.28y0.28/1.01z1.26/sim/{binning_type}/10_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/7.13b8.85/sim/{binning_type}/10_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-0.28y0.28/1.01z1.26/sim/{binning_type}/10_datapoints/arrays/\"\n",
    "        ],\n",
    "        \"labels\": [None,None,get_legend_label([7.13, 8.85],\"b\"),get_legend_label([0.5,0.94],\"z\")],\n",
    "    },   \n",
    "}\n",
    "\n",
    "save_path = get_base_POPPLOT_path(resampled_sim_bool=False) + \\\n",
    "            f\"0R3.5_0R2/-2l2_-0.28y0.28/1.5b3.51_0.21z0.5__3.51b6.6_0.5z0.94__7.13b8.85_1.01z1.26/sim/sim_{binning_type}/sim_n40,40_n40,40__n20,20_n20,20__n10,10_n10,10/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [5,6,7,8]\n",
    "    all_dicts[key][\"colors\"] = 2*[\"blue\", \"orange\"]\n",
    "    all_dicts[key][\"line_alphas\"] = 2*[alpha_reduction_factor*line_alpha] + 2*[line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 2*[alpha_reduction_factor*surface_alpha] + 2*[surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = 2*[number_alpha_reduction_factor*number_alpha] + 2*[number_alpha]\n",
    "    all_dicts[key][\"zorderNs\"] = [6,6,5,5]\n",
    "    all_dicts[key][\"plot_ranges_str\"] = nplots*[\"mean\"]\n",
    "    all_dicts[key][\"surface_bools\"] = nplots*[True]\n",
    "    all_dicts[key][\"scatter_join_bools\"] = nplots*[True]\n",
    "    all_dicts[key][\"number_bools\"] = [False,False,True,True]\n",
    "    \n",
    "    all_dicts[key][\"invert_xaxis\"] = True\n",
    "    all_dicts[key][\"title\"] = None\n",
    "    all_dicts[key][\"xaxis_label\"] = \"Age [Gyr]\"\n",
    "    all_dicts[key][\"x_ticks\"] = np.arange(5,11,1) #np.arange(-0.9,0.6+0.3,0.3)\n",
    "    all_dicts[key][\"x_lims\"] = [4,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim normal vs resampled 3 columns\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/sim/equalN/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/sim/equalN/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R2/-2l2/1.5b3.51/sim/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R3.5/-2l2/1.5b3.51/sim/equalN/4_datapoints/arrays/\",\n",
    "\n",
    "        ],\n",
    "        \"title\": get_legend_label([1.5,3.51],\"b\"),\n",
    "        \"labels\": 4*[None],\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/sim/equalN/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/sim/equalN/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R2/-2l2/3.51b6.6/sim/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R3.5/-2l2/3.51b6.6/sim/equalN/4_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": get_legend_label([3.51,6.6],\"b\"),\n",
    "        \"labels\": [None,\"Model\",None,\"Resampled model (k=10)\"]\n",
    "    },\n",
    "    2: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/sim/equalN/15_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/sim/equalN/15_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R2/-2l2/7.13b8.85/sim/equalN/3_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R3.5/-2l2/7.13b8.85/sim/equalN/3_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": get_legend_label([7.13,8.85],\"b\"),\n",
    "        \"labels\": 4*[None]\n",
    "    },\n",
    "    \n",
    "}\n",
    "\n",
    "save_path = get_base_POPPLOT_path(resampled_sim_bool=False) + \\\n",
    "            \"sim__resampled_sim/0R3.5_0R2/-2l2/1.5b3.51__3.51b6.6__7.13b8.85/sim_equalN/sim_n20,20_n4,4__n20,20_n4,4__n15,15_n3,3/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [5,6,7,8]\n",
    "    all_dicts[key][\"zorderNs\"] = [5,5,6,6]\n",
    "    all_dicts[key][\"colors\"] = [\"blue\",\"blue\",\"orange\",\"orange\"]\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = 2*[alpha_reduction_factor*line_alpha, line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 2*[alpha_reduction_factor*surface_alpha, surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    \n",
    "    all_dicts[key][\"plot_ranges_str\"] = [\"mean\",\"mean\",\"median\",\"median\"]\n",
    "    all_dicts[key][\"surface_bools\"] = [True,True,False,False]\n",
    "    all_dicts[key][\"scatter_join_bools\"] = nplots*[True]\n",
    "    all_dicts[key][\"number_bools\"] = [False,True,False,True]\n",
    "    \n",
    "    all_dicts[key][\"invert_xaxis\"] = True\n",
    "    all_dicts[key][\"xaxis_label\"] = \"Age [Gyr]\"\n",
    "    all_dicts[key][\"x_ticks\"] = np.arange(5,11,1) #np.arange(-0.9,0.6+0.3,0.3)\n",
    "    all_dicts[key][\"x_lims\"] = [4,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data and sim 2 columns (sim equalN)\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Data\",\n",
    "        \"labels\": 6*[None],\n",
    "        \"plot_ranges_str\": 6*[\"median\"],\n",
    "        \"surface_bools\": 6*[False],\n",
    "        \"invert_xaxis\": False,\n",
    "        \"xaxis_label\": \"[Fe/H]\",\n",
    "        \"x_ticks\": np.arange(-0.9,0.6+0.3,0.3),\n",
    "        \"x_lims\": [-1,0.61]\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/sim/equalN/30_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/sim/equalN/30_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/sim/equalN/25_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/sim/equalN/30_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/sim/equalN/30_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/sim/equalN/25_datapoints/arrays/\",\n",
    "\n",
    "        ],\n",
    "        \"title\": \"Model\",\n",
    "        \"labels\": 3*[None] + [get_legend_label([1.5,3.51],\"b\"), get_legend_label([3.51,6.6],\"b\"), get_legend_label([7.13,8.85],\"b\")],\n",
    "        \"plot_ranges_str\": 6*[\"mean\"],\n",
    "        \"surface_bools\": 6*[True],\n",
    "        \"invert_xaxis\": True,\n",
    "        \"xaxis_label\": \"Age [Gyr]\",\n",
    "        \"x_ticks\": np.arange(5,10,1),\n",
    "        \"x_lims\": [4,10]\n",
    "    }, \n",
    "}\n",
    "\n",
    "save_path = get_base_POPPLOT_path(resampled_sim_bool=False) + \\\n",
    "            \"0R3.5_0R2/-2l2/1.5b3.51_3.51b6.6_7.13b8.85/both/data_equalN/data_n4,4,3_n4,4,3/sim_equalN/sim_n30,30,25_n30,30,25/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [5,4,3,8,7,6]\n",
    "    all_dicts[key][\"zorderNs\"] = [5,5,5,6,7,8]\n",
    "    all_dicts[key][\"colors\"] = 2*colors\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = 3*[alpha_reduction_factor*line_alpha] + 3*[line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 3*[alpha_reduction_factor*surface_alpha] + 3*[surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    \n",
    "    all_dicts[key][\"number_bools\"] = 3*[False] + 3*[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data and sim 2 columns (sim equalSteps)\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Data\",\n",
    "        \"labels\": 6*[None],\n",
    "        \"plot_ranges_str\": 6*[\"median\"],\n",
    "        \"surface_bools\": 6*[False],\n",
    "        \"invert_xaxis\": False,\n",
    "        \"xaxis_label\": \"[Fe/H]\",\n",
    "        \"x_ticks\": np.arange(-0.9,0.6+0.3,0.3),\n",
    "        \"x_lims\": [-1,0.61]\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/sim/equalSteps/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/sim/equalSteps/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/sim/equalSteps/10_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/sim/equalSteps/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/sim/equalSteps/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/sim/equalSteps/10_datapoints/arrays/\",\n",
    "\n",
    "        ],\n",
    "        \"title\": \"Model\",\n",
    "        \"labels\": 3*[None] + [get_legend_label([1.5,3.51],\"b\"), get_legend_label([3.51,6.6],\"b\"), get_legend_label([7.13,8.85],\"b\")],\n",
    "        \"plot_ranges_str\": 6*[\"mean\"],\n",
    "        \"surface_bools\": 6*[True],\n",
    "        \"invert_xaxis\": True,\n",
    "        \"xaxis_label\": \"Age [Gyr]\",\n",
    "        \"x_ticks\": np.arange(4,10,1),\n",
    "        \"x_lims\": [4,10]\n",
    "    }, \n",
    "}\n",
    "\n",
    "save_path = get_base_POPPLOT_path(resampled_sim_bool=False) + \\\n",
    "            \"0R3.5_0R2/-2l2/1.5b3.51_3.51b6.6_7.13b8.85/both/data_equalN/data_n4,4,3_n4,4,3/sim_equalSteps/sim_n40,20,10_n40,20,10/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [5,4,3,8,7,6]\n",
    "    all_dicts[key][\"zorderNs\"] = [5,5,5,6,7,8]\n",
    "    all_dicts[key][\"colors\"] = 2*colors\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = 3*[alpha_reduction_factor*line_alpha] + 3*[line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 3*[alpha_reduction_factor*surface_alpha] + 3*[surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    \n",
    "    all_dicts[key][\"number_bools\"] = 3*[False] + 3*[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, sim and sim resampled 3 columns\n",
    "\n",
    "# sim_binning_type = \"equalN\"\n",
    "sim_binning_type = \"equalSteps\"\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Data\",\n",
    "        \"labels\": 6*[None],\n",
    "        \"plot_ranges_str\": 6*[\"median\"],\n",
    "        \"surface_bools\": 6*[False],\n",
    "        \"invert_xaxis\": False,\n",
    "        \"xaxis_label\": \"[Fe/H]\",\n",
    "        \"x_ticks\": np.arange(-0.9,0.6+0.3,0.3),\n",
    "        \"x_lims\": [-1,0.61],\n",
    "        \"bar_width\": 0.03\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/1.5b3.51/sim/{sim_binning_type}/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/3.51b6.6/sim/{sim_binning_type}/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/7.13b8.85/sim/{sim_binning_type}/10_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/1.5b3.51/sim/{sim_binning_type}/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/3.51b6.6/sim/{sim_binning_type}/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/7.13b8.85/sim/{sim_binning_type}/10_datapoints/arrays/\",\n",
    "\n",
    "        ],\n",
    "        \"title\": \"Model\",\n",
    "        \"labels\": 3*[None] + [get_legend_label([1.5,3.51],\"b\"), get_legend_label([3.51,6.6],\"b\"), get_legend_label([7.13,8.85],\"b\")],\n",
    "        \"plot_ranges_str\": 6*[\"mean\"],\n",
    "        \"surface_bools\": 6*[True],\n",
    "        \"invert_xaxis\": True,\n",
    "        \"xaxis_label\": \"Age [Gyr]\",\n",
    "        \"x_ticks\": np.arange(5,10,1),\n",
    "        \"x_lims\": [4,10],\n",
    "        \"bar_width\": 0.05\n",
    "    },\n",
    "    2: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R2/-2l2/1.5b3.51/sim/{sim_binning_type}/8_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R2/-2l2/3.51b6.6/sim/{sim_binning_type}/5_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R2/-2l2/7.13b8.85/sim/{sim_binning_type}/3_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R3.5/-2l2/1.5b3.51/sim/{sim_binning_type}/8_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R3.5/-2l2/3.51b6.6/sim/{sim_binning_type}/6_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R3.5/-2l2/7.13b8.85/sim/{sim_binning_type}/4_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Resampled model\",\n",
    "        \"labels\": 6*[None],\n",
    "        \"plot_ranges_str\": 6*[\"median\"],\n",
    "        \"surface_bools\": 6*[False],\n",
    "        \"invert_xaxis\": True,\n",
    "        \"xaxis_label\": \"Age [Gyr]\",\n",
    "        \"x_ticks\": np.arange(5,10,1),\n",
    "        \"x_lims\": [4,10],\n",
    "        \"bar_width\": 0.12\n",
    "    }    \n",
    "}\n",
    "\n",
    "save_path = get_base_POPPLOT_path(resampled_sim_bool=False) + \\\n",
    "            f\"data__sim__resampled_sim/0R3.5_0R2/-2l2/1.5b3.51_3.51b6.6_7.13b8.85/both/data_equalN__sim_{sim_binning_type}/\"+\\\n",
    "            \"data_n4,4,3_n4,4,3__sim_n40,20,10_n40,20,10__resampledsim_n8,6,4_n8,5,3/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [5,4,3,8,7,6]\n",
    "    all_dicts[key][\"zorderNs\"] = [5,5,5,6,7,8]\n",
    "    all_dicts[key][\"colors\"] = 2*colors\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = 3*[alpha_reduction_factor*line_alpha] + 3*[line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 3*[alpha_reduction_factor*surface_alpha] + 3*[surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    \n",
    "    all_dicts[key][\"number_bools\"] = 3*[False] + 3*[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in all_dicts:\n",
    "    print(key)\n",
    "    for path in all_dicts[key][\"load_paths\"]:\n",
    "        print(path)\n",
    "        if not os.path.isdir(path):\n",
    "            raise ValueError(\"Path did not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(save_path,exist_ok=True)\n",
    "\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsize = 5\n",
    "\n",
    "scatter_join_bool = True\n",
    "# scatter_join_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_bool = True\n",
    "# number_bool = False\n",
    "\n",
    "# number_variations_bool = True\n",
    "number_variations_bool = False\n",
    "\n",
    "bar_log = True\n",
    "# bar_log = False\n",
    "\n",
    "if number_bool: # check there are actually any to be plotted\n",
    "    \n",
    "    any_number_bool = False\n",
    "    for key in all_dicts:\n",
    "        any_number_bool = any_number_bool or any(all_dicts[key][\"number_bools\"])\n",
    "        \n",
    "    if not any_number_bool:\n",
    "        number_bool = False\n",
    "        print(\"No plot with number bool to draw, setting number_bool=False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_coded_ylims_bool = True # currently needed to ensure the y axis is shared correctly\n",
    "# hard_coded_ylims_bool = False\n",
    "\n",
    "# symmetric_ylims_bool = True\n",
    "symmetric_ylims_bool = False\n",
    "\n",
    "hard_coded_ylims = {\n",
    "#     \"tilt_abs\": [-45,3],\n",
    "    \"tilt_abs\": [-45,45],\n",
    "}\n",
    "\n",
    "yshift_dict = {\n",
    "    \"tilt_abs\": 2,\n",
    "    \"anisotropy\": 0.02,\n",
    "    \"correlation\": 0.01,\n",
    "    \"mean_vx\": 1,\n",
    "    \"mean_vy\": 1,\n",
    "    \"std_vx\": 2,\n",
    "    \"std_vy\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_legend_params(ncols, all_dicts,number_bool):\n",
    "    \n",
    "    if ncols != len(all_dicts):\n",
    "        raise ValueError(\"Expected the `ncols` to match the length of `all_dicts`.\")\n",
    "    \n",
    "    legend_cols = []\n",
    "    for k in all_dicts.keys():\n",
    "        if any(all_dicts[k][\"labels\"]):\n",
    "            legend_cols.append(k)\n",
    "    \n",
    "    ncols_leg = len(np.unique(all_dicts[legend_cols[0]][\"colors\"])) if len(legend_cols) == 1 else 1\n",
    "    \n",
    "    if ncols == 2:\n",
    "        loc_x = -0.75\n",
    "    elif ncols == 3:\n",
    "        loc_x = -0.6 if len(legend_cols) == 1 else 0.16\n",
    "    elif ncols == 1:\n",
    "        loc_x = -0.25\n",
    "        \n",
    "    legend_loc = [loc_x, 1.65]\n",
    "    \n",
    "    if not any(any(all_dicts[k][\"number_bools\"]) for k in all_dicts.keys()):\n",
    "        legend_loc[1] -= 0.4\n",
    "        \n",
    "    if not any(all_dicts[k][\"title\"] for k in all_dicts.keys()):\n",
    "        legend_loc[1] -= 0.15\n",
    "    \n",
    "    return legend_cols, legend_loc, ncols_leg\n",
    "            \n",
    "legend_row = 1\n",
    "# legend_row = len(map_list)\n",
    "\n",
    "legend_cols, legend_loc, ncols_leg = get_legend_params(ncols, all_dicts,number_bool)\n",
    "# legend_loc = \"upper right\"; ncols_leg=1\n",
    "# legend_cols = [1]\n",
    "\n",
    "legend_bool = True\n",
    "# legend_bool = False\n",
    "\n",
    "if legend_bool: # check there are actually any labels to be plotted\n",
    "    \n",
    "    any_legend_bool = False\n",
    "    for key in all_dicts:\n",
    "        any_legend_bool = any_legend_bool or any(all_dicts[key][\"labels\"])\n",
    "        \n",
    "    if not any_legend_bool:\n",
    "        legend_bool = False\n",
    "        print(\"No plot with label, setting legend_bool=False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_line_color = \"grey\"\n",
    "zero_line_alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 22\n",
    "ylabel_size = 24\n",
    "legend_fontsize = 15.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_x = 15\n",
    "\n",
    "figsize_y = 1.41*figsize_x # aspect ratio of A4\n",
    "\n",
    "figsize_x /= 2 if ncols == 1 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\",\"anisotropy\",\"correlation\",\"tilt_abs\"]; map_list_string = \"all\"\n",
    "# map_list = [\"anisotropy\",\"correlation\",\"tilt_abs\"]; map_list_string = \"anicorrtilt\"\n",
    "# map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\"]; map_list_string = \"velmeanstd\"\n",
    "# map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\",\"anisotropy\"]; map_list_string = \"meanstdani\"\n",
    "# map_list = [\"std_vx\",\"std_vy\",\"anisotropy\"]; map_list_string = \"stdani\"\n",
    "# map_list = [\"mean_vx\",\"mean_vy\"]; map_list_string = \"velmeans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_suffix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "fig,axs = plt.subplots(figsize=(figsize_x,figsize_y),nrows=len(map_list)+1,ncols=ncols, facecolor='w',\\\n",
    "                       gridspec_kw={'hspace':0,'wspace':0,'height_ratios':[0.35]+len(map_list)*[1]})\n",
    "\n",
    "if number_bool: # number and title\n",
    "    bar_n_min,bar_n_max = [10**30],[0]\n",
    "\n",
    "    for col in all_dicts:\n",
    "        dic = all_dicts[col]\n",
    "\n",
    "        axs[0,col].set_title(dic[\"title\"])\n",
    "\n",
    "        for i in range(len(dic[\"load_paths\"])):\n",
    "            if dic[\"number_bools\"][i]:\n",
    "                map_dict,min_range,max_range,plot_range = load_values_and_plot_ranges(dic[\"load_paths\"][i],full_map_string_list)\n",
    "                \n",
    "                if dic[\"plot_ranges_str\"][i] == \"mean\":\n",
    "                    plot_range = PH.get_range_means(min_range,max_range)\n",
    "\n",
    "                POPPLOT_number_bar(axs[0,col], plot_range, map_dict[\"number\"],color=dic[\"colors\"][i],alpha=dic[\"number_alphas\"][i],\\\n",
    "                                   zorder=dic[\"zorderNs\"][i], bar_width=dic[\"bar_width\"])\n",
    "\n",
    "                bar_n_min = min(bar_n_min, np.min(map_dict[\"number\"]))\n",
    "                bar_n_max = max(bar_n_max, np.max(map_dict[\"number\"]))\n",
    "    \n",
    "    for col in all_dicts:\n",
    "        POPPLOT_number_bar_axis_settings(axs[0,col],min_n=bar_n_min,max_n=bar_n_max,bar_log=bar_log,labels_on=col==ncols-1)        \n",
    "else:\n",
    "    for col in all_dicts:\n",
    "        fig.delaxes(axs[0,col])\n",
    "        \n",
    "        axs[1,col].set_title(all_dicts[col])\n",
    "\n",
    "for row,map_string in enumerate(map_list): # plot\n",
    "    error_string = map_string+\"_error\"\n",
    "    \n",
    "    ymin,ymax = [float(\"inf\")],[float(\"-inf\")]\n",
    "    \n",
    "    for col in all_dicts:\n",
    "        \n",
    "        POPPLOT_yaxis_settings(axs[row+1,col],map_string,error_string,set_ylims=False,labels_on=col==0)\n",
    "        axs[row+1,col].axhline(y=0,linestyle='--',color=zero_line_color,alpha=zero_line_alpha,zorder=0)\n",
    "        \n",
    "        dic = all_dicts[col]\n",
    "        for i in range(len(dic[\"load_paths\"])):\n",
    "            \n",
    "            map_dict,min_range,max_range,plot_range = load_values_and_plot_ranges(dic[\"load_paths\"][i],full_map_string_list)\n",
    "            plot_range = plot_range if dic[\"plot_ranges_str\"][i]==\"median\" else PH.get_range_means(min_range,max_range)\n",
    "            label = dic[\"labels\"][i] if row == legend_row-1 else None\n",
    "            \n",
    "            if dic[\"surface_bools\"][i]:\n",
    "                POPPLOT_values_surface(axs[row+1,col],map_dict[map_string],map_dict[error_string],plot_range,color=dic[\"colors\"][i],label=label,\\\n",
    "                                       line_alpha=dic[\"line_alphas\"][i],surface_alpha=dic[\"surface_alphas\"][i],zorder=dic[\"zorders\"][i])\n",
    "            else:\n",
    "                POPPLOT_values_scatter(axs[row+1,col],map_dict[map_string],map_dict[error_string],plot_range,min_range,max_range,color=dic[\"colors\"][i],label=label,\\\n",
    "                                       line_alpha=dic[\"line_alphas\"][i],zorder=dic[\"zorders\"][i],lines_bool=scatter_join_bool)\n",
    "            \n",
    "            ymin = min(ymin, np.nanmin(map_dict[map_string]-map_dict[error_string]))\n",
    "            ymax = max(ymax, np.nanmax(map_dict[map_string]+map_dict[error_string]))\n",
    "    \n",
    "    if map_string in yshift_dict:\n",
    "        ymin -= yshift_dict[map_string]\n",
    "        ymax += yshift_dict[map_string]\n",
    "    \n",
    "    if hard_coded_ylims_bool and map_string in hard_coded_ylims:\n",
    "        ymin,ymax = hard_coded_ylims[map_string]\n",
    "    \n",
    "    for col in all_dicts:\n",
    "        axs[row+1,col].set_ylim(ymin,ymax)\n",
    "\n",
    "if legend_bool: # legend\n",
    "    for col in all_dicts:\n",
    "        if col in legend_cols:\n",
    "            axs[legend_row,col].legend(loc=legend_loc,fontsize=legend_fontsize,ncols=ncols_leg)#,loc=\"lower left\")\n",
    "    \n",
    "if True: # x-axis\n",
    "        \n",
    "    for col in all_dicts:\n",
    "        \n",
    "        dic = all_dicts[col]\n",
    "    \n",
    "        for row in range(len(map_list)+1): # include number bars\n",
    "\n",
    "            POPPLOT_xaxis_settings(axs[row,col],xmin=dic[\"x_lims\"][0],xmax=dic[\"x_lims\"][1],xlabel=dic[\"xaxis_label\"],xticks=dic[\"x_ticks\"],labels_on=row==len(map_list))\n",
    "\n",
    "            if dic[\"invert_xaxis\"]:\n",
    "                axs[row,col].invert_xaxis()\n",
    "    \n",
    "    fig.align_labels()\n",
    "    \n",
    "if True: # save\n",
    "    \n",
    "    filename = \"kinpop_\" + map_list_string\n",
    "    \n",
    "    filename += \"_noN\" if not number_bool else \"\"\n",
    "    \n",
    "    filename += \"_noNvar\" if number_bool and not number_variations_bool else \"\"\n",
    "    \n",
    "    filename += \"_noLeg\" if not legend_bool else \"\"\n",
    "    \n",
    "    if not scatter_join_bool:\n",
    "        filename += \"_noLines\"\n",
    "    \n",
    "    filename += filename_suffix\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        print(\"Saving in\",save_path)\n",
    "        for formatting in ['.png','.pdf']:\n",
    "            plt.savefig(save_path+filename+formatting, bbox_inches='tight', dpi=300)\n",
    "            print(\"Saved\",formatting)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how wide in longitude we can go before the metal-poor develop a tilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmax = 2\n",
    "bmin = 0.5\n",
    "bmax = 10\n",
    "\n",
    "data_bulge = data[(np.abs(data['l'])<lmax)&(data['d']>6)&(data['d']<10)&(data['b']>bmin)&(data['b']<bmax)]\n",
    "\n",
    "data_bulge_poor = data_bulge[data_bulge['FeH']<-0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vx = data_bulge_poor.vr.values\n",
    "vy = data_bulge_poor.vl.values\n",
    "\n",
    "# val = CV.calculate_tilt(vx,vy,absolute=True)\n",
    "# err = CE.get_std_bootstrap(vx,vy,CV.calculate_tilt,tilt=True,absolute=True)\n",
    "val = CV.calculate_correlation(vx,vy)\n",
    "err = CE.get_std_bootstrap(vx,vy,CV.calculate_correlation)\n",
    "\n",
    "print(r\"%.2f +- %.2f\"%(val,err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in distance distribution for the simulation, check at what latitude it appears\n",
    "\n",
    "In the literature they say the MW's one appears with $l=0$ and $b=-5$, but most of my data lives below $b=5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 to 7 Gyr: inner split visible at $b>2.5$, hard to see at $b>4$, where outer X-shape dominates\n",
    "\n",
    "9.8 to 10 Gyr: visible at $b>3.5$, far end dissappears after $b>6$\n",
    "\n",
    "4 to 10 Gyr: visible at $b>3$, far end dissapears after $b>6$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmax = 2\n",
    "bmin = 6\n",
    "bmax = 10\n",
    "\n",
    "# agemin = 4\n",
    "# agemax = 10\n",
    "agemin = 4\n",
    "agemax = 7\n",
    "# agemin = 9.8\n",
    "# agemax = 10\n",
    "\n",
    "df_bulge = df0[(np.abs(df0['l'])<lmax)&(df0['d']>6)&(df0['d']<10)&(df0['b']>bmin)&(df0['b']<bmax)&(df0['age']>agemin)&(df0['age']<agemax)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.hist(df_bulge['d'],bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmax = 2\n",
    "bmin = 2.5\n",
    "bmax = 10\n",
    "\n",
    "metalmin = data['FeH'].min()\n",
    "metalmax = data['FeH'].max()\n",
    "\n",
    "data_bulge = data[(np.abs(data['l'])<lmax)&(data['d']>6)&(data['d']<10)&(data['b']>bmin)&(data['b']<bmax)&(data['FeH']>metalmin)&(data['FeH']<metalmax)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.hist(data_bulge['d'],bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmin = -1.5\n",
    "lmax = 1.5\n",
    "bmin = 2.5\n",
    "bmax = 4.5\n",
    "\n",
    "dmin = 6\n",
    "dmax = 10\n",
    "\n",
    "df_extra = df0[(df0[\"l\"]>lmin)&(df0[\"l\"]<lmax)&(df0[\"d\"]>dmin)&(df0[\"d\"]<dmax)&(df0[\"b\"]>bmin)&(df0[\"b\"]<bmax+b_step)]\n",
    "df_ages = [df_extra[(df_extra[\"age\"]>agelim[0])&(df_extra[\"age\"]<agelim[1])] for agelim in age_limits]\n",
    "\n",
    "poor_condition = (o_df_extra[\"FeH\"] < metal_poor_highlim)&(o_df_extra[\"FeH\"] > metal_poor_lowlim)\n",
    "rich_condition = o_df_extra[\"FeH\"] > metal_rich_lowlim if metal_rich_highlim is None else (o_df_extra[\"FeH\"] < metal_rich_highlim)&(o_df_extra[\"FeH\"] > metal_rich_lowlim)\n",
    "\n",
    "df_metals = [o_df_extra[rich_condition], o_df_extra[poor_condition]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_step = 1\n",
    "d_range = np.arange(dmin,dmax,d_step)\n",
    "d_range_plot = d_range+d_step/2\n",
    "o_d_range_plot = d_range_plot\n",
    "print(\"d_range is\",d_range)\n",
    "print(\"Plotting at:\",d_range_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = general_path + \"708main_simulation/graphs/Oscar/Apogee/\"\n",
    "create_dir(save_path)\n",
    "\n",
    "# save_path += \"scaling_\"+str(sim_scaling)+'/'\n",
    "# MF.create_dir(save_path)\n",
    "\n",
    "save_path += \"individual_variable/\"\n",
    "MF.create_dir(save_path)\n",
    "\n",
    "save_path += \"distance/\"\n",
    "MF.create_dir(save_path)\n",
    "    \n",
    "save_path += f\"{lmin}l{lmax}/\"\n",
    "create_dir(save_path)\n",
    "\n",
    "save_path += f\"{bmin}b{bmax}/\"\n",
    "create_dir(save_path)\n",
    "    \n",
    "save_path += f\"{young_min}-{young_max}_{old_min}-{old_max}/\"\n",
    "create_dir(save_path)\n",
    "\n",
    "#save_path += 'halo_metal/'\n",
    "#create_dir(save_path)\n",
    "\n",
    "if not galactocentric:\n",
    "    save_path += 'LSR/'\n",
    "    create_dir(save_path)\n",
    "\n",
    "poor_condition = (o_df_extra[\"FeH\"] < metal_poor_highlim)&(o_df_extra[\"FeH\"] > metal_poor_lowlim)\n",
    "label_poor = fr'${metal_poor_lowlim}<$[Fe/H]$<{metal_poor_highlim}$'\n",
    "\n",
    "if metal_rich_highlim is None:\n",
    "    rich_condition = o_df_extra[\"FeH\"] > metal_rich_lowlim\n",
    "    label_rich = fr'${metal_rich_lowlim}<$[Fe/H]'\n",
    "    save_path += f\"{metal_rich_lowlim}to{metal_rich_highlim}_{metal_poor_lowlim}to{metal_poor_highlim}/\"\n",
    "else:\n",
    "    rich_condition = (o_df_extra[\"FeH\"] < metal_rich_highlim)&(o_df_extra[\"FeH\"] > metal_rich_lowlim)\n",
    "    label_rich = fr'${metal_rich_lowlim}<$[Fe/H]$<{metal_rich_highlim}$'\n",
    "    save_path += f\"{metal_rich_lowlim}to{metal_rich_highlim}_{metal_poor_lowlim}to{metal_poor_highlim}/\"\n",
    "\n",
    "df_metals = [o_df_extra[rich_condition], o_df_extra[poor_condition]]\n",
    "label_rich += f\" ({len(df_metals[0])})\"\n",
    "label_poor += f\" ({len(df_metals[1])})\"\n",
    "\n",
    "create_dir(save_path)\n",
    "\n",
    "if halo_bool:\n",
    "    df_metals.append(o_df_extra[o_df_extra[\"FeH\"] < metal_halo_lim])    \n",
    "    label_halo = fr'(%i) [Fe/H]$<{metal_halo_lim}$'%len(df_metals[2])\n",
    "    print(\"Working with the halo population\")\n",
    "\n",
    "print(\"SAVING IN\\n\"+save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "alpha=0.7\n",
    "bins = np.linspace(dmin,dmax,50)\n",
    "if not halo_bool:\n",
    "    ax.hist(o_df_extra['d'],bins=bins,label='(%i) All'%len(o_df_extra['d']),alpha=alpha,color='orange')\n",
    "ax.hist(df_metals[1]['d'],bins=bins,label=label_poor,alpha=alpha,color='blue')\n",
    "ax.hist(df_metals[0]['d'],bins=bins,label=label_rich,alpha=alpha,color='red')\n",
    "if halo_bool:\n",
    "    ax.hist(df_metals[2]['d'],bins=bins,label=label_halo,alpha=alpha*0.75,color='cyan')\n",
    "ax.set_xlim(dmin,dmax)\n",
    "ax.set_xticks(np.arange(dmin,dmax,1))\n",
    "ax.set_xlabel(r'$d$ [kpc]')\n",
    "ax.set_ylabel(r\"$N$\",rotation=0,labelpad=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.text(0.05,0.9,fr\"${lmin} < l < {lmax}$\",transform=ax.transAxes)\n",
    "ax.text(0.07,0.85,fr\"${bmin} < b < {bmax}$\",transform=ax.transAxes)\n",
    "plt.savefig(save_path+f\"number_observations_{lmin}l{lmax}_{bmin}b{bmax}.png\",bbox_inches='tight',dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_arrays = np.zeros(shape=(len(full_map_string_list),len(d_range),len(df_ages)))\n",
    "o_all_arrays = np.zeros(shape=(len(full_map_string_list),len(d_range),len(df_metals)))\n",
    "\n",
    "for d_index,distance in enumerate(d_range):\n",
    "    for age_index,df in enumerate(df_ages):\n",
    "        vr = df[(df['d']>distance)&(df['d']<distance+d_step)].vr.values\n",
    "        vl = df[(df['d']>distance)&(df['d']<distance+d_step)].vl.values\n",
    "        \n",
    "        values = get_all_variable_values_and_errors(vr,vl,bootstrap_repeat=100,min_number=min_number_sim)\n",
    "        \n",
    "        for index, val in enumerate(values):\n",
    "            all_arrays[index, d_index, age_index] = val\n",
    "    \n",
    "    for metal_index, o_df in enumerate(df_metals):\n",
    "        vr = o_df[(o_df['d']>distance)&(o_df['d']<distance+d_step)].vr.values\n",
    "        vl = o_df[(o_df['d']>distance)&(o_df['d']<distance+d_step)].vl.values\n",
    "        \n",
    "        values = get_all_variable_values_and_errors(vr,vl,bootstrap_repeat=100,min_number=10)\n",
    "        \n",
    "        for index, val in enumerate(values):\n",
    "            o_all_arrays[index, d_index, metal_index] = val\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = create_map_array_dict(full_map_string_list, all_arrays)\n",
    "o_map_dict = create_map_array_dict(full_map_string_list, o_all_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsymbol = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_string = \"vertex_abs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_array = map_dict[map_string]\n",
    "error_array = map_dict[error_string]\n",
    "map_symbol = symbol_dict[map_string]\n",
    "map_title = title_dict[map_string]\n",
    "yticks = get_variable_ticks(map_string, map_array)\n",
    "displacement = max(yticks) - min(yticks)\n",
    "\n",
    "color_y, color_o = color_dict['vertex_abs'][0], color_dict['vertex_abs'][1]\n",
    "\n",
    "transparency = 0.5\n",
    "alpha_area = 0.4\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "ax_histx = divider.append_axes(\"top\", size=1.2, pad=0, sharex=ax)\n",
    "ax_histx.xaxis.set_tick_params(labelbottom=False)\n",
    "\n",
    "alpha=0.7\n",
    "ax_histx.hist(df_metals[1]['d'],bins=bins,alpha=1,color=color_o)\n",
    "ax_histx.hist(df_metals[0]['d'],bins=bins,alpha=alpha,color=color_y)\n",
    "if halo_bool:\n",
    "    ax_histx.hist(df_metals[2]['d'],bins=bins,alpha=alpha,color='cyan')\n",
    "\n",
    "bar_width=0.2\n",
    "ax_histx.bar(d_range_plot-bar_width/2, map_dict[\"number\"][:,0], width=bar_width,alpha=transparency,log=True,color=color_y)\n",
    "ax_histx.bar(d_range_plot+bar_width/2, map_dict[\"number\"][:,1], width=bar_width,alpha=transparency,log=True,color=color_o)\n",
    "ax_histx.yaxis.set_tick_params(labelleft=False,labelright=True)\n",
    "ax_histx.set_yticks([1,10,100,1000,10000,100000])\n",
    "ax_histx.set_ylabel(r\"$N$\",labelpad=15,rotation=0)\n",
    "ax_histx.yaxis.set_label_position(\"right\")\n",
    "\n",
    "ax.plot(d_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "ax.plot(d_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "\n",
    "\n",
    "ax.fill_between(d_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "ax.fill_between(d_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "\n",
    "if not absolute:\n",
    "    ax.fill_between(d_range_plot, map_array[:,1]-error_array[:,1]+displacement, map_array[:,1]+error_array[:,1]+displacement,alpha=alpha_area, facecolor=color_o)\n",
    "    ax.fill_between(d_range_plot, map_array[:,1]-error_array[:,1]-displacement, map_array[:,1]+error_array[:,1]-displacement,alpha=alpha_area, facecolor=color_o)\n",
    "    ax.fill_between(d_range_plot, map_array[:,0]-error_array[:,0]+displacement, map_array[:,0]+error_array[:,0]+displacement,alpha=alpha_area, facecolor=color_y)\n",
    "    ax.fill_between(d_range_plot, map_array[:,0]-error_array[:,0]-displacement, map_array[:,0]+error_array[:,0]-displacement,alpha=alpha_area, facecolor=color_y)\n",
    "\n",
    "#OBSERVATIONS-----------------------------------------------------------------------------------------------\n",
    "o_map_array = o_map_dict[map_string]\n",
    "o_error_array = o_map_dict[error_string]\n",
    "\n",
    "ax.errorbar(o_d_range_plot, o_map_array[:,1] , yerr= o_error_array[:,1], color=color_o, label=label_poor,fmt='o',marker=\"$\\u25A1$\")\n",
    "ax.errorbar(o_d_range_plot, o_map_array[:,0], yerr= o_error_array[:,0], color=color_y, alpha=0.8,label=label_rich,fmt='s',marker=\"$\\u25EF$\")\n",
    "if halo_bool:\n",
    "    ax.errorbar(o_d_range_plot, o_map_array[:,2] , yerr=o_error_array[:,2], color='cyan', label=label_halo,fmt='o',markersize=8,marker=\"$\\u25B3$\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "ax.legend(fontsize=15,loc=\"best\")\n",
    "\n",
    "ax.set_xlim(dmin,dmax)\n",
    "ax.set_xticks(np.arange(dmin,dmax,1))\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_ylim(min(yticks),max(yticks))\n",
    "\n",
    "ax.set_xlabel(r\"$%s$ [Â°]\"%xsymbol)\n",
    "ax.set_ylabel(map_symbol)\n",
    "\n",
    "title_string = 'Vertex deviation (absolute value equation)' if absolute else 'Vertex deviation'\n",
    "ax_histx.set_title(title_string,fontsize=18,pad=10)\n",
    "\n",
    "#ax.set_aspect(0.082 if absolute else 0.04)\n",
    "\n",
    "ax.text(x=-0.14,y=1.24,s='Sim scaling '+str(sim_scaling),size=13, transform=ax.transAxes)\n",
    "l_string = r\"$%i < l [%s] < {%i},$\"%(lmin,degree_symbol,lmax)\n",
    "d_string = r\"${%i}<d [\\mathrm{%s}]<{%i}$\"%(dmin,'kpc',dmax)\n",
    "text_y = -0.09\n",
    "ax.text(x=0.79,y=text_y,s=l_string,size=13,transform=ax.transAxes)\n",
    "ax.text(x=0.94,y=text_y,s=d_string,size=13,transform=ax.transAxes)\n",
    "plt.savefig(save_path+map_string+'_distance.pdf',bbox_inches='tight')\n",
    "print(save_path+map_string)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_min = 9.\n",
    "age_max = 10.\n",
    "\n",
    "dmin = 6\n",
    "dmax = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_step = 0.5\n",
    "distance_range = np.arange(dmin,dmax,d_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_step = 1.5\n",
    "\n",
    "lmin = -lb_step/2\n",
    "lmax = lb_step/2\n",
    "bmin = -lb_step/2\n",
    "bmax = lb_step/2\n",
    "\n",
    "min_star_number = 10\n",
    "\n",
    "limit_vertex = -40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude_range = np.arange(lmin, lmax, lb_step)\n",
    "latitude_range = np.arange(bmin, bmax, lb_step)\n",
    "\n",
    "print(\"Longitude range:\",longitude_range)\n",
    "print(\"Latitude range:\",latitude_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in latitude_range:\n",
    "    print(i,i+lb_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"708main_simulation/graphs/vertex_distance/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No division in distance intervals\n",
    "theta_across_d = []\n",
    "\n",
    "df_dist_age = df0[(df0.age <= age_max)&(df0.age >= age_min)&(df0.d <= dmax)&(df0.d>=dmin)]\n",
    "\n",
    "for longitude in longitude_range:\n",
    "        df_long = df_dist_age[(df_dist_age.l >= longitude)&(df_dist_age.l < longitude + lb_step)]\n",
    "\n",
    "        for latitude in latitude_range:\n",
    "            df_lat = df_long[(df_long.b >= latitude)&(df_long.b < latitude + lb_step)]\n",
    "\n",
    "            cov = np.cov(df_lat.vr.values, df_lat.pml.values)\n",
    "            varr = cov[0,0]\n",
    "            varl = cov[1,1]\n",
    "            covrl = cov[0,1]\n",
    "\n",
    "            if len(df_lat) > min_star_number:\n",
    "                theta = np.degrees(np.arctan2(2.*covrl, np.abs(varr - varl))/2.)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            print(theta)\n",
    "            theta_across_d.append(theta)\n",
    "del df_dist_age, df_long, df_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path + \"total_vertex_\"+str(lmin)+\"l\"+str(lmax)+\"_\"+str(bmin)+\"b\"+str(bmax)+\".txt\", 'w') as f:\n",
    "    f.write(\"The total vertex deviation across the line of sight (6 < d < 10)kpc is: \"+str(theta_across_d[0])+'Â°'\\\n",
    "           \"\\n\\nWorking with a \"+str(lb_step)+\"Ã\"+str(lb_step)+\"Â° window in: \\n\"+str(lmin)+\" <= l < \"+str(lmax)+\n",
    "           \"\\n\"+str(bmin)+\" <= b < \"+str(bmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = df0[(df0.age <= age_max)&(df0.age >= age_min)]\n",
    "\n",
    "x_positions, y_positions, x_velocities, y_velocities, r_vel, t_vel = [], [], [], [], [], []\n",
    "theta_values, number_points = [], []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for distance in distance_range:\n",
    "    df_dist = df_age[(df_age.d >= distance)&(df_age.d < distance + d_step)]\n",
    "\n",
    "    for longitude in longitude_range:\n",
    "        df_long = df_dist[(df_dist.l >= longitude)&(df_dist.l < longitude + lb_step)]\n",
    "\n",
    "        for latitude in latitude_range:\n",
    "            df_lat = df_long[(df_long.b >= latitude)&(df_long.b < latitude + lb_step)]\n",
    "\n",
    "            cov = np.cov(df_lat.vr.values, df_lat.pml.values)\n",
    "            varr = cov[0,0]\n",
    "            varl = cov[1,1]\n",
    "            covrl = cov[0,1]\n",
    "\n",
    "            if len(df_lat) > min_star_number:\n",
    "                theta = np.degrees(np.arctan2(2.*covrl, np.abs(varr - varl))/2.)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            print(theta)\n",
    "            #if theta < limit_vertex:\n",
    "            number_points.append(len(df_lat.x.values))\n",
    "            theta_values.append(theta)\n",
    "            x_positions.append(df_lat.x.values)\n",
    "            y_positions.append(df_lat.y.values)\n",
    "            x_velocities.append(df_lat.vx.values)\n",
    "            y_velocities.append(df_lat.vy.values)\n",
    "            r_vel.append(df_lat.vr.values)\n",
    "            t_vel.append(df_lat.pml.values)\n",
    "        \n",
    "        i+=1\n",
    "                        \n",
    "print(\"There were\",i,\"intervals\")\n",
    "print(\"There are\",len(distance_range),\"distance bins\")\n",
    "\n",
    "del df_dist, df_long, df_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The max number of points is\",np.max(number_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "n_points_frac = 0.5\n",
    "l1= ax.scatter(distance_range+0.25, theta_values, s=n_points_frac*np.array(number_points), alpha=0.7)\n",
    "ax.plot(distance_range+0.25, theta_values)#, s=number_points, alpha=0.7)\n",
    "\n",
    "ax.set_xlim(6,10)\n",
    "\n",
    "\n",
    "#handles, labels = l1.legend_elements(prop=\"sizes\", num = [500,1000,1500], alpha=0.7, color='blue')\n",
    "#leg = ax.legend(handles, labels, loc=\"lower right\", title=\"#Datapoints\", numpoints = 1, fontsize=13, labelspacing=1)\n",
    "#leg.get_title().set_fontsize('13')\n",
    "size1, size2, size3 = 500, 1500, 2500\n",
    "leg_colour = \"tab:blue\"\n",
    "leg1 = ax.scatter([],[],s = n_points_frac*size1, color=leg_colour, alpha=0.7)\n",
    "leg2 = ax.scatter([],[],s = n_points_frac*size2, color=leg_colour, alpha=0.7)\n",
    "leg3 = ax.scatter([],[],s = n_points_frac*size3, color=leg_colour, alpha=0.7)\n",
    "\n",
    "leg = ax.legend((leg1, leg2, leg3),\n",
    "             (str(size1),str(size2),str(size3)),\n",
    "             scatterpoints=1,\n",
    "             loc=\"lower right\",\n",
    "             ncol=1,\n",
    "             fontsize=13,\n",
    "             title = \"# datapoints\",\n",
    "             labelspacing=1.3)\n",
    "leg.get_title().set_fontsize('14')\n",
    "\n",
    "\n",
    "ax.set_xlabel(r\"Distance (kpc)\")\n",
    "ax.set_ylabel(r\"$\\theta_v \\hspace{0.4}[Â°]$\")\n",
    "\n",
    "filename = \"vertexdistance_\"+str(lmin)+\"l\"+str(lmax)+\"_\"+str(bmin)+\"b\"+str(bmax)+\"_\"+str(dmin)+\"d\"+str(dmax)+\".png\"\n",
    "plt.savefig(save_path + filename, bbox='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_vel = save_path + \"velocities_\"+str(lmin)+\"l\"+str(lmax)+\"_\"+str(bmin)+\"b\"+str(bmax)+'/'\n",
    "\n",
    "if not os.path.isdir(save_path_vel):\n",
    "    os.mkdir(save_path_vel)\n",
    "\n",
    "print(save_path_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(theta_values)):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.scatter(r_vel[index], t_vel[index], marker='.', color='grey')\n",
    "\n",
    "    cmap2 = 'coolwarm'\n",
    "\n",
    "    level_n = 10\n",
    "\n",
    "    sns.kdeplot(r_vel[index], t_vel[index], cmap=cmap2, cut=1, n_levels=level_n, fill=True, shade_lowest=False, \\\n",
    "                alpha=0.4, cbar=False, aspect='equal', extend='both')\n",
    "\n",
    "    mec = sns.kdeplot(r_vel[index], t_vel[index], cmap=cmap2, cut=1, n_levels=level_n, fill=False, shade_lowest=False, \\\n",
    "                alpha=1, cbar=True, aspect='equal', extend='both', linewidths=2, \\\n",
    "                      cbar_kws={'label': r'Probability density [$\\rm s^{2} \\hspace{0.3} km^{-2}$]'})\n",
    "\n",
    "    ax.set_xlabel(r\"$v_r$ [km $\\rm s^{-1}$]\")\n",
    "    ax.set_ylabel(r\"$\\mu_l$ [km $\\rm s^{-1}$]\")\n",
    "\n",
    "    text_box = dict(boxstyle='round', facecolor='wheat', alpha=1)\n",
    "    theta = theta_values[index]\n",
    "    ax.text(0.6, 0.95, r\"$\\theta_v=$\"+(r'$-$' if abs(theta) != theta else '')\\\n",
    "            +str(np.float16(abs(theta)))+'Â°', transform=ax.transAxes, fontsize=20, verticalalignment='top', bbox=text_box)\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    dmin = distance_range[index]\n",
    "    dmax = dmin + d_step\n",
    "    \n",
    "    ax.set_title(str(dmin)+r\" $\\leq$ Distance [kpc] $<$ \"+str(dmax), fontsize=18)\n",
    "    \n",
    "    filename = \"velocity_\"+str(lmin)+\"l\"+str(lmax)+\"_\"+str(bmin)+\"b\"+str(bmax)+\"_\"+str(dmin)+\"d\"+str(dmax)+\".png\"\n",
    "    plt.savefig(save_path_vel+filename, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "226.93px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
