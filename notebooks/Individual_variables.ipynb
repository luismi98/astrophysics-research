{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False # To make auto-complete faster\n",
    "\n",
    "#Reloads imported files automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "from scipy.spatial import KDTree\n",
    "import copy\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import colormaps as mplcmaps\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from matplotlib_param_funcs import set_matplotlib_params,reset_rcParams\n",
    "set_matplotlib_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compute_variables as CV\n",
    "import miscellaneous_functions as MF\n",
    "import mixed_plots as MP\n",
    "import plotting_helpers as PH\n",
    "import variable_values_and_errors as val_err\n",
    "import velocity_plot\n",
    "import load_sim\n",
    "import load_data\n",
    "import map_functions as mapf\n",
    "import coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, clear_output\n",
    "display(HTML(\"<style>.container { width:88% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree_symbol = '°'\n",
    "degree_symbol = '^\\circ'\n",
    "\n",
    "mass_density_label = r\"$\\Sigma \\hspace{0.3} [\\rm M_\\odot kpc^{-2}]$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coolwarm = mplcmaps['coolwarm']\n",
    "red = coolwarm(0.95)\n",
    "blue = coolwarm(0.05)\n",
    "green = 'darkgreen'\n",
    "grey = 'lightgrey'\n",
    "\n",
    "plt.rcParams['font.size'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHOOSE\n",
    "\n",
    "x_variable = \"l\"\n",
    "y_variable = \"b\"\n",
    "\n",
    "vel_x_variable = 'r'\n",
    "vel_y_variable = 'l'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_dict = mapf.get_kinematic_symbols_dict(x_variable=x_variable,\n",
    "                                                         y_variable=y_variable,\n",
    "                                                         vel_x_variable=vel_x_variable,\n",
    "                                                         vel_y_variable=vel_y_variable)\n",
    "\n",
    "units_dict = mapf.get_kinematic_units_dict(position_variables=x_variable+y_variable,\n",
    "                                                     vel_x_variable=vel_x_variable,\n",
    "                                                     vel_y_variable=vel_y_variable,\n",
    "                                                     degree_symbol=degree_symbol)\n",
    "\n",
    "pos_symbols_dict,pos_units_dict = mapf.get_position_symbols_and_units_dict(degree_symbol=\"°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_dict[\"mean_b\"] = r\"$\\langle |b| \\rangle$\"\n",
    "units_dict[\"mean_b\"] = r\"$[^\\circ]$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_map_string_list,divergent_map_list = mapf.get_map_string_lists()\n",
    "\n",
    "all_maps = False\n",
    "full_map_string_list = [map_string for map_string in full_map_string_list if \"spherical\" not in map_string]\n",
    "\n",
    "print(full_map_string_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variable_ticks(map_string, map_array):\n",
    "    if map_string == \"vertex_abs\":\n",
    "        max_value = 45\n",
    "        min_value = -max_value\n",
    "    elif map_string == \"vertex\":\n",
    "        max_value = 90\n",
    "        min_value = -max_value\n",
    "    elif map_string == \"error\":\n",
    "        min_value = 0\n",
    "        max_value = np.nanmax(map_array)\n",
    "    elif map_string == \"varr\" or map_string == \"varl\":\n",
    "        #min_value = 0\n",
    "        min_value = np.nanmin([all_varr[norm_index], all_varl[norm_index]])\n",
    "        max_value = np.nanmax([all_varr, all_varl])\n",
    "    elif map_string == \"mean_vr\" or map_string == \"mean_vl\":\n",
    "        mini = np.nanmin([map_dict[\"mean_vr\"],map_dict[\"mean_vl\"]])\n",
    "        maxi = np.nanmax([map_dict[\"mean_vr\"],map_dict[\"mean_vl\"]])\n",
    "\n",
    "        limits = [mini, maxi]\n",
    "\n",
    "        lims_factor = 1\n",
    "        min_value = -lims_factor*np.max(np.abs(limits))\n",
    "        max_value = lims_factor*np.max(np.abs(limits))\n",
    "    elif map_string in [\"covariance\",\"correlation\",\"anisotropy\"]:#divergent_map_list:\n",
    "        mini = np.nanmin(map_array)\n",
    "        maxi = np.nanmax(map_array)\n",
    "\n",
    "        limits = [mini, maxi]\n",
    "\n",
    "        lims_factor = 1\n",
    "        min_value = -lims_factor*np.max(np.abs(limits))\n",
    "        max_value = lims_factor*np.max(np.abs(limits))\n",
    "    else:\n",
    "        min_value = np.nanmin(map_array)\n",
    "        max_value = np.nanmax(map_array)\n",
    "\n",
    "    ticks = np.linspace(min_value,max_value,5)\n",
    "    return ticks\n",
    "def create_map_array_dict(full_map_string_list, all_arrays):\n",
    "    if len(full_map_string_list) != len(all_arrays):\n",
    "        raise ValueError(\"len(full_map_string_list) different to len(all_arrays)\")\n",
    "    map_dict = {}\n",
    "    for index, map_string in enumerate(full_map_string_list):\n",
    "        map_dict[map_string] = all_arrays[index]\n",
    "    return map_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.DataFrame([[1,2,3],[2,3,1],[6,3,4]], columns=['a','b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_path = '/Users/luismi/Desktop/MRes_UCLan/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zabs = True\n",
    "# zabs = False\n",
    "\n",
    "R0 = 8.1\n",
    "\n",
    "GSR = True\n",
    "# GSR = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_choice = \"708main\" #stuart\n",
    "\n",
    "rot_angle = -27\n",
    "axisymmetric = False\n",
    "pos_scaling = 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_chunk = False\n",
    "\n",
    "if not load_chunk:\n",
    "    np_path = general_path+f\"data/708main_simulation/numpy_arrays/R0_{R0}/\"\n",
    "        \n",
    "    df0 = load_sim.load_simulation(path=np_path, choice=sim_choice, rot_angle = rot_angle, axisymmetric=axisymmetric, GSR=GSR,zabs=zabs, pos_factor=pos_scaling,R0=R0)\n",
    "else:\n",
    "    if sim_choice == \"708main\" and rot_angle == 27 and not axisymmetric and zabs and sim_scaling == 1.7:\n",
    "        pickle_name = \"df_bulge_zabs.pkl\"\n",
    "        df0 = pd.read_pickle(\"708main_simulation/\"+pickle_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_resampled_bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_path = \"C:/Users/Luismi/JUPYTER_NOTEBOOKS/MRes_UCLan/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.genfromtxt(general_path + \"Oscar_data/gibs_vvvPMs.dat\", names=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_columns = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['l','b','Vgc','FeH','mul_grs','mub_grs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_columns = delete_columns.drop(columns_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=delete_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_distance = 8 #8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vl']=(fixed_distance*3.086e16)*data.mul_grs.values*((np.pi/(180 * 3600))*10**(-3)/(3.1536e7))\n",
    "data['vb']=(fixed_distance*3.086e16)*data.mub_grs.values*((np.pi/(180 * 3600))*10**(-3)/(3.1536e7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"vr\"] = data[\"Vgc\"]\n",
    "#data[\"vr\"] = np.sqrt(data[\"Vgc\"]**2 - data[\"vl\"]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = ['Vgc','mul_grs','mub_grs'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.l > 180, 'l'] -= 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = general_path+'708main_simulation/graphs/Oscar/GIBS/'\n",
    "print(\"Saving in:\",save_path)\n",
    "\n",
    "save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fullrange = True\n",
    "\n",
    "lim = 1000\n",
    "if not fullrange:\n",
    "    ax.set_xlim(-lim,lim)\n",
    "    bins = np.linspace(-lim,lim,100)\n",
    "else:\n",
    "    bins = 100\n",
    "    ax.text(x=0.03,y=0.06,s=str(len(np.where(data['vl'] < -1000)[0])),color='blue',transform=ax.transAxes)\n",
    "lw = 3\n",
    "alpha = 0.5\n",
    "a_n,a_bins,_ = ax.hist(data['vl'],bins=bins,alpha=alpha, color='blue',label=r'GIBS $v_l$')\n",
    "ax.plot([np.mean(data['vl']),np.mean(data['vl'])],[0,np.max(a_n)],alpha=1,color='blue',lw=lw,linestyle='-.')\n",
    "\n",
    "b_n,_,_ = ax.hist(data['vr'],bins=bins if not fullrange else a_bins,alpha=alpha, color='cyan',label=r'GIBS $v_r$')\n",
    "ax.plot([np.mean(data['vr']),np.mean(data['vr'])],[0,np.max(b_n)],alpha=1,color='cyan',lw=lw,linestyle='-.')\n",
    "\n",
    "ax.set_xlabel(r\"Velocity $[\\mathrm{km \\hspace{0.3} s^{-1}}]$\")\n",
    "ax.set_ylabel(r\"$N$\", rotation=0,labelpad=20)\n",
    "plt.legend(loc='best')\n",
    "if save_bool:\n",
    "    filename = 'velocities_fullrange' if fullrange else 'velocities'\n",
    "    plt.savefig(save_path+filename+'.png',bbox_inches='tight',dpi=150)\n",
    "    print(save_path+filename+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apogee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_errors = True\n",
    "obs_errors = False\n",
    "\n",
    "data_zabs = True\n",
    "# data_zabs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = general_path+\"data/Observational_data/\"\n",
    "\n",
    "data = load_data.load_and_process_data(data_path=data_path, error_bool=obs_errors, zabs=zabs, R0=R0, GSR=GSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-sample sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10 # number of nearest neighbours to find\n",
    "\n",
    "tree = KDTree(df0[[\"x\",\"y\",\"z\"]].values)\n",
    "\n",
    "already_chosen_indices = set()\n",
    "nearest_simulation_star_indices = []\n",
    "all_distances = []\n",
    "\n",
    "for i, obs_star in enumerate(data[[\"x\",\"y\",\"z\"]].values):\n",
    "    k = K\n",
    "    while True:\n",
    "        distances, indices = tree.query(obs_star, k=k)# + len(already_chosen_indices))\n",
    "        \n",
    "        new_indices = [idx for idx in indices if idx not in already_chosen_indices]\n",
    "        \n",
    "        if len(new_indices) >= K:\n",
    "            chosen_indices = new_indices[:K]\n",
    "            \n",
    "            nearest_simulation_star_indices.append(chosen_indices)            \n",
    "            all_distances.append([dist for idx, dist in zip(indices, distances) if idx in chosen_indices])\n",
    "            \n",
    "            already_chosen_indices.update(chosen_indices)\n",
    "            \n",
    "            break\n",
    "        else:\n",
    "            k += K\n",
    "            \n",
    "#     clear_output(wait=True)\n",
    "#     print(f\"Iteration: {i+1}/{len(data)}\")\n",
    "            \n",
    "nearest_simulation_star_indices = np.array(nearest_simulation_star_indices)\n",
    "all_distances = np.array(all_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_simulation_star_indices.shape, all_distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"{general_path}graphs/other_plots/resampled_sim/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distance distribution\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.hist(all_distances.flatten(),bins=300,log=False)\n",
    "ax.set_xlabel(\"Nearest neighbour distances [kpc]\")\n",
    "ax.set_ylabel(r\"$N$\",rotation=0,labelpad=15)\n",
    "\n",
    "max_distance = max(all_distances.flatten())\n",
    "ax.axvline(x=max_distance,color=\"red\",label=\"Maximum distance: %.2f [kpc]\"%max_distance)\n",
    "ax.legend()\n",
    "\n",
    "if save_bool:\n",
    "    plt.savefig(save_path + \"distance_distribution\",dpi=150,bbox_inches=\"tight\")\n",
    "    print(\"Saved:\",save_path + \"distance_distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # lognormal fit to the distance distribution\n",
    "\n",
    "    from scipy.stats import lognorm, norm, gaussian_kde\n",
    "\n",
    "    # fit lognorm in linear scale\n",
    "    shape, loc, scale = lognorm.fit(all_distances.flatten(), floc=0)\n",
    "    mu, sigma = np.log(scale), shape\n",
    "\n",
    "    plt.figure()\n",
    "    count, bins, ignored = plt.hist(all_distances.flatten(), bins=200, density=True, alpha=0.3, color='b')\n",
    "    pdf = lognorm.pdf(bins, sigma, scale=np.exp(mu))\n",
    "    plt.plot(bins, pdf, color='r')\n",
    "    plt.show()\n",
    "\n",
    "    # fit gaussian in log scale\n",
    "    log_distances = np.log(all_distances.flatten())\n",
    "    mu, std = norm.fit(log_distances)\n",
    "\n",
    "    plt.figure()\n",
    "    count, bins, ignored = plt.hist(log_distances, bins=200, density=True, alpha=0.3, color='b')\n",
    "    pdf = norm.pdf(bins, mu, std)\n",
    "    plt.plot(bins, pdf, color='r')\n",
    "    plt.show()\n",
    "\n",
    "    # check KDE\n",
    "    values = np.linspace(min(all_distances.flatten()), max(all_distances.flatten()), 1000)\n",
    "    kde = gaussian_kde(all_distances.flatten())\n",
    "    kde_values = kde(values)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.hist(all_distances.flatten(), bins=200, density=True, alpha=0.3, color='b')\n",
    "    plt.plot(values, kde_values, color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_resampled = df0.iloc[nearest_simulation_star_indices.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts_dict = {\"R\":[0,3.5],\"age\":[4,10]}#,\"z\":[0.5,2.2]}\n",
    "\n",
    "cumulative = True\n",
    "# cumulative = False\n",
    "\n",
    "if True: # plot age distribution\n",
    "    fig,ax=plt.subplots()\n",
    "\n",
    "    bins = 500 if cumulative else 100\n",
    "\n",
    "    ax.hist(MF.apply_cuts_to_df(df=df0, cuts_dict=cuts_dict)[\"age\"],bins=bins,label=\"Original\",density=True,cumulative=cumulative)\n",
    "    ax.hist(MF.apply_cuts_to_df(df=sim_resampled, cuts_dict=cuts_dict)[\"age\"],bins=bins,alpha=0.7,label=f\"Resampled (k={K})\",density=True,cumulative=cumulative)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Age [Gyr]\")\n",
    "    ax.set_ylabel(\"Probability density\" if not cumulative else \"Fraction\")\n",
    "\n",
    "    filename = \"age_distribution\"\n",
    "    filename += \"_cumulative\" if cumulative else \"\"\n",
    "\n",
    "    for cut_variable in cuts_dict:\n",
    "        if cut_variable != \"age\":\n",
    "            l,r = cuts_dict[cut_variable]\n",
    "            filename += f\"_{l}{cut_variable}{r}\"\n",
    "\n",
    "    if save_bool:\n",
    "        plt.savefig(save_path+filename+\".png\",dpi=150,bbox_inches=\"tight\")\n",
    "        print(\"Saved:\",save_path+filename+\".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False\n",
    "\n",
    "# density_bool = True\n",
    "density_bool = False\n",
    "bins_x = 100\n",
    "\n",
    "if True: # xy and xz views\n",
    "    fig,axs=plt.subplots(figsize=(9,11),nrows=2,gridspec_kw={\"hspace\":0})\n",
    "    c1 = MP.quick_show_xy(sim_resampled,show=False,density=density_bool,bins_x=bins_x)\n",
    "    c2 = MP.quick_show_xz(sim_resampled,show=False,zmin=0,density=density_bool,bins_x=bins_x)\n",
    "\n",
    "    norm = PH.get_norm_from_count_list([c1,c2],log=True)\n",
    "\n",
    "    MP.quick_show_xy(sim_resampled,ax=axs[0],norm=norm, density=density_bool,bins_x=bins_x)\n",
    "    MP.quick_show_xz(sim_resampled,ax=axs[1],norm=norm,zmin=0, density=density_bool,bins_x=bins_x)\n",
    "\n",
    "    cbar = plt.colorbar(cm.ScalarMappable(norm=norm,cmap=\"viridis\"),ax=axs,shrink=0.8)\n",
    "    cbar.set_label(mass_density_label) if density_bool else cbar.set_label(r\"$N$\",rotation=0,labelpad=20)\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    if True: # filename and saving\n",
    "\n",
    "        filename = f\"resampled_sim_xyxz_k{k}\"\n",
    "        filename += f\"_xbins{bins_x}\"\n",
    "        filename += \"_N\" if not density_bool else \"_density\"\n",
    "\n",
    "        print(filename)\n",
    "\n",
    "        if save_bool:\n",
    "            print(\"Saving in:\",save_path)\n",
    "\n",
    "            plt.savefig(save_path+filename+\".png\", dpi=200,bbox_inches=\"tight\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_resampled_bool = True\n",
    "\n",
    "if sim_resampled_bool:\n",
    "    df0 = sim_resampled\n",
    "    \n",
    "    del sim_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_path(single_variable):\n",
    "    save_path = general_path+f'graphs/Observations/Apogee/individual_variable/{single_variable}/'\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "def get_save_path_cuts(single_variable, cuts_dict):\n",
    "        \n",
    "    save_path = get_base_path(single_variable)\n",
    "    \n",
    "    for variable in cuts_dict:\n",
    "        value_tuple = cuts_dict[variable]\n",
    "        \n",
    "        save_path += f\"{MF.return_int_or_dec(value_tuple[0],2)}{variable}{MF.return_int_or_dec(value_tuple[1],2)}/\"\n",
    "        MF.create_dir(save_path)\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "def get_save_path_data(save_path_spatial, metal_lowcut, metal_lims, binning_str, pop_str):\n",
    "        \n",
    "    save_path = save_path_spatial + \"data/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"metal_lowcut_{metal_lowcut}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{str(MF.return_int_or_dec(metal_lims[0],2))}metal{str(MF.return_int_or_dec(metal_lims[1],2))}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{binning_str}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{pop_str}/\"\n",
    "    MF.create_dir(save_path)\n",
    "        \n",
    "    return save_path\n",
    "\n",
    "def get_save_path_sim(save_path_spatial, bar_angle, resampled_sim_bool, age_lims, binning_str, pop_str):\n",
    "        \n",
    "    save_path = save_path_spatial + \"sim/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"bar_angle_{bar_angle}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += \"resampled_sim/\" if resampled_sim_bool else \"\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{MF.return_int_or_dec(age_lims[0],2)}age{MF.return_int_or_dec(age_lims[1],2)}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{binning_str}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{pop_str}/\"\n",
    "    MF.create_dir(save_path)\n",
    "        \n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = \"b\"\n",
    "\n",
    "x_min = 1\n",
    "x_max = 13\n",
    "\n",
    "if True: # x_label\n",
    "    if x_var in pos_symbols_dict:\n",
    "        x_label = pos_symbols_dict[x_var] + f\" [{pos_units_dict[x_var]}]\"\n",
    "    else:\n",
    "        if x_var == \"age\":\n",
    "            x_label = \"Age [Gyr]\"\n",
    "        elif x_var == \"FeH\":\n",
    "            x_label = \"[Fe/H]\"\n",
    "        else:\n",
    "            raise ValueError(\"x_label not defined for the chosen variable}\")\n",
    "    \n",
    "MP.show_text(x_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_cuts_dict = {\n",
    "    x_var: [x_min,x_max],\n",
    "    \"R\": [0,3.5],\n",
    "    \"l\": [-2,2]\n",
    "}\n",
    "\n",
    "for variable in spatial_cuts_dict:\n",
    "    print(variable, spatial_cuts_dict[variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_spatial = get_save_path_cuts(single_variable=x_var,cuts_dict=spatial_cuts_dict)\n",
    "\n",
    "print(save_path_spatial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_lims = [4,7]\n",
    "# age_lims = [9.5,10]\n",
    "\n",
    "df = MF.apply_cuts_to_df(df=df0,cuts_dict=[spatial_cuts_dict,{\"age\":age_lims}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_steps = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if equal_steps:\n",
    "    if x_var == \"b\":\n",
    "        n_edges = 7 if x_max == 9 else 8\n",
    "        n_points = n_edges - 1\n",
    "    else:\n",
    "        raise ValueError(f\"Number of points not implemented for {x_var} yet.\")\n",
    "\n",
    "    x_edges = np.linspace(x_min,x_max,n_edges)\n",
    "\n",
    "    x_range_min = x_edges[:-1]\n",
    "    x_range_max = x_edges[1:]\n",
    "    \n",
    "    binning_str = \"equal_steps\"\n",
    "    pop_str = f\"{n_points}_bins\"\n",
    "    \n",
    "# Saving the median because upon plotting we can always compute the mean but for the median we need the dataframe\n",
    "x_range_plot = PH.get_range_medians(df[x_var], x_range_min, x_range_max)\n",
    "\n",
    "print(\"Plotting at:\",x_range_plot)\n",
    "print(\"Number of datapoints:\",n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(10,2))\n",
    "\n",
    "ax.errorbar(x=x_range_plot,xerr=PH.get_xerr(minima=x_range_min,maxima=x_range_max,plot=x_range_plot,frac=1),y=[0]*n_points,fmt=\"d\",capsize=20)\n",
    "ax.set_xlim(x_min-(x_max-x_min)/30,x_max+(x_max-x_min)/30)\n",
    "ax.minorticks_on()\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of stars per bin\n",
    "stat.binned_statistic(values=None,x=df[x_var].values,bins=x_edges,statistic=\"count\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = get_save_path_sim(save_path_spatial, bar_angle=rot_angle,resampled_sim_bool=sim_resampled_bool, age_lims=age_lims,\\\n",
    "                              binning_str=binning_str, pop_str=pop_str)\n",
    "\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metal_lowcut = -9999\n",
    "metal_lowcut = -1\n",
    "\n",
    "data_trim = data[data['FeH']>=metal_lowcut]\n",
    "\n",
    "print(f\"Chose minimum metallicity of {metal_lowcut}\" if metal_lowcut != -9999 else \"No minimum metallicity\")\n",
    "\n",
    "if metal_lowcut != -9999:\n",
    "    print(f\"Removed {len(data)-len(data_trim)} ({MF.return_int_or_dec((len(data)-len(data_trim))/len(data)*100,2)}%) stars. {len(data_trim)} left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metallicity_median = MF.return_int_or_dec(np.median(data_trim[\"FeH\"]),2)\n",
    "print(metallicity_median,np.sum(data_trim['FeH']<metallicity_median),np.sum(data_trim['FeH']>metallicity_median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metal_lims = [min(data_trim[\"FeH\"]), metallicity_median]\n",
    "# metal_lims = [metallicity_median, max(data_trim[\"FeH\"])]\n",
    "\n",
    "df = MF.apply_cuts_to_df(df=data_trim,cuts_dict=[spatial_cuts_dict,{\"FeH\":metal_lims}])\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "alpha=0.7\n",
    "xmin = data_trim[x_var].min()\n",
    "xmax = data_trim[x_var].max()\n",
    "bins = np.linspace(xmin,xmax,50)\n",
    "\n",
    "ax.hist(data_trim[x_var],bins=bins,label=fr'${str(MF.return_int_or_dec(min(data_trim[\"FeH\"]),2))}\\leq$[Fe/H]$\\leq{str(MF.return_int_or_dec(max(data_trim[\"FeH\"]),2))}$',\\\n",
    "        alpha=alpha,color='grey')\n",
    "\n",
    "if len(data_trim) != len(df):\n",
    "    ax.hist(df[x_var],bins=bins,label=fr'${str(MF.return_int_or_dec(metal_lims[0],2))}\\leq$[Fe/H]$\\leq{str(MF.return_int_or_dec(metal_lims[1],2))}$',\\\n",
    "            alpha=alpha,color='orange')\n",
    "\n",
    "ax.set_xlim(xmin,xmax)\n",
    "ax.axvline(x_min,color=\"orange\");ax.axvline(x_max,color=\"orange\")\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.set_xlabel(x_label)\n",
    "ax.set_ylabel(r\"$N$\",rotation=0,labelpad=20)\n",
    "ax.legend()\n",
    "\n",
    "plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(20,5))\n",
    "ax.hist(df[x_var],bins=500)\n",
    "ticksss = np.arange(x_min,x_max,0.2)\n",
    "ax.set_xticks(ticksss)\n",
    "ax.set_xticklabels(labels=[str(np.float32(t)) for t in ticksss],size=8)\n",
    "ax.set_xlabel(x_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_number = False # divide in equal-number bins across all b\n",
    "equal_number_low = True # divide in equal-number bins below |b|<6.61˚\n",
    "custom_range = False\n",
    "equal_steps = False # divide in constant latitude steps\n",
    "\n",
    "plot_median_bool = True\n",
    "# plot_median_bool = False # mid-point of bin\n",
    "\n",
    "if x_var == \"b\":\n",
    "    n_points = 3\n",
    "    n_points += 1 if x_max == 13 else 0\n",
    "else:\n",
    "    raise ValueError(f\"Number of points not implemented for {x_var} yet.\")\n",
    "\n",
    "print(f\"{n_points} total points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert equal_number+equal_number_low+custom_range+equal_steps == 1, \"Choose a single range selection\"\n",
    "\n",
    "if x_var == \"b\":\n",
    "    if equal_number:\n",
    "        x_edges = PH.get_equal_n_bin_edges(df[x_var], n_points)\n",
    "\n",
    "        x_range_max = x_edges[1:]\n",
    "        x_range_min = x_edges[:-1]\n",
    "\n",
    "        range_path = \"\"\n",
    "\n",
    "    if equal_number_low:\n",
    "        low_max = np.max(df[df[x_var]<6.8][x_var])\n",
    "        n_points_low = n_points-2 if x_max == 13 else n_points-1\n",
    "        edges_low = PH.get_equal_n_bin_edges(df[df[x_var]<=low_max][x_var], n_points_low)\n",
    "\n",
    "    #     print(edges_low)\n",
    "\n",
    "        high_min = np.min(df[df[x_var]>6.8][x_var])\n",
    "        high_max = np.max(df[df[x_var]<9][x_var])\n",
    "\n",
    "        x_range_min = list(edges_low[:-1]) + [high_min]\n",
    "        x_range_max = list(edges_low[1:]) + [high_max]\n",
    "\n",
    "    #     print(x_range_min,x_range_max)\n",
    "\n",
    "        if x_max == 13:\n",
    "            higher_min = np.min(df[df[x_var]>9][x_var])\n",
    "            higher_max = np.max(df[x_var])\n",
    "\n",
    "            x_range_min += [higher_min]\n",
    "            x_range_max += [higher_max]\n",
    "\n",
    "        x_range_min = np.array(x_range_min)\n",
    "        x_range_max = np.array(x_range_max)\n",
    "    elif custom_range:\n",
    "        range_dict = {\n",
    "            '1min': [0.5,  2.5,  4,    7],\n",
    "            '1max': [2.5,  4,    6.1,  9],\n",
    "\n",
    "            '1.5min': [0.5,2.5,4,7],\n",
    "            '1.5max': [2.5,4,6.2,9],\n",
    "\n",
    "            '2min': [1,2.5,4,7.1],\n",
    "            '2max': [2.5,4,6.61,9]\n",
    "        }\n",
    "\n",
    "        if x_max==13:\n",
    "            range_dict[\"2min\"] += [10.4]\n",
    "            range_dict[\"2max\"] += [13]\n",
    "\n",
    "        x_range_min = range_dict[str(lmax)+'min']\n",
    "        x_range_max = range_dict[str(lmax)+'max']\n",
    "\n",
    "        n_points = len(x_range_plot)    \n",
    "    elif equal_steps:\n",
    "        x_edges = np.linspace(x_min,x_max,n_points)\n",
    "        x_range_min = x_edges[:-1]\n",
    "        x_range_max = x_edges[1:]\n",
    "else:\n",
    "    raise ValueError(f\"Binning not implemented for {x_var} yet.\")\n",
    "\n",
    "# Saving the median because upon plotting we can always compute the mean but for the median we need the dataframe\n",
    "x_range_plot = PH.get_range_medians(df[x_var], x_range_min, x_range_max)\n",
    "\n",
    "binning_str = np.array([\"equal_number\",\"equal_number_low\",\"custom_range\",\"equal_steps\"])[np.array([equal_number,equal_number_low,custom_range,equal_steps])][0]\n",
    "pop_str = f\"{n_points}_bins\"\n",
    "\n",
    "print(\"Plotting at:\",x_range_plot,\"\\n\")\n",
    "print(f\"{n_points} datapoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = get_save_path_data(save_path_spatial, metal_lowcut, metal_lims, binning_str, pop_str)\n",
    "\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MP.visualise_1D_binning(df[x_var],x_range_min,bin_edges_max=x_range_max,save_bool=True,save_path=save_path,xlabel=x_label,log=False,\\\n",
    "                       hist_bins=400 if not data_bool else 100)\n",
    "\n",
    "if not data_bool:\n",
    "    MP.visualise_1D_binning(df[x_var],x_range_min,bin_edges_max=x_range_max,save_bool=True,save_path=save_path,xlabel=x_label,log=True,\\\n",
    "                           hist_bins=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_hist_bool = True\n",
    "# vel_hist_bool = False\n",
    "\n",
    "velhist_bins = 100 if not data_bool else 50\n",
    "\n",
    "if vel_hist_bool:\n",
    "    save_path_hist = save_path + \"vel_histograms/\"\n",
    "    MF.create_dir(save_path_hist)\n",
    "    \n",
    "    save_path_hist += f\"{velhist_bins}bins/\"\n",
    "    MF.create_dir(save_path_hist)\n",
    "    \n",
    "    print(\"Saving velocity histograms on\\n\",save_path_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # example vel hist\n",
    "    MP.plot_velocity_histograms_both_stats(df[(df[x_var]>=min(x_range_min))&(df[x_var]<=min(x_range_max))],vel_x_variable,vel_y_variable,\\\n",
    "                                               bins=velhist_bins,colour_var=\"x\",save_bool=False,suffix=\"example\",verbose=True,show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_repeat = 500\n",
    "\n",
    "min_star_number = 100 if not data_bool else 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = {}\n",
    "for map_string in full_map_string_list:\n",
    "    map_dict[map_string] = np.zeros(shape=(len(x_range_min)))\n",
    "\n",
    "for x_index, (xmin, xmax) in enumerate(zip(x_range_min,x_range_max)):\n",
    "\n",
    "    print(xmin,xmax)\n",
    "    \n",
    "    include_lims = \"both\" if x_index==len(x_range_min)-1 else \"min\"\n",
    "    df_x = MF.apply_cuts_to_df(df, cuts_dict={x_var:[xmin,xmax]}, lims_dict={x_var:include_lims})\n",
    "\n",
    "    if vel_hist_bool:\n",
    "        name_suffix = f\"{str(MF.return_int_or_dec(xmin,dec=2))}{x_var}{str(MF.return_int_or_dec(xmax,dec=2))}\"\n",
    "        MP.plot_velocity_histograms_both_stats(df_x,vel_x_variable,vel_y_variable,save_bool=True,save_path=save_path_hist,suffix=name_suffix,verbose=x_index==0,bins=velhist_bins)\n",
    "\n",
    "    values = val_err.get_all_variable_values_and_errors(df_x[f\"v{vel_x_variable}\"].values,df_x[f\"v{vel_y_variable}\"].values, full_map_string_list,\\\n",
    "                                                            repeat=bootstrap_repeat, min_number = min_star_number)   \n",
    "\n",
    "    if len(values) != len(full_map_string_list):\n",
    "        raise ValueError(\"The length of the values list does not match the string list!\")\n",
    "\n",
    "    for map_string in full_map_string_list:\n",
    "        map_dict[map_string][x_index] = values[map_string]\n",
    "    \n",
    "del df,df_x\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict[\"number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save arrays\n",
    "\n",
    "array_path = save_path + \"arrays/\"\n",
    "MF.create_dir(array_path)\n",
    "\n",
    "if True: # values as .txt and .npy\n",
    "            \n",
    "    with open(array_path+'values.txt','w') as f:\n",
    "        for key in map_dict:\n",
    "            f.write(key+'\\n')\n",
    "            np.savetxt(f,map_dict[key],fmt='%.5f')\n",
    "            f.write('\\n')\n",
    "    \n",
    "    for map_string in full_map_string_list:\n",
    "        np.save(array_path+map_string, map_dict[map_string])\n",
    "        \n",
    "if True: # plot limits as .txt and .npy\n",
    "\n",
    "    with open(array_path+'x_ranges.txt','w') as f:\n",
    "        f.write(\"x_range_min\\n\")\n",
    "        for mini in x_range_min:\n",
    "            f.write(f\"{mini}\\t\")\n",
    "        f.write(\"\\n\\nx_range_max\\n\")\n",
    "        for maxi in x_range_max:\n",
    "            f.write(f\"{maxi}\\t\")\n",
    "        f.write(\"\\n\\nx_range_plot\\n\")\n",
    "        for p in x_range_plot:\n",
    "            f.write(f\"{p}\\t\")\n",
    "    \n",
    "    np.save(array_path+\"x_range_min\", x_range_min)\n",
    "    np.save(array_path+\"x_range_max\", x_range_max)\n",
    "    np.save(array_path+\"x_range_plot\", x_range_plot)\n",
    "    \n",
    "print(\"Saved .txt and .npy in\",array_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With distance division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_range = np.linspace(dmin,dmax,5)[:-1]\n",
    "d_step = np.diff(d_range)[0]\n",
    "\n",
    "# d_range = [6]\n",
    "# d_step = 4\n",
    "\n",
    "print(d_range,d_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_arrays = np.zeros(shape=(7,len(b_range),len(df_ages)))\n",
    "variables = [\"vertex_abs\", \"anisotropy\", \"correlation\"]\n",
    " \n",
    "for b_index,latitude in enumerate(b_range):\n",
    "    for age_index,df in enumerate(df_ages):\n",
    "        df_b = df[(df['b']>latitude)&(df['b']<latitude+b_step)]\n",
    "        df_b = df[(df['b']>latitude)&(df['b']<latitude+b_step)]\n",
    "        \n",
    "        values_d = []\n",
    "        for d_index, distance in enumerate(d_range):\n",
    "            vr = df_b[(df_b['d']>distance)&(df_b['d']<distance+d_step)].vr.values\n",
    "            vl = df_b[(df_b['d']>distance)&(df_b['d']<distance+d_step)].vl.values\n",
    "\n",
    "            values_d.append(get_all_variable_values_and_errors(vr,vl,bootstrap_repeat=100,min_number=min_number_sim))\n",
    "        \n",
    "        values_d = np.array(values_d)\n",
    "        values = []\n",
    "        \n",
    "        for var in variables:\n",
    "            val_index = np.where(full_map_string_list == var)[0][0]\n",
    "            err_index = np.where(full_map_string_list == (var+\"_error\"))[0][0]\n",
    "            \n",
    "            mean_variance = 1/np.sum(1/values_d[:,err_index]**2)\n",
    "            mean = mean_variance*np.sum(values_d[:,val_index]/values_d[:,err_index]**2)\n",
    "            values.append(mean)\n",
    "            values.append(np.sqrt(mean_variance))\n",
    "                \n",
    "        for index, val in enumerate(values):\n",
    "            all_arrays[index, b_index, age_index] = val\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_d_variables = []\n",
    "for i in variables:\n",
    "    full_d_variables.append(i)\n",
    "    full_d_variables.append(i+'_error')\n",
    "\n",
    "d_map_dict = {}\n",
    "for variable, array in zip(full_d_variables,all_arrays):\n",
    "    d_map_dict[variable] = array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'vertex_abs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "if var == 'vertex_abs':\n",
    "    ax.set_ylim(-45,45)\n",
    "else:\n",
    "    max_val = np.max(np.abs(map_dict[var])) + 0.05\n",
    "#     ax.set_ylim(-max_val,max_val)\n",
    "    ax.set_ylim(-0.7,0.5)\n",
    "ax.fill_between(x=b_range_plot,y1=map_dict[var][:,0]-map_dict[var+'_error'][:,0],y2=map_dict[var][:,0]+map_dict[var+'_error'][:,0],color='blue',alpha=0.6,label='Young')\n",
    "ax.fill_between(x=b_range_plot,y1=map_dict[var][:,1]-map_dict[var+'_error'][:,1],y2=map_dict[var][:,1]+map_dict[var+'_error'][:,1],color='red',alpha=0.6,label='Old')\n",
    "ax.axhline(y=0,color='black',linestyle='dotted')\n",
    "ax.set_title(var)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save_path_arrays = save_path + \"arrays/\"\n",
    "if not os.path.isdir(save_path_arrays):\n",
    "    os.mkdir(save_path_arrays)\n",
    "    \n",
    "    for map_string in full_map_string_list:\n",
    "        np.save(save_path_arrays+\"708main_\"+map_string, map_dict[map_string])\n",
    "    print(\"Arrays saved in\",save_path_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BT repeat\n",
    "The standard deviation is the deviation from the mean. We are not calculating the vertex deviation's standard deviation from the mean bootstrap vertex, but from the true vertex instead.\n",
    "Therefore, let's analyse how much these two values, $l_\\mathrm{v}$ and $\\langle l_{\\mathrm{v}}^\\mathrm{bootstrap}\\rangle$, differ for different choices of bootstrap repetitions.\n",
    "\n",
    "To run the code below, you first have to change the definition of get_std_bootstrap() and get_vertex_std_bootstrap() so that they return the list of bootstrap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_number = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_repeats = np.array([100,500,1000,5000,10000,50000])\n",
    "ani_diff,corr_diff,vertex_diff = [[] for repeat in bootstrap_repeats],[[] for repeat in bootstrap_repeats],[[] for repeat in bootstrap_repeats]\n",
    "\n",
    "df = df_ages[1] ###\n",
    "for b_index,latitude in enumerate(b_range):\n",
    "    start = time.time()\n",
    "    #for age_index,df in enumerate(df_ages):\n",
    "    \n",
    "    vr = df[(df['b']>latitude)&(df['b']<latitude+b_step)].vr.values\n",
    "    vl = df[(df['b']>latitude)&(df['b']<latitude+b_step)].vl.values\n",
    "\n",
    "    number = len(vr)\n",
    "\n",
    "    if number > min_number:\n",
    "\n",
    "        cov = np.cov(vr,vl)\n",
    "\n",
    "        true_anisotropy = 1-cov[1,1]/cov[0,0]\n",
    "        true_correlation = cov[0,1]/np.sqrt(cov[0,0]*cov[1,1])\n",
    "        true_vertex = np.degrees(np.arctan2(2.*cov[0,1], cov[0,0]-cov[1,1])/2.)\n",
    "\n",
    "        for repeat_index, bootstrap_repeat in enumerate(bootstrap_repeats):\n",
    "\n",
    "            anisotropy_boot_values,_ = get_std_bootstrap(vr,vl,calculate_anisotropy,repeat=bootstrap_repeat)\n",
    "            correlation_boot_values,_ = get_std_bootstrap(vr,vl,calculate_correlation,repeat=bootstrap_repeat)\n",
    "            vertex_boot_values,_ = get_vertex_std_bootstrap(vr, vl, repeat=bootstrap_repeat)\n",
    "\n",
    "            ani_diff[repeat_index].append(np.abs(true_anisotropy-np.mean(anisotropy_boot_values)))\n",
    "            corr_diff[repeat_index].append(np.abs(true_correlation-np.mean(correlation_boot_values)))\n",
    "            vertex_diff[repeat_index].append(np.abs(true_vertex-np.mean(vertex_boot_values)))\n",
    "\n",
    "            print(\"Done with repeat\",bootstrap_repeat)\n",
    "                \n",
    "    print(\"Done with latitude index\",b_index)\n",
    "    end = time.time()\n",
    "    print(\"Took\",(end-start)/60,\"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_variable = \"vertex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs_dict = {\n",
    "    \"anisotropy\": ani_diff,\n",
    "    \"correlation\": corr_diff,\n",
    "    \"vertex\": vertex_diff\n",
    "}\n",
    "\n",
    "ylabel_dict = {\n",
    "    \"anisotropy\": r\"abs($a_{rl} - \\langle a_{rl}^{\\mathrm{bootstrap}} \\rangle$)\",\n",
    "    \"correlation\": r\"abs($\\rho_{rl}-\\langle \\rho_{rl}^{\\mathrm{bootstrap}} \\rangle$)\",\n",
    "    \"vertex\": r\"abs($l_\\mathrm{v}-\\langle l_{\\mathrm{v}}^{\\mathrm{bootstrap}} \\rangle$) [°]\"\n",
    "}\n",
    "\n",
    "diffs = diffs_dict[diff_variable]\n",
    "ylabel = ylabel_dict[diff_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for diff_variable in [\"anisotropy\",\"correlation\",\"vertex\"]:\n",
    "    \n",
    "    diffs = diffs_dict[diff_variable]\n",
    "    ylabel = ylabel_dict[diff_variable]\n",
    "    \n",
    "    diffs_mean = [np.mean(np.abs(array)) for array in diffs]\n",
    "    diffs_95_percentile = [np.percentile(np.abs(array),95) for array in diffs]\n",
    "    diffs_max = [np.max(np.abs(array)) for array in diffs]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    bar_width = 0.1\n",
    "    transparency = 0.6\n",
    "\n",
    "    x_ticks = np.arange(len(bootstrap_repeats))+1\n",
    "    x_ticklabels = [str(repeat) for repeat in bootstrap_repeats]\n",
    "\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels(x_ticklabels)\n",
    "\n",
    "    ax.bar(x_ticks-bar_width,diffs_mean, width=bar_width, label=\"Mean\",alpha=transparency,color='blue')\n",
    "    ax.bar(x_ticks,diffs_95_percentile, width=bar_width, label=\"95 percentile\",alpha=transparency,color='red')\n",
    "    ax.bar(x_ticks+bar_width,diffs_max, width=bar_width, label=\"Maximum\",alpha=transparency,color='green')\n",
    "\n",
    "    linewidth = 0.5\n",
    "    for index in range(len(bootstrap_repeats)):\n",
    "        ax.hlines(diffs_mean[index], xmin=0, xmax=x_ticks[index]-bar_width, color='blue',linestyle='-',lw=linewidth)\n",
    "        ax.hlines(diffs_95_percentile[index], xmin=0, xmax=x_ticks[index], color='red',linestyle='-',lw=linewidth)\n",
    "        ax.hlines(diffs_max[index], xmin=0, xmax=x_ticks[index]+bar_width, color='green',linestyle='-',lw=linewidth)\n",
    "\n",
    "    #ax.legend(bbox_to_anchor=[0.535,0.8])\n",
    "    ax.set_xlabel(\"Bootstrap repeats\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    #ax.set_yticks(np.arange(0,15))\n",
    "    #ax.set_xticks([100,500,1000])\n",
    "    ax.set_xlim(0.75,x_ticks[-1]+0.25)\n",
    "    #ax.set_ylim(0,13)\n",
    "\n",
    "    #ax.set_aspect(50)\n",
    "    filename = f\"old_{bootstrap_repeats[-1]}_{diff_variable}\"\n",
    "    plt.savefig(general_path+\"bootstrap_repeats/\"+filename+\".png\",bbox_inches='tight',dpi=150)\n",
    "    print(\"Saved:\",filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LATPLOT_number_bars_sim(sim_number_array, sim_b_range_plot,alpha=1,zorder=0, show_hist=False):\n",
    "    if show_hist:\n",
    "        ax_histx.hist(df_extra[\"b\"].values,bins=100,color=\"k\",histtype=\"step\")\n",
    "    \n",
    "    ax_histx.bar(sim_b_range_plot-bar_width/2, sim_number_array[:,0], width=bar_width,alpha=alpha,log=True,color=color_y,zorder=zorder)#,hatch=\".\")\n",
    "    ax_histx.bar(sim_b_range_plot+bar_width/2, sim_number_array[:,1], width=bar_width,alpha=alpha,log=True,color=color_o,zorder=zorder)#,hatch=\".\")\n",
    "    \n",
    "def LATPLOT_number_bars_data(data_number_array, o_b_range_plot, alpha=1, zorder=0, linewidth=2,show_hist=False):\n",
    "    if show_hist:\n",
    "        ax_histx.hist(o_df_extra[\"b\"].values,bins=50,color=\"grey\",histtype=\"step\")\n",
    "    \n",
    "    ax_histx.bar(o_b_range_plot-bar_width/2, data_number_array[:,0], width=bar_width,fill=False,log=True,zorder=zorder,linewidth=linewidth,edgecolor=color_y)#,color=\"k\")\n",
    "    ax_histx.bar(o_b_range_plot+bar_width/2, data_number_array[:,1], width=bar_width,fill=False,log=True,zorder=zorder,linewidth=linewidth,edgecolor=color_o)#,color=\"k\")\n",
    "\n",
    "def LATPLOT_values_sim(map_array, error_array, sim_b_range_plot, alpha=1, zorder=0, legend=False):\n",
    "    \n",
    "    if np.all(error_array == 0):\n",
    "        linestyle = None\n",
    "        line_labels = [label_y, label_o] if legend else [None,None]\n",
    "        area_labels = [None,None]\n",
    "    else:\n",
    "        linestyle = \"--\"\n",
    "        line_labels = [None,None]\n",
    "        area_labels = [label_y, label_o] if legend else [None,None]\n",
    "    \n",
    "    ax.plot(sim_b_range_plot, map_array[:,0], color=color_y, linestyle=linestyle, lw=1,zorder=zorder,label=line_labels[0])\n",
    "    ax.plot(sim_b_range_plot, map_array[:,1] , color=color_o, linestyle=linestyle, lw=1,zorder=zorder,label=line_labels[1])\n",
    "\n",
    "    ax.fill_between(sim_b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha, facecolor=color_y, zorder=zorder,label=area_labels[0])\n",
    "    ax.fill_between(sim_b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha, facecolor=color_o, zorder=zorder,label=area_labels[1])\n",
    "\n",
    "    if map_string =='vertex':\n",
    "        # to make it cyclic, mirror what goes below the plot to above\n",
    "        displacement = max(yticks) - min(yticks)\n",
    "        ax.fill_between(sim_b_range_plot, map_array[:,1]-error_array[:,1]+displacement, map_array[:,1]+error_array[:,1]+displacement,alpha=alpha, facecolor=color_o,zorder=zorder)\n",
    "        ax.fill_between(sim_b_range_plot, map_array[:,1]-error_array[:,1]-displacement, map_array[:,1]+error_array[:,1]-displacement,alpha=alpha, facecolor=color_o,zorder=zorder)\n",
    "        ax.fill_between(sim_b_range_plot, map_array[:,0]-error_array[:,0]+displacement, map_array[:,0]+error_array[:,0]+displacement,alpha=alpha, facecolor=color_y,zorder=zorder)\n",
    "        ax.fill_between(sim_b_range_plot, map_array[:,0]-error_array[:,0]-displacement, map_array[:,0]+error_array[:,0]-displacement,alpha=alpha, facecolor=color_y,zorder=zorder)\n",
    "        \n",
    "def LATPLOT_values_data(map_array, error_array, o_b_range_min, o_b_range_max, o_b_range_plot, alpha=1, zorder=1, legend=False):\n",
    "    if False:#map_string == \"anisotropy\" and not outlier_bool:\n",
    "        map_array = copy.copy(map_array)\n",
    "        error_array = copy.copy(error_array)\n",
    "        map_array[-1,0] = np.nan # COMMENT THIS OUT TO CHECK THE LAST DATAPOINT IS INDEED OFF\n",
    "        #error_array[np.where(np.abs(error_array)>2)] = 1        \n",
    "        \n",
    "    marker_size = 7.5\n",
    "    \n",
    "    xerr = PH.get_xerr(o_b_range_min, o_b_range_max, o_b_range_plot, frac=xerr_frac) if x_error_data_bool else None\n",
    "    \n",
    "    ax.errorbar(o_b_range_plot, map_array[:,1] , yerr= error_array[:,1], xerr=xerr, color=color_o, alpha=alpha,capsize=capsize_lat,markersize=marker_size,ls=\"none\",marker=\"$\\u25A1$\",zorder=zorder,label=label_poor if legend else None)\n",
    "    ax.errorbar(o_b_range_plot, map_array[:,0], yerr= error_array[:,0], xerr=xerr, color=color_y, alpha=0.9 if alpha==1 else alpha,capsize=capsize_lat,markersize=marker_size,ls=\"none\",marker=\"$\\u25EF$\",zorder=zorder,label=label_rich if legend else None)\n",
    "    if halo_bool:\n",
    "        ax.errorbar(o_b_range_plot, map_array[:,2] , yerr=error_array[:,2], color='cyan', alpha=0.9 if alpha==1 else alpha,capsize=capsize_lat,markersize=marker_size,ls=\"none\",marker=\"$\\u25B3$\",zorder=zorder,label=label_halo if legend else None)\n",
    "        \n",
    "def LATPLOT_number_bars_axis_settings():\n",
    "    ax_histx.tick_params(axis='x',bottom=False,top=False,labelbottom=False)\n",
    "    ax_histx.tick_params(axis='y',labelleft=False,labelright=True, labelsize=number_bar_labelsize)\n",
    "\n",
    "    histx_ticks = [10**i for i in range(1,6)]\n",
    "    ax_histx.set_yticks(histx_ticks)\n",
    "#     ax_histx.set_yticklabels(['']+[r\"$10^%i$\"%np.log10(i) for i in histx_ticks[1:]])\n",
    "    ax_histx.set_ylabel(r\"$N$\",labelpad=20,rotation=0,size=axis_labelsize)\n",
    "    ax_histx.yaxis.set_label_position(\"right\")\n",
    "        \n",
    "def LATPLOT_xaxis_settings():\n",
    "    xmax = np.max(np.concatenate([sim_b_range_max, o_b_range_max]))\n",
    "    ax.set_xlim(bmin,xmax)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "#     ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "    \n",
    "    ax.set_xlabel(r\"$|b|$ $[^\\circ]$\", size=axis_labelsize)\n",
    "        \n",
    "def LATPLOT_yaxis_settings(map_string, hardcode=True):\n",
    "    if hardcode and map_string in ylim_dict:\n",
    "        ax.set_ylim(ylim_dict[map_string])\n",
    "        \n",
    "    if map_string in ['tilt_abs','vertex_abs']:\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "        \n",
    "#     yticks = get_variable_ticks(map_string, sim_map_array)\n",
    "#     if 'vertex' in map_string:\n",
    "#         ax.set_yticks(yticks)\n",
    "#         ax.set_ylim(min(yticks),max(yticks))\n",
    "#     else:\n",
    "#         ax.yaxis.set_minor_locator(ticker.AutoMinorLocator(2))\n",
    "#         ax.tick_params(which='minor',direction='in',color='black',length=4)\n",
    "    \n",
    "#     ax.yaxis.set_minor_locator(ticker.AutoMinorLocator())\n",
    "\n",
    "    ax.set_ylabel(map_symbol+units_dict[map_string], size=axis_labelsize)\n",
    "        \n",
    "def LATPLOT_legend_and_text(legend_bool, extra_string_bool):\n",
    "\n",
    "    if legend_bool:\n",
    "        if map_string in legend_loc_dict:\n",
    "            leg_location = legend_loc_dict[map_string]\n",
    "            ax.legend(fontsize=legend_fontsize,loc=leg_location)\n",
    "        else:\n",
    "            ax.legend(fontsize=legend_fontsize)\n",
    "    if extra_string_bool:\n",
    "        l_string = fr\"$|l|<{lmax}^\\circ$,\"\n",
    "        extra_string = r\"${%i}<d /\\mathrm{%s}<{%i}$\"%(dmin,'kpc',dmax)\n",
    "        ax.text(x=0.8,y=-0.1,s=l_string+'  '+d_string,size=extra_variables_size,transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number_bar(barax, plot_range, number_array,color,fill_bool=True,alpha=1,zorder=0, bar_width=50,bar_log=True):\n",
    "    barax.bar(plot_range,number_array,width=bar_width,log=bar_log,color=color,alpha=alpha,zorder=zorder,fill=fill_bool)\n",
    "        \n",
    "def plot_values_scatter_with_errors(ax, val_array, err_array, plot_range, min_range, max_range, color, label,line_alpha=1,zorder=0,\\\n",
    "                                    lines_bool=True,x_error_bool=True):\n",
    "    xerror = PH.get_xerr(min_range,max_range,plot_range)\n",
    "\n",
    "    ax.errorbar(plot_range,val_array,yerr=err_array,xerr=xerror if x_error_bool else None,capsize=capsize,marker='.',color=color,\\\n",
    "                label=label,linestyle=None if lines_bool else '',alpha=line_alpha,zorder=zorder)\n",
    "\n",
    "def plot_values_surface(ax, val_array, err_array, plot_range,color,label,line_alpha=1,surface_alpha=0.75,zorder=0):\n",
    "    ax.plot(plot_range,val_array,color=color,alpha=line_alpha,zorder=zorder)\n",
    "    ax.fill_between(plot_range,val_array-err_array,val_array+err_array,label=label,color=color,alpha=surface_alpha,linewidth=0,zorder=zorder)\n",
    "        \n",
    "def set_number_bar_axis_settings(barax,min_n,max_n,bar_log=True,labels_on=True,min_shift_bool=True,max_shift_bool=True):\n",
    "    if bar_log:\n",
    "        exponent_ticks = np.arange(MF.get_exponent(min_n),MF.get_exponent(max_n)+1,1)\n",
    "        barax.set_yticks([10**i for i in exponent_ticks])\n",
    "        barax.set_ylim(bottom = 10**min(exponent_ticks) - (min_n/3 if min_shift_bool else 0))\n",
    "        barax.set_ylim(top = max_n + (10**MF.get_exponent(max_n) if max_shift_bool else 0))\n",
    "    elif equal_number:\n",
    "        barax.set_yticks([0,max_n])\n",
    "            \n",
    "    barax.yaxis.set_tick_params(which='minor', right=True,left=False)\n",
    "\n",
    "    barax.tick_params(which='both',labelleft=False,labelright=labels_on)\n",
    "    barax.tick_params(which='minor',labelright=False)\n",
    "\n",
    "    if labels_on:\n",
    "        barax.set_ylabel(r\"$N$\",rotation=0,labelpad=20)\n",
    "        barax.yaxis.set_label_position(\"right\")\n",
    "    \n",
    "def set_xaxis_settings(ax,xmin,xmax,xlabel,xticks=None,labels_on=True):\n",
    "#     ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.25))\n",
    "    \n",
    "    ax.set_xlim(xmin,xmax)\n",
    "    \n",
    "    if xticks is not None:\n",
    "        ax.set_xticks(xticks)\n",
    "    \n",
    "    if labels_on:\n",
    "        ax.set_xlabel(xlabel)\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "def compute_ylims(map_dict, map_string, error_string, var1_bool=False):\n",
    "    minimum = np.nanmin(map_dict[map_string]-map_dict[error_string])\n",
    "    maximum = np.nanmax(map_dict[map_string]+map_dict[error_string])\n",
    "\n",
    "    if var1_bool:\n",
    "        minimum1 = np.nanmin(map_dict[var1]-map_dict[err1])\n",
    "        maximum1 = np.nanmax(map_dict[var1]+map_dict[err1])\n",
    "\n",
    "        minimum = min([minimum,minimum1])\n",
    "        maximum = max([maximum,maximum1])\n",
    "    \n",
    "    if map_string in yshift_dict:\n",
    "        minimum -= yshift_dict[map_string]\n",
    "        maximum += yshift_dict[map_string]\n",
    "\n",
    "    if symmetric_ylims_bool:\n",
    "        maxabs = np.nanmax(np.abs([minimum,maximum]))\n",
    "        ax.set_ylim(-maxabs,maxabs)\n",
    "    else:\n",
    "        ax.set_ylim(minimum,maximum)\n",
    "        \n",
    "def set_yaxis_settings(ax, map_string, error_string, map_dict=None, labels_on=True,var1_bool=False, set_ylims=True):\n",
    "    \n",
    "    if map_string == 'tilt_abs':# or \"mean\" in map_string or \"std\" in map_string:\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "        #ax.yaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "    elif map_string == 'anisotropy':# or map_string == 'correlation':\n",
    "#         ax.yaxis.set_major_locator(ticker.MultipleLocator(0.25))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "        ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.25))\n",
    "    elif map_string == \"correlation\":\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(0.15))\n",
    "#     elif map_string in [\"mean_vx\",\"mean_vy\"]:\n",
    "#         ax.yaxis.set_major_locator(ticker.MultipleLocator(15))\n",
    "    elif map_string in [\"std_vx\",\"std_vy\"]:\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "    \n",
    "    if not var1_bool and labels_on:\n",
    "        ax.set_ylabel(symbol_dict[map_string]+units_dict[map_string],fontsize=ylabel_size)\n",
    "    \n",
    "    if set_ylims:\n",
    "        if hard_coded_ylims_bool and map_string in hard_coded_ylims:\n",
    "            ax.set_ylim(hard_coded_ylims[map_string])\n",
    "        else:\n",
    "            if map_dict is None:\n",
    "                raise ValueError(\"Cannot compute ylims if `map_dict` is None.\")\n",
    "            _PLOT1D_compute_ylims(map_dict, map_string, error_string, var1_bool=var1_bool)\n",
    "        \n",
    "    if not labels_on:\n",
    "        ax.set_yticklabels([])\n",
    "        \n",
    "def get_label(map_string):\n",
    "    return symbol_dict[map_string]+units_dict[map_string]\n",
    "\n",
    "def get_legend_label(var_tuple,variable):\n",
    "    var_symbol = pos_symbols_dict[variable]\n",
    "    var_units = pos_units_dict[variable]\n",
    "    \n",
    "    if var_tuple[0] == 0:\n",
    "        return var_symbol + fr\"$< {var_tuple[1]}~$\"+var_units\n",
    "    else:\n",
    "        return r\"$%s<$\"%str(var_tuple[0]) + var_symbol + r\"$/\\mathrm{%s}$\"%var_units + fr\"$<{var_tuple[1]}$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_values_and_plot_ranges(path,full_map_string_list):\n",
    "    \n",
    "    map_dict = {}\n",
    "    for m in full_map_string_list:\n",
    "        map_dict[m] = np.load(f\"{path}{m}.npy\")\n",
    "    \n",
    "    min_range = np.load(path + f\"pop_min_range.npy\")\n",
    "    max_range = np.load(path + f\"pop_max_range.npy\")\n",
    "    plot_range = np.load(path + f\"pop_plot_range.npy\")\n",
    "    \n",
    "    return map_dict, min_range, max_range, plot_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_bool: #metallicity labels\n",
    "    if metal_rich_highlim is None:\n",
    "        label_rich = fr'[Fe/H]-rich ($>{str(metal_rich_lowlim)}$)'\n",
    "    else:\n",
    "        label_rich = fr'[Fe/H]-rich (${str(metal_rich_lowlim)}$-${str(metal_rich_highlim)}$)'\n",
    "\n",
    "    if metal_poor_lowlim is None:\n",
    "        label_poor = fr'[Fe/H]-poor ($<{str(metal_rich_lowlim)}$)'\n",
    "    else:\n",
    "        label_poor = fr'[Fe/H]-poor (${str(metal_poor_lowlim)}$-$<{str(metal_poor_highlim)}$)'\n",
    "\n",
    "    MP.show_text(label_rich+\"\\n\"+label_poor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fontsizes and legend loc\n",
    "plt.rcParams.update({'font.size' : 25})\n",
    "axis_labelsize = \"large\"\n",
    "legend_fontsize = \"21.5\"\n",
    "number_bar_labelsize = \"medium\"\n",
    "extra_variables_size = \"x-small\"\n",
    "capsize_lat = 5\n",
    "\n",
    "legend_loc_dict = {\n",
    "    'anisotropy':'lower left',\n",
    "    'correlation':(0.4,0.71),\n",
    "    'tilt_abs':(0.4,0.71)\n",
    "}\n",
    "\n",
    "ylim_dict = {\n",
    "    \"tilt_abs\": [-45,3],\n",
    "    \"vertex_abs\": [-45,3],\n",
    "}\n",
    "\n",
    "bar_width=0.2 if bmax == 9 else 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra_string_bool = True\n",
    "extra_string_bool = False\n",
    "\n",
    "number_bool = True\n",
    "# number_bool = False\n",
    "\n",
    "x_error_data_bool = True; xerr_frac = 2\n",
    "# x_error_data_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some reference values\n",
    "\n",
    "l_cuts = [-2,2]\n",
    "y_cuts = MF.return_int_or_dec_for_array([coordinates.ang_to_rect(ang=l_cut,x=coordinates.get_solar_radius()) for l_cut in l_cuts])\n",
    "\n",
    "b_range_min,b_range_max = PH.get_equal_n_minmax_b_ranges(data_trim)\n",
    "b_variations = [[MF.return_int_or_dec(m,2),MF.return_int_or_dec(M,2)] for (m,M) in zip(b_range_min,b_range_max)]\n",
    "\n",
    "z_range_min = [coordinates.ang_to_rect(ang=bmin,x=coordinates.get_solar_radius()) for bmin in b_range_min]\n",
    "z_range_max = [coordinates.ang_to_rect(ang=bmax,x=coordinates.get_solar_radius()) for bmax in b_range_max]\n",
    "z_variations = [[MF.return_int_or_dec(m,2),MF.return_int_or_dec(M,2)] for (m,M) in zip(z_range_min,z_range_max)]\n",
    "\n",
    "R_variations = [[0,3.5],[0,2]]\n",
    "\n",
    "print(\"l\",l_cuts)\n",
    "print(\"y\",y_cuts)\n",
    "print(\"b\",b_variations)\n",
    "print(\"z\",z_variations)\n",
    "print(\"R\",R_variations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinpop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_units_dict[\"b\"] = \"deg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://colorbrewer2.org/#type=qualitative&scheme=Dark2&n=3\n",
    "\n",
    "# colors = [\"blue\",\"blue\",\"blue\"]\n",
    "colors = [\"#1b9e77\",\"#d95f02\",\"#7570b3\"]\n",
    "\n",
    "line_alpha = 0.9\n",
    "surface_alpha = 0.75\n",
    "alpha_reduction_factor = 0.25\n",
    "\n",
    "number_alpha = 0.75\n",
    "number_alpha_reduction_factor = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim galactic vs rectangular 3 columns\n",
    "\n",
    "# binning_type = \"equalN\"\n",
    "binning_type = \"equalSteps\"\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/1.5b3.51/sim/{binning_type}/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-0.28y0.28/0.21z0.5/sim/{binning_type}/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/1.5b3.51/sim/{binning_type}/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-0.28y0.28/0.21z0.5/sim/{binning_type}/40_datapoints/arrays/\"\n",
    "        ],\n",
    "        \"labels\": [None,None,get_legend_label([1.5,3.51],\"b\"),get_legend_label([0.21,0.5],\"z\")],\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/3.51b6.6/sim/{binning_type}/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-0.28y0.28/0.5z0.94/sim/{binning_type}/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/3.51b6.6/sim/{binning_type}/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-0.28y0.28/0.5z0.94/sim/{binning_type}/20_datapoints/arrays/\"\n",
    "        ],\n",
    "        \"labels\": [None,None,get_legend_label([3.51, 6.6],\"b\"),get_legend_label([0.5,0.94],\"z\")],\n",
    "    },\n",
    "    2: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/7.13b8.85/sim/{binning_type}/10_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-0.28y0.28/1.01z1.26/sim/{binning_type}/10_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/7.13b8.85/sim/{binning_type}/10_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-0.28y0.28/1.01z1.26/sim/{binning_type}/10_datapoints/arrays/\"\n",
    "        ],\n",
    "        \"labels\": [None,None,get_legend_label([7.13, 8.85],\"b\"),get_legend_label([0.5,0.94],\"z\")],\n",
    "    },   \n",
    "}\n",
    "\n",
    "save_path = get_base_POPPLOT_path(resampled_sim_bool=False) + \\\n",
    "            f\"0R3.5_0R2/-2l2_-0.28y0.28/1.5b3.51_0.21z0.5__3.51b6.6_0.5z0.94__7.13b8.85_1.01z1.26/sim/sim_{binning_type}/sim_n40,40_n40,40__n20,20_n20,20__n10,10_n10,10/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [5,6,7,8]\n",
    "    all_dicts[key][\"colors\"] = 2*[\"blue\", \"orange\"]\n",
    "    all_dicts[key][\"line_alphas\"] = 2*[alpha_reduction_factor*line_alpha] + 2*[line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 2*[alpha_reduction_factor*surface_alpha] + 2*[surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = 2*[number_alpha_reduction_factor*number_alpha] + 2*[number_alpha]\n",
    "    all_dicts[key][\"zorderNs\"] = [6,6,5,5]\n",
    "    all_dicts[key][\"plot_ranges_str\"] = nplots*[\"mean\"]\n",
    "    all_dicts[key][\"surface_bools\"] = nplots*[True]\n",
    "    all_dicts[key][\"scatter_join_bools\"] = nplots*[True]\n",
    "    all_dicts[key][\"number_bools\"] = [False,False,True,True]\n",
    "    \n",
    "    all_dicts[key][\"invert_xaxis\"] = True\n",
    "    all_dicts[key][\"title\"] = None\n",
    "    all_dicts[key][\"xaxis_label\"] = \"Age [Gyr]\"\n",
    "    all_dicts[key][\"x_ticks\"] = np.arange(5,11,1) #np.arange(-0.9,0.6+0.3,0.3)\n",
    "    all_dicts[key][\"x_lims\"] = [4,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim normal vs resampled 3 columns\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/sim/equalN/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/sim/equalN/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R2/-2l2/1.5b3.51/sim/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R3.5/-2l2/1.5b3.51/sim/equalN/4_datapoints/arrays/\",\n",
    "\n",
    "        ],\n",
    "        \"title\": get_legend_label([1.5,3.51],\"b\"),\n",
    "        \"labels\": 4*[None],\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/sim/equalN/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/sim/equalN/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R2/-2l2/3.51b6.6/sim/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R3.5/-2l2/3.51b6.6/sim/equalN/4_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": get_legend_label([3.51,6.6],\"b\"),\n",
    "        \"labels\": [None,\"Model\",None,\"Resampled model (k=10)\"]\n",
    "    },\n",
    "    2: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/sim/equalN/15_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/sim/equalN/15_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R2/-2l2/7.13b8.85/sim/equalN/3_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R3.5/-2l2/7.13b8.85/sim/equalN/3_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": get_legend_label([7.13,8.85],\"b\"),\n",
    "        \"labels\": 4*[None]\n",
    "    },\n",
    "    \n",
    "}\n",
    "\n",
    "save_path = get_base_POPPLOT_path(resampled_sim_bool=False) + \\\n",
    "            \"sim__resampled_sim/0R3.5_0R2/-2l2/1.5b3.51__3.51b6.6__7.13b8.85/sim_equalN/sim_n20,20_n4,4__n20,20_n4,4__n15,15_n3,3/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [5,6,7,8]\n",
    "    all_dicts[key][\"zorderNs\"] = [5,5,6,6]\n",
    "    all_dicts[key][\"colors\"] = [\"blue\",\"blue\",\"orange\",\"orange\"]\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = 2*[alpha_reduction_factor*line_alpha, line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 2*[alpha_reduction_factor*surface_alpha, surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    \n",
    "    all_dicts[key][\"plot_ranges_str\"] = [\"mean\",\"mean\",\"median\",\"median\"]\n",
    "    all_dicts[key][\"surface_bools\"] = [True,True,False,False]\n",
    "    all_dicts[key][\"scatter_join_bools\"] = nplots*[True]\n",
    "    all_dicts[key][\"number_bools\"] = [False,True,False,True]\n",
    "    \n",
    "    all_dicts[key][\"invert_xaxis\"] = True\n",
    "    all_dicts[key][\"xaxis_label\"] = \"Age [Gyr]\"\n",
    "    all_dicts[key][\"x_ticks\"] = np.arange(5,11,1) #np.arange(-0.9,0.6+0.3,0.3)\n",
    "    all_dicts[key][\"x_lims\"] = [4,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data and sim 2 columns (sim equalN)\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Data\",\n",
    "        \"labels\": 6*[None],\n",
    "        \"plot_ranges_str\": 6*[\"median\"],\n",
    "        \"surface_bools\": 6*[False],\n",
    "        \"invert_xaxis\": False,\n",
    "        \"xaxis_label\": \"[Fe/H]\",\n",
    "        \"x_ticks\": np.arange(-0.9,0.6+0.3,0.3),\n",
    "        \"x_lims\": [-1,0.61]\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/sim/equalN/30_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/sim/equalN/30_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/sim/equalN/25_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/sim/equalN/30_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/sim/equalN/30_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/sim/equalN/25_datapoints/arrays/\",\n",
    "\n",
    "        ],\n",
    "        \"title\": \"Model\",\n",
    "        \"labels\": 3*[None] + [get_legend_label([1.5,3.51],\"b\"), get_legend_label([3.51,6.6],\"b\"), get_legend_label([7.13,8.85],\"b\")],\n",
    "        \"plot_ranges_str\": 6*[\"mean\"],\n",
    "        \"surface_bools\": 6*[True],\n",
    "        \"invert_xaxis\": True,\n",
    "        \"xaxis_label\": \"Age [Gyr]\",\n",
    "        \"x_ticks\": np.arange(5,10,1),\n",
    "        \"x_lims\": [4,10]\n",
    "    }, \n",
    "}\n",
    "\n",
    "save_path = get_base_POPPLOT_path(resampled_sim_bool=False) + \\\n",
    "            \"0R3.5_0R2/-2l2/1.5b3.51_3.51b6.6_7.13b8.85/both/data_equalN/data_n4,4,3_n4,4,3/sim_equalN/sim_n30,30,25_n30,30,25/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [5,4,3,8,7,6]\n",
    "    all_dicts[key][\"zorderNs\"] = [5,5,5,6,7,8]\n",
    "    all_dicts[key][\"colors\"] = 2*colors\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = 3*[alpha_reduction_factor*line_alpha] + 3*[line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 3*[alpha_reduction_factor*surface_alpha] + 3*[surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    \n",
    "    all_dicts[key][\"number_bools\"] = 3*[False] + 3*[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data and sim 2 columns (sim equalSteps)\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Data\",\n",
    "        \"labels\": 6*[None],\n",
    "        \"plot_ranges_str\": 6*[\"median\"],\n",
    "        \"surface_bools\": 6*[False],\n",
    "        \"invert_xaxis\": False,\n",
    "        \"xaxis_label\": \"[Fe/H]\",\n",
    "        \"x_ticks\": np.arange(-0.9,0.6+0.3,0.3),\n",
    "        \"x_lims\": [-1,0.61]\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/sim/equalSteps/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/sim/equalSteps/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/sim/equalSteps/10_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/sim/equalSteps/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/sim/equalSteps/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/sim/equalSteps/10_datapoints/arrays/\",\n",
    "\n",
    "        ],\n",
    "        \"title\": \"Model\",\n",
    "        \"labels\": 3*[None] + [get_legend_label([1.5,3.51],\"b\"), get_legend_label([3.51,6.6],\"b\"), get_legend_label([7.13,8.85],\"b\")],\n",
    "        \"plot_ranges_str\": 6*[\"mean\"],\n",
    "        \"surface_bools\": 6*[True],\n",
    "        \"invert_xaxis\": True,\n",
    "        \"xaxis_label\": \"Age [Gyr]\",\n",
    "        \"x_ticks\": np.arange(4,10,1),\n",
    "        \"x_lims\": [4,10]\n",
    "    }, \n",
    "}\n",
    "\n",
    "save_path = get_base_POPPLOT_path(resampled_sim_bool=False) + \\\n",
    "            \"0R3.5_0R2/-2l2/1.5b3.51_3.51b6.6_7.13b8.85/both/data_equalN/data_n4,4,3_n4,4,3/sim_equalSteps/sim_n40,20,10_n40,20,10/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [5,4,3,8,7,6]\n",
    "    all_dicts[key][\"zorderNs\"] = [5,5,5,6,7,8]\n",
    "    all_dicts[key][\"colors\"] = 2*colors\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = 3*[alpha_reduction_factor*line_alpha] + 3*[line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 3*[alpha_reduction_factor*surface_alpha] + 3*[surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    \n",
    "    all_dicts[key][\"number_bools\"] = 3*[False] + 3*[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, sim and sim resampled 3 columns\n",
    "\n",
    "# sim_binning_type = \"equalN\"\n",
    "sim_binning_type = \"equalSteps\"\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Data\",\n",
    "        \"labels\": 6*[None],\n",
    "        \"plot_ranges_str\": 6*[\"median\"],\n",
    "        \"surface_bools\": 6*[False],\n",
    "        \"invert_xaxis\": False,\n",
    "        \"xaxis_label\": \"[Fe/H]\",\n",
    "        \"x_ticks\": np.arange(-0.9,0.6+0.3,0.3),\n",
    "        \"x_lims\": [-1,0.61],\n",
    "        \"bar_width\": 0.03\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/1.5b3.51/sim/{sim_binning_type}/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/3.51b6.6/sim/{sim_binning_type}/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/7.13b8.85/sim/{sim_binning_type}/10_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/1.5b3.51/sim/{sim_binning_type}/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/3.51b6.6/sim/{sim_binning_type}/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/7.13b8.85/sim/{sim_binning_type}/10_datapoints/arrays/\",\n",
    "\n",
    "        ],\n",
    "        \"title\": \"Model\",\n",
    "        \"labels\": 3*[None] + [get_legend_label([1.5,3.51],\"b\"), get_legend_label([3.51,6.6],\"b\"), get_legend_label([7.13,8.85],\"b\")],\n",
    "        \"plot_ranges_str\": 6*[\"mean\"],\n",
    "        \"surface_bools\": 6*[True],\n",
    "        \"invert_xaxis\": True,\n",
    "        \"xaxis_label\": \"Age [Gyr]\",\n",
    "        \"x_ticks\": np.arange(5,10,1),\n",
    "        \"x_lims\": [4,10],\n",
    "        \"bar_width\": 0.05\n",
    "    },\n",
    "    2: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R2/-2l2/1.5b3.51/sim/{sim_binning_type}/8_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R2/-2l2/3.51b6.6/sim/{sim_binning_type}/5_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R2/-2l2/7.13b8.85/sim/{sim_binning_type}/3_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R3.5/-2l2/1.5b3.51/sim/{sim_binning_type}/8_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R3.5/-2l2/3.51b6.6/sim/{sim_binning_type}/6_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R3.5/-2l2/7.13b8.85/sim/{sim_binning_type}/4_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Resampled model\",\n",
    "        \"labels\": 6*[None],\n",
    "        \"plot_ranges_str\": 6*[\"median\"],\n",
    "        \"surface_bools\": 6*[False],\n",
    "        \"invert_xaxis\": True,\n",
    "        \"xaxis_label\": \"Age [Gyr]\",\n",
    "        \"x_ticks\": np.arange(5,10,1),\n",
    "        \"x_lims\": [4,10],\n",
    "        \"bar_width\": 0.12\n",
    "    }    \n",
    "}\n",
    "\n",
    "save_path = get_base_POPPLOT_path(resampled_sim_bool=False) + \\\n",
    "            f\"data__sim__resampled_sim/0R3.5_0R2/-2l2/1.5b3.51_3.51b6.6_7.13b8.85/both/data_equalN__sim_{sim_binning_type}/\"+\\\n",
    "            \"data_n4,4,3_n4,4,3__sim_n40,20,10_n40,20,10__resampledsim_n8,6,4_n8,5,3/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [5,4,3,8,7,6]\n",
    "    all_dicts[key][\"zorderNs\"] = [5,5,5,6,7,8]\n",
    "    all_dicts[key][\"colors\"] = 2*colors\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = 3*[alpha_reduction_factor*line_alpha] + 3*[line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 3*[alpha_reduction_factor*surface_alpha] + 3*[surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    \n",
    "    all_dicts[key][\"number_bools\"] = 3*[False] + 3*[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in all_dicts:\n",
    "    print(key)\n",
    "    for path in all_dicts[key][\"load_paths\"]:\n",
    "        print(path)\n",
    "        if not os.path.isdir(path):\n",
    "            raise ValueError(\"Path did not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(save_path,exist_ok=True)\n",
    "\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsize = 5\n",
    "\n",
    "scatter_join_bool = True\n",
    "# scatter_join_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_bool = True\n",
    "# number_bool = False\n",
    "\n",
    "# number_variations_bool = True\n",
    "number_variations_bool = False\n",
    "\n",
    "bar_log = True\n",
    "# bar_log = False\n",
    "\n",
    "if number_bool: # check there are actually any to be plotted\n",
    "    \n",
    "    any_number_bool = False\n",
    "    for key in all_dicts:\n",
    "        any_number_bool = any_number_bool or any(all_dicts[key][\"number_bools\"])\n",
    "        \n",
    "    if not any_number_bool:\n",
    "        number_bool = False\n",
    "        print(\"No plot with number bool to draw, setting number_bool=False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_coded_ylims_bool = True # currently needed to ensure the y axis is shared correctly\n",
    "# hard_coded_ylims_bool = False\n",
    "\n",
    "# symmetric_ylims_bool = True\n",
    "symmetric_ylims_bool = False\n",
    "\n",
    "hard_coded_ylims = {\n",
    "#     \"tilt_abs\": [-45,3],\n",
    "    \"tilt_abs\": [-45,45],\n",
    "}\n",
    "\n",
    "yshift_dict = {\n",
    "    \"tilt_abs\": 2,\n",
    "    \"anisotropy\": 0.02,\n",
    "    \"correlation\": 0.01,\n",
    "    \"mean_vx\": 1,\n",
    "    \"mean_vy\": 1,\n",
    "    \"std_vx\": 2,\n",
    "    \"std_vy\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_legend_params(ncols, all_dicts,number_bool):\n",
    "    \n",
    "    if ncols != len(all_dicts):\n",
    "        raise ValueError(\"Expected the `ncols` to match the length of `all_dicts`.\")\n",
    "    \n",
    "    legend_cols = []\n",
    "    for k in all_dicts.keys():\n",
    "        if any(all_dicts[k][\"labels\"]):\n",
    "            legend_cols.append(k)\n",
    "    \n",
    "    ncols_leg = len(np.unique(all_dicts[legend_cols[0]][\"colors\"])) if len(legend_cols) == 1 else 1\n",
    "    \n",
    "    if ncols == 2:\n",
    "        loc_x = -0.75\n",
    "    elif ncols == 3:\n",
    "        loc_x = -0.6 if len(legend_cols) == 1 else 0.16\n",
    "    elif ncols == 1:\n",
    "        loc_x = -0.25\n",
    "        \n",
    "    legend_loc = [loc_x, 1.65]\n",
    "    \n",
    "    if not any(any(all_dicts[k][\"number_bools\"]) for k in all_dicts.keys()):\n",
    "        legend_loc[1] -= 0.4\n",
    "        \n",
    "    if not any(all_dicts[k][\"title\"] for k in all_dicts.keys()):\n",
    "        legend_loc[1] -= 0.15\n",
    "    \n",
    "    return legend_cols, legend_loc, ncols_leg\n",
    "            \n",
    "legend_row = 1\n",
    "# legend_row = len(map_list)\n",
    "\n",
    "legend_cols, legend_loc, ncols_leg = get_legend_params(ncols, all_dicts,number_bool)\n",
    "# legend_loc = \"upper right\"; ncols_leg=1\n",
    "# legend_cols = [1]\n",
    "\n",
    "legend_bool = True\n",
    "# legend_bool = False\n",
    "\n",
    "if legend_bool: # check there are actually any labels to be plotted\n",
    "    \n",
    "    any_legend_bool = False\n",
    "    for key in all_dicts:\n",
    "        any_legend_bool = any_legend_bool or any(all_dicts[key][\"labels\"])\n",
    "        \n",
    "    if not any_legend_bool:\n",
    "        legend_bool = False\n",
    "        print(\"No plot with label, setting legend_bool=False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_line_color = \"grey\"\n",
    "zero_line_alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 22\n",
    "ylabel_size = 24\n",
    "legend_fontsize = 15.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_x = 15\n",
    "\n",
    "figsize_y = 1.41*figsize_x # aspect ratio of A4\n",
    "\n",
    "figsize_x /= 2 if ncols == 1 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\",\"anisotropy\",\"correlation\",\"tilt_abs\"]; map_list_string = \"all\"\n",
    "# map_list = [\"anisotropy\",\"correlation\",\"tilt_abs\"]; map_list_string = \"anicorrtilt\"\n",
    "# map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\"]; map_list_string = \"velmeanstd\"\n",
    "# map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\",\"anisotropy\"]; map_list_string = \"meanstdani\"\n",
    "# map_list = [\"std_vx\",\"std_vy\",\"anisotropy\"]; map_list_string = \"stdani\"\n",
    "# map_list = [\"mean_vx\",\"mean_vy\"]; map_list_string = \"velmeans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_suffix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "fig,axs = plt.subplots(figsize=(figsize_x,figsize_y),nrows=len(map_list)+1,ncols=ncols, facecolor='w',\\\n",
    "                       gridspec_kw={'hspace':0,'wspace':0,'height_ratios':[0.35]+len(map_list)*[1]})\n",
    "\n",
    "if number_bool: # number and title\n",
    "    bar_n_min,bar_n_max = [10**30],[0]\n",
    "\n",
    "    for col in all_dicts:\n",
    "        dic = all_dicts[col]\n",
    "\n",
    "        axs[0,col].set_title(dic[\"title\"])\n",
    "\n",
    "        for i in range(len(dic[\"load_paths\"])):\n",
    "            if dic[\"number_bools\"][i]:\n",
    "                map_dict,min_range,max_range,plot_range = load_values_and_plot_ranges(dic[\"load_paths\"][i],full_map_string_list)\n",
    "                \n",
    "                if dic[\"plot_ranges_str\"][i] == \"mean\":\n",
    "                    plot_range = PH.get_range_means(min_range,max_range)\n",
    "\n",
    "                POPPLOT_number_bar(axs[0,col], plot_range, map_dict[\"number\"],color=dic[\"colors\"][i],alpha=dic[\"number_alphas\"][i],\\\n",
    "                                   zorder=dic[\"zorderNs\"][i], bar_width=dic[\"bar_width\"])\n",
    "\n",
    "                bar_n_min = min(bar_n_min, np.min(map_dict[\"number\"]))\n",
    "                bar_n_max = max(bar_n_max, np.max(map_dict[\"number\"]))\n",
    "    \n",
    "    for col in all_dicts:\n",
    "        POPPLOT_number_bar_axis_settings(axs[0,col],min_n=bar_n_min,max_n=bar_n_max,bar_log=bar_log,labels_on=col==ncols-1)        \n",
    "else:\n",
    "    for col in all_dicts:\n",
    "        fig.delaxes(axs[0,col])\n",
    "        \n",
    "        axs[1,col].set_title(all_dicts[col])\n",
    "\n",
    "for row,map_string in enumerate(map_list): # plot\n",
    "    error_string = map_string+\"_error\"\n",
    "    \n",
    "    ymin,ymax = [float(\"inf\")],[float(\"-inf\")]\n",
    "    \n",
    "    for col in all_dicts:\n",
    "        \n",
    "        POPPLOT_yaxis_settings(axs[row+1,col],map_string,error_string,set_ylims=False,labels_on=col==0)\n",
    "        axs[row+1,col].axhline(y=0,linestyle='--',color=zero_line_color,alpha=zero_line_alpha,zorder=0)\n",
    "        \n",
    "        dic = all_dicts[col]\n",
    "        for i in range(len(dic[\"load_paths\"])):\n",
    "            \n",
    "            map_dict,min_range,max_range,plot_range = load_values_and_plot_ranges(dic[\"load_paths\"][i],full_map_string_list)\n",
    "            plot_range = plot_range if dic[\"plot_ranges_str\"][i]==\"median\" else PH.get_range_means(min_range,max_range)\n",
    "            label = dic[\"labels\"][i] if row == legend_row-1 else None\n",
    "            \n",
    "            if dic[\"surface_bools\"][i]:\n",
    "                POPPLOT_values_surface(axs[row+1,col],map_dict[map_string],map_dict[error_string],plot_range,color=dic[\"colors\"][i],label=label,\\\n",
    "                                       line_alpha=dic[\"line_alphas\"][i],surface_alpha=dic[\"surface_alphas\"][i],zorder=dic[\"zorders\"][i])\n",
    "            else:\n",
    "                POPPLOT_values_scatter(axs[row+1,col],map_dict[map_string],map_dict[error_string],plot_range,min_range,max_range,color=dic[\"colors\"][i],label=label,\\\n",
    "                                       line_alpha=dic[\"line_alphas\"][i],zorder=dic[\"zorders\"][i],lines_bool=scatter_join_bool)\n",
    "            \n",
    "            ymin = min(ymin, np.nanmin(map_dict[map_string]-map_dict[error_string]))\n",
    "            ymax = max(ymax, np.nanmax(map_dict[map_string]+map_dict[error_string]))\n",
    "    \n",
    "    if map_string in yshift_dict:\n",
    "        ymin -= yshift_dict[map_string]\n",
    "        ymax += yshift_dict[map_string]\n",
    "    \n",
    "    if hard_coded_ylims_bool and map_string in hard_coded_ylims:\n",
    "        ymin,ymax = hard_coded_ylims[map_string]\n",
    "    \n",
    "    for col in all_dicts:\n",
    "        axs[row+1,col].set_ylim(ymin,ymax)\n",
    "\n",
    "if legend_bool: # legend\n",
    "    for col in all_dicts:\n",
    "        if col in legend_cols:\n",
    "            axs[legend_row,col].legend(loc=legend_loc,fontsize=legend_fontsize,ncols=ncols_leg)#,loc=\"lower left\")\n",
    "    \n",
    "if True: # x-axis\n",
    "        \n",
    "    for col in all_dicts:\n",
    "        \n",
    "        dic = all_dicts[col]\n",
    "    \n",
    "        for row in range(len(map_list)+1): # include number bars\n",
    "\n",
    "            POPPLOT_xaxis_settings(axs[row,col],xmin=dic[\"x_lims\"][0],xmax=dic[\"x_lims\"][1],xlabel=dic[\"xaxis_label\"],xticks=dic[\"x_ticks\"],labels_on=row==len(map_list))\n",
    "\n",
    "            if dic[\"invert_xaxis\"]:\n",
    "                axs[row,col].invert_xaxis()\n",
    "    \n",
    "    fig.align_labels()\n",
    "    \n",
    "if True: # save\n",
    "    \n",
    "    filename = \"kinpop_\" + map_list_string\n",
    "    \n",
    "    filename += \"_noN\" if not number_bool else \"\"\n",
    "    \n",
    "    filename += \"_noNvar\" if number_bool and not number_variations_bool else \"\"\n",
    "    \n",
    "    filename += \"_noLeg\" if not legend_bool else \"\"\n",
    "    \n",
    "    if not scatter_join_bool:\n",
    "        filename += \"_noLines\"\n",
    "    \n",
    "    filename += filename_suffix\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        print(\"Saving in\",save_path)\n",
    "        for formatting in ['.png','.pdf']:\n",
    "            plt.savefig(save_path+filename+formatting, bbox_inches='tight', dpi=300)\n",
    "            print(\"Saved\",formatting)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Older plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "color_dict = {\n",
    "    \"vertex_abs\" : [\"blue\", \"red\"],\n",
    "    \"vertex\" : [\"orangered\", \"deepskyblue\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_string = \"tilt_abs\"\n",
    "# map_string = \"correlation\"\n",
    "# map_string = \"anisotropy\"\n",
    "# map_string = 'mean_vx'\n",
    "\n",
    "error_string = map_string+\"_error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# legend_bool = True\n",
    "legend_bool = True if map_string == \"anisotropy\" else False\n",
    "# legend_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "map_symbol = symbol_dict[map_string]\n",
    "# map_title = title_dict[map_string]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "ax_histx = divider.append_axes(\"top\", size=1.2, pad=0, sharex=ax)\n",
    "\n",
    "if sim_bool:\n",
    "    sim_map_array = map_dict[map_string]\n",
    "    sim_error_array = map_dict[map_string+\"_error\"]\n",
    "    \n",
    "    if number_bool:\n",
    "        LATPLOT_number_bars_sim(map_dict[\"number\"], sim_b_range_plot,alpha=0.5)\n",
    "    \n",
    "    LATPLOT_values_sim(sim_map_array, sim_error_array, sim_b_range_plot,alpha=0.4,legend=True)\n",
    "\n",
    "if data_bool:\n",
    "    o_map_array = o_map_dict[map_string]\n",
    "    o_error_array = o_map_dict[error_string]\n",
    "        \n",
    "    if number_bool:\n",
    "        LATPLOT_number_bars_data(o_map_dict[\"number\"], o_b_range_plot)\n",
    "    \n",
    "    LATPLOT_values_data(o_map_array, o_error_array, o_b_range_min, o_b_range_max, o_b_range_plot,legend=True)\n",
    "\n",
    "ax.plot([bmin,bmax],[0,0],color='black',linestyle='dotted')\n",
    "\n",
    "LATPLOT_number_bars_axis_settings()\n",
    "LATPLOT_xaxis_settings()\n",
    "LATPLOT_yaxis_settings(map_string)\n",
    "\n",
    "if True: # save\n",
    "    \n",
    "    legend_string = '' if legend_bool else '_noLeg'\n",
    "    \n",
    "    filename = map_string + legend_string\n",
    "    print(save_path+filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        for formatting in ['.png','.pdf']:\n",
    "            plt.savefig(save_path+filename+formatting, bbox_inches='tight', dpi=300)\n",
    "            print(\"Saved\",formatting)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_list = [\"anisotropy\",\"correlation\",\"tilt_abs\"]; map_list_string = \"anicorrtilt\"\n",
    "# error_list = [m+\"_error\" for m in map_list]\n",
    "\n",
    "# map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\"]; map_list_string = \"velmeanstd\"\n",
    "# error_list = [\"std_vx\",\"std_vy\",\"zero\",\"zero\"]; map_list_string += \"err\"\n",
    "# error_list = [\"zero\",\"zero\",\"zero\",\"zero\"]\n",
    "\n",
    "# map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\",\"anisotropy\"]; map_list_string = \"velmeanstdani\"\n",
    "# error_list = [\"zero\",\"zero\",\"zero\",\"zero\",\"anisotropy_error\"]\n",
    "\n",
    "map_list = [\"std_vx\",\"std_vy\",\"anisotropy\"]; map_list_string = \"stdani\"\n",
    "error_list = [\"zero\",\"zero\",\"anisotropy_error\"]\n",
    "\n",
    "# map_list = [\"mean_vx\",\"mean_vy\"]; map_list_string = \"meanvel\"\n",
    "# error_list = [\"std_vx\",\"std_vy\"]; map_list_string += \"err\"\n",
    "# error_list = [\"zero\",\"zero\"]\n",
    "\n",
    "# map_list = [\"mean_vx\",\"mean_vy\",\"anisotropy\"]; map_list_string = \"meanvelerrani\"\n",
    "# error_list = [\"std_vx\",\"std_vy\",\"anisotropy_error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# legend_row = 0\n",
    "legend_row = len(map_list)-1\n",
    "# legend_row = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "nrows = len(map_list)+1\n",
    "\n",
    "x_figsize = 10\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(x_figsize,len(map_list)*x_figsize),ncols=1,nrows=nrows,sharex=True,gridspec_kw={\"height_ratios\":[0.2]+[1]*(nrows-1),\"hspace\":0})\n",
    "\n",
    "ax_histx = axs[0]\n",
    "\n",
    "if number_bool:\n",
    "    if sim_bool:\n",
    "        LATPLOT_number_bars_sim(map_dict[\"number\"], sim_b_range_plot,alpha=0.5)\n",
    "    if data_bool:\n",
    "        LATPLOT_number_bars_data(o_map_dict[\"number\"], o_b_range_plot)\n",
    "        \n",
    "    LATPLOT_number_bars_axis_settings()\n",
    "\n",
    "for row in range(nrows - 1):\n",
    "    ax = axs[row+1]\n",
    "    map_string = map_list[row]\n",
    "    error_string = error_list[row]\n",
    "    \n",
    "    legend_bool = row == legend_row\n",
    "    \n",
    "    map_symbol = symbol_dict[map_string]\n",
    "    # map_title = title_dict[map_string]\n",
    "\n",
    "    if sim_bool:\n",
    "        sim_map_array = map_dict[map_string]\n",
    "        sim_error_array = map_dict[error_string]\n",
    "\n",
    "        LATPLOT_values_sim(sim_map_array, sim_error_array, sim_b_range_plot,alpha=0.4,legend=True)\n",
    "\n",
    "    if data_bool:\n",
    "        o_map_array = o_map_dict[map_string]\n",
    "        o_error_array = o_map_dict[error_string]\n",
    "\n",
    "        LATPLOT_values_data(o_map_array, o_error_array, o_b_range_min, o_b_range_max, o_b_range_plot,legend=True)\n",
    "    \n",
    "    if True: # zero line\n",
    "        minima = [np.nanmin(sim_map_array-sim_error_array),np.nanmin(o_map_array-o_error_array)]\n",
    "        maxima = [np.nanmax(sim_map_array+sim_error_array),np.nanmax(o_map_array+o_error_array)]\n",
    "        if PH.shall_plot_zero_line(minima,maxima):\n",
    "            ax.plot([bmin,bmax],[0,0],color='black',linestyle='dotted')\n",
    "    \n",
    "    LATPLOT_yaxis_settings(map_string)\n",
    "    LATPLOT_legend_and_text(legend_bool, extra_string_bool)\n",
    "\n",
    "LATPLOT_xaxis_settings()\n",
    "\n",
    "if True: # save\n",
    "    \n",
    "    xerr_string = f\"_xerr{xerr_frac}\" if x_error_data_bool else \"\"\n",
    "    \n",
    "    filename = filename_prefix + xerr_string\n",
    "    print(save_path+filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        for formatting in ['.png','.pdf']:\n",
    "            plt.savefig(save_path+filename+formatting, bbox_inches='tight', dpi=300)\n",
    "            print(\"Saved\",formatting)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shadowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to use this is:\n",
    "* Run all the code above for the variations you want, in order to save the arrays\n",
    "* Before producing the plot with shadows, run all the code above for the variation you'd like to show as main plot (i.e. the brightest ones)\n",
    "* The code below will load the shadows and create the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "current_var = \"R\"\n",
    "variation_var = \"R\"\n",
    "\n",
    "variations_dict = {\n",
    "    \"Nbins\": [[4,6],[5,7]], # [:,0] and [:,1] correspond to data and sim respectively\n",
    "    \"l\": [[-2,2],[-1.5,1.5],[-2.5,2.5]],\n",
    "    \"R\": [[0,3.5],[0,2]],\n",
    "    \"d\": [[6.1,10.1]]\n",
    "}\n",
    "\n",
    "def get_variable_path_str(variable,var_tuple):\n",
    "    if variable == \"Nbins\":\n",
    "        return f\"{var_tuple[0]}_points_data/{var_tuple[1]}_points_sim/\"\n",
    "    elif variable == \"R\" or variable == \"d\":\n",
    "        return f\"extra_{variable}/{var_tuple[0]}{variable}{var_tuple[1]}/\"\n",
    "\n",
    "def get_variation_results(variable, var_tuple, path, array_prefix=\"\",range_prefix=\"pop_\", deconstructed=True, verbose=False):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    variable: string\n",
    "        variable to use\n",
    "    var_tuple: tuple \n",
    "        values of variation\n",
    "    path: string\n",
    "    deconstructed: boolean\n",
    "        if True, `path` is a tuple with the deconstructed save path portions to be completed with the variation values\n",
    "        if False, `path` is the complete save path with the variation values already added in\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    map_dict: dict \n",
    "        Contains a 1D array entry per kinematic variable in `full_map_string_list`\n",
    "    range_min: 1D array\n",
    "    range_max: 1D array\n",
    "    range_plot: 1D array\n",
    "    \"\"\"\n",
    "    \n",
    "    if deconstructed:\n",
    "        var_string = get_variable_path_str(variable,var_tuple)\n",
    "\n",
    "        variation_path = path[0] + var_string + path[1]\n",
    "    else:\n",
    "        variation_path = path\n",
    "    \n",
    "    variation_arrays_path = variation_path + \"arrays/\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Loading from\\n\",variation_arrays_path)\n",
    "    \n",
    "    map_dict = {}\n",
    "    \n",
    "    for m in full_map_string_list:\n",
    "        map_dict[m] = np.load(f\"{variation_arrays_path}{array_prefix}{m}.npy\")\n",
    "    \n",
    "    min_range = np.load(variation_arrays_path + f\"{range_prefix}range_min.npy\")\n",
    "    max_range = np.load(variation_arrays_path + f\"{range_prefix}range_max.npy\")\n",
    "    plot_range = np.load(variation_arrays_path + f\"{range_prefix}range_plot.npy\")\n",
    "    \n",
    "    return map_dict, min_range, max_range, plot_range\n",
    "\n",
    "current_string_tuples_dict = {\n",
    "    \"Npoints\": [n_points_data,n_points_sim],\n",
    "    \"l\": [lmin,lmax],\n",
    "    extra_variable: [extra_min,extra_max]\n",
    "}\n",
    "\n",
    "current_tuple = current_string_tuples_dict[current_var]\n",
    "\n",
    "current_string = get_variable_path_str(current_var,current_tuple)\n",
    "\n",
    "def get_save_path_variation():\n",
    "    \n",
    "    variation_string_dict = {\n",
    "        \"Npoints\": \"Nbins_variation\",\n",
    "        \"l\": \"l_variation\",\n",
    "        \"R\": \"R_variation\",\n",
    "        \"d\": \"d_variation\"\n",
    "    }\n",
    "    \n",
    "    save_path_variation = get_save_path() + variation_string_dict[variation_var] + \"/\"\n",
    "    MF.create_dir(save_path_variation)\n",
    "    \n",
    "    return save_path_variation\n",
    "\n",
    "save_path_variation = get_save_path_variation()\n",
    "print(\"Saving in:\",save_path_variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_save_path = get_save_path()\n",
    "deconstructed_path = current_save_path.split(current_string)\n",
    "\n",
    "variations_list = variations_dict[variation_var]\n",
    "\n",
    "if current_var == variation_var and current_tuple in variations_list:\n",
    "    variations_list.remove(current_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variations\n",
    "\n",
    "variations_list = variations_dict[variation_var]\n",
    "\n",
    "sim_dict_of_map_dicts,sim_b_range_min_dict,sim_b_range_max_dict,sim_b_range_plot_dict = {},{},{},{}\n",
    "o_dict_of_map_dicts,o_b_range_min_dict,o_b_range_max_dict,o_b_range_plot_dict = {},{},{},{}\n",
    "\n",
    "for var_tuple in variations_list:\n",
    "    \n",
    "    var_key = f\"{var_tuple[0]},{var_tuple[1]}\"\n",
    "    print(var_key)\n",
    "    \n",
    "    map_sim,min_sim,max_sim,plot_sim = get_variation_results(variation_var,var_tuple,deconstructed_path,array_prefix=\"sim_\",range_prefix=\"sim_b_\",verbose=True)\n",
    "    map_data,min_data,max_data,plot_data = get_variation_results(variation_var,var_tuple,deconstructed_path,array_prefix=\"o_\",range_prefix=\"o_b_\",verbose=False)\n",
    "    \n",
    "    sim_dict_of_map_dicts[var_key] = map_sim\n",
    "    o_dict_of_map_dicts[var_key] = map_data\n",
    "    \n",
    "    for d,v in zip([sim_b_range_min_dict,sim_b_range_max_dict,sim_b_range_plot_dict],[min_sim,max_sim,plot_sim]):\n",
    "        d[var_key] = v\n",
    "    \n",
    "    for d,v in zip([o_b_range_min_dict,o_b_range_max_dict,o_b_range_plot_dict],[min_data,max_data,plot_data]):\n",
    "        d[var_key] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variation in variations_list:\n",
    "    variation_key = f\"{variation[0]},{variation[1]}\"\n",
    "        \n",
    "    PH.add_zero_array_key(sim_dict_of_map_dicts[variation_key])\n",
    "    PH.add_zero_array_key(o_dict_of_map_dicts[variation_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_new_colors(plot_idx=0, totalN = 256):\n",
    "    mid_idx = totalN//2\n",
    "    \n",
    "    frac = (1/3)**(plot_idx)\n",
    "    \n",
    "    young_idx = int(mid_idx * (1-frac))\n",
    "    old_idx = totalN - young_idx\n",
    "    \n",
    "    global color_y, color_o\n",
    "    color_y,color_o = coolwarm(young_idx),coolwarm(old_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_variations_bool = True\n",
    "# number_variations_bool = False\n",
    "\n",
    "current_first = True\n",
    "# current_first = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_alpha = 0.75\n",
    "alpha_reduction_factor = 1\n",
    "\n",
    "# variation_legend_bool = True # not currently implemented\n",
    "variation_legend_bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_list = [\"anisotropy\",\"correlation\",\"tilt_abs\"]; map_list_string = \"anicorrtilt\"\n",
    "error_list = [m+\"_error\" for m in map_list]\n",
    "\n",
    "# map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\"]; map_list_string = \"velmeanstd\"\n",
    "# error_list = [\"zero\",\"zero\",\"zero\",\"zero\"]\n",
    "# error_list = [\"std_vx\",\"std_vy\",\"zero\",\"zero\"]; map_list_string += \"err\"\n",
    "\n",
    "# map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\",\"anisotropy\"]; map_list_string = \"velmeanstdani\"\n",
    "# error_list = [\"zero\",\"zero\",\"zero\",\"zero\",\"anisotropy_error\"]\n",
    "\n",
    "# map_list = [\"std_vx\",\"std_vy\",\"anisotropy\"]; map_list_string = \"stdani\"\n",
    "# error_list = [\"zero\",\"zero\",\"anisotropy_error\"]\n",
    "\n",
    "# map_list = [\"mean_vx\",\"mean_vy\"]; map_list_string = \"meanvel\"\n",
    "# error_list = [\"std_vx\",\"std_vy\"]; map_list_string += \"err\"\n",
    "# error_list = [\"zero\",\"zero\"]\n",
    "\n",
    "# map_list = [\"mean_vx\",\"mean_vy\",\"anisotropy\"]; map_list_string = \"meanvelerrani\"\n",
    "# error_list = [\"std_vx\",\"std_vy\",\"anisotropy_error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_row = 0\n",
    "# legend_row = len(map_list)-1\n",
    "# legend_row = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "x_figsize = 10\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(x_figsize,len(map_list)*x_figsize),ncols=1,nrows=len(map_list)+1,sharex=True,gridspec_kw={\"height_ratios\":[0.2]+[1]*len(map_list),\"hspace\":0})\n",
    "\n",
    "ax_histx = axs[0]\n",
    "\n",
    "if number_bool:\n",
    "    alpha = main_alpha\n",
    "    plot_idx = 0\n",
    "    set_new_colors(plot_idx)\n",
    "    \n",
    "    if sim_bool:\n",
    "        LATPLOT_number_bars_sim(map_dict[\"number\"], sim_b_range_plot,alpha=alpha,zorder=10 if current_first else None)\n",
    "    if data_bool:\n",
    "        LATPLOT_number_bars_data(o_map_dict[\"number\"], o_b_range_plot,alpha=alpha,zorder=10 if current_first else None)\n",
    "        \n",
    "    if number_variations_bool:\n",
    "        \n",
    "        for k in sim_dict_of_map_dicts: # assumes the same variation are applied to model and data\n",
    "            alpha *= alpha_reduction_factor\n",
    "            plot_idx += 1\n",
    "            set_new_colors(plot_idx)\n",
    "\n",
    "            if sim_bool:\n",
    "                variation_sim_map_dict = sim_dict_of_map_dicts[k]\n",
    "                variation_sim_b_range_plot = sim_b_range_plot_dict[k]\n",
    "                \n",
    "                LATPLOT_number_bars_sim(variation_sim_map_dict[\"number\"],variation_sim_b_range_plot)#,alpha=alpha)\n",
    "                \n",
    "            if data_bool:\n",
    "                variation_o_map_dict = o_dict_of_map_dicts[k]\n",
    "                variation_o_b_range_plot = o_b_range_plot_dict[k]\n",
    "                \n",
    "                LATPLOT_number_bars_data(variation_o_map_dict[\"number\"],variation_o_b_range_plot)#,alpha=alpha)\n",
    "        \n",
    "    LATPLOT_number_bars_axis_settings()\n",
    "\n",
    "for row in range(len(map_list)):\n",
    "    ax = axs[row+1]\n",
    "    map_string = map_list[row]\n",
    "    error_string = error_list[row]\n",
    "    \n",
    "    alpha = main_alpha\n",
    "    plot_idx = 0\n",
    "    set_new_colors(plot_idx)\n",
    "    \n",
    "    legend_bool = row == legend_row\n",
    "    \n",
    "    map_symbol = symbol_dict[map_string]\n",
    "    # map_title = title_dict[map_string]\n",
    "\n",
    "    if sim_bool:\n",
    "        LATPLOT_values_sim(map_dict[map_string], map_dict[error_string], sim_b_range_plot,alpha=alpha,zorder=10 if current_first else None,legend=True)\n",
    "    if data_bool:\n",
    "        LATPLOT_values_data(o_map_dict[map_string], o_map_dict[error_string], o_b_range_min, o_b_range_max, o_b_range_plot,\\\n",
    "                            zorder=10 if current_first else None,legend=True)\n",
    "        \n",
    "    for k in sim_dict_of_map_dicts: # assumes the same variations are applied to model and data\n",
    "        alpha *= alpha_reduction_factor\n",
    "        plot_idx += 1\n",
    "        set_new_colors(plot_idx)\n",
    "\n",
    "        if sim_bool:\n",
    "            variation_sim_map_dict = sim_dict_of_map_dicts[k]\n",
    "\n",
    "            LATPLOT_values_sim(variation_sim_map_dict[map_string],variation_sim_map_dict[error_string],sim_b_range_plot_dict[k],alpha=alpha)\n",
    "\n",
    "        if data_bool:\n",
    "            variation_o_map_dict = o_dict_of_map_dicts[k]\n",
    "\n",
    "            LATPLOT_values_data(variation_o_map_dict[map_string],variation_o_map_dict[error_string],\\\n",
    "                                o_b_range_min_dict[k],o_b_range_max_dict[k],o_b_range_plot_dict[k])\n",
    "\n",
    "    if True: # zero line\n",
    "        minima = [np.nanmin(d[map_string]-d[error_string]) for d in [map_dict,o_map_dict,variation_sim_map_dict,variation_o_map_dict]]\n",
    "        maxima = [np.nanmax(d[map_string]+d[error_string]) for d in [map_dict,o_map_dict,variation_sim_map_dict,variation_o_map_dict]]\n",
    "        \n",
    "        if PH.shall_plot_zero_line(minima,maxima):\n",
    "            ax.plot([bmin,bmax],[0,0],color='black',linestyle='dotted')\n",
    "    \n",
    "    LATPLOT_yaxis_settings(map_string)\n",
    "    LATPLOT_legend_and_text(legend_bool = row == legend_row, extra_string_bool=extra_string_bool)\n",
    "\n",
    "LATPLOT_xaxis_settings()\n",
    "\n",
    "if True: # save\n",
    "    \n",
    "    variation_string = f\"_{variation_var}Var\"\n",
    "    for var_list in variations_list:\n",
    "        variation_string += f\"_{var_list[0]}-{var_list[1]}\"\n",
    "        \n",
    "    number_variation_string = \"_noNvar\" if not number_variations_bool else \"\"\n",
    "    legend_string = \"_noLeg\" if legend_row >= len(map_string) else \"\"\n",
    "    variation_legend_string = \"_varLegend\" if variation_legend_bool else \"\"\n",
    "    \n",
    "    filename = \"lat_\" + map_list_string + variation_string + number_variation_string + legend_string + variation_legend_string\n",
    "    print(save_path_variation+filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        for formatting in ['.png','.pdf']:\n",
    "            plt.savefig(save_path_variation+filename+formatting, bbox_inches='tight', dpi=300)\n",
    "            print(\"Saved\",formatting)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_bool = True\n",
    "save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "map_symbol = symbol_dict[map_string]\n",
    "# map_title = title_dict[map_string]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "ax_histx = divider.append_axes(\"top\", size=1.2, pad=0, sharex=ax)\n",
    "\n",
    "if sim_bool:\n",
    "    sim_map_array = map_dict[map_string]\n",
    "    sim_error_array = map_dict[map_string+\"_error\"]\n",
    "    \n",
    "    alpha = 0.75\n",
    "    plot_idx = 0\n",
    "    set_new_colors(plot_idx)\n",
    "    \n",
    "    if number_bool:\n",
    "        LATPLOT_number_bars_sim(map_dict[\"number\"], sim_b_range_plot, alpha=alpha, zorder=10 if current_first else None)\n",
    "    LATPLOT_values_sim(sim_map_array, sim_error_array, sim_b_range_plot, alpha=alpha, legend=True, zorder=10 if current_first else None)\n",
    "    \n",
    "    for k in sim_dict_of_map_dicts:\n",
    "        alpha *= alpha_reduction_factor\n",
    "        plot_idx += 1\n",
    "        set_new_colors(plot_idx)\n",
    "        \n",
    "        variation_sim_map_dict = sim_dict_of_map_dicts[k]\n",
    "        variation_sim_b_range_plot = sim_b_range_plot_dict[k]\n",
    "        \n",
    "        if number_variations_bool:\n",
    "            LATPLOT_number_bars_sim(variation_sim_map_dict[\"number\"],variation_sim_b_range_plot,alpha)\n",
    "        LATPLOT_values_sim(variation_sim_map_dict[map_string],variation_sim_map_dict[error_string],variation_sim_b_range_plot,alpha)\n",
    "\n",
    "if data_bool:\n",
    "    o_map_array = o_map_dict[map_string]\n",
    "    o_error_array = o_map_dict[error_string]\n",
    "    \n",
    "    alpha = 0.75\n",
    "    plot_idx = 0\n",
    "    set_new_colors(plot_idx)\n",
    "    \n",
    "    if number_bool:        \n",
    "        LATPLOT_number_bars_data(o_map_dict[\"number\"], o_b_range_plot,alpha=alpha,zorder=11 if current_first else None)\n",
    "    LATPLOT_values_data(o_map_array, o_error_array, o_b_range_min, o_b_range_max, o_b_range_plot,alpha=alpha,legend=True,zorder=11 if current_first else None)\n",
    "    \n",
    "    for k in o_dict_of_map_dicts:\n",
    "        alpha *= alpha_reduction_factor\n",
    "        plot_idx += 1\n",
    "        set_new_colors(plot_idx)\n",
    "        \n",
    "        variation_o_map_dict = o_dict_of_map_dicts[k]\n",
    "        variation_o_b_range_plot = o_b_range_plot_dict[k]\n",
    "        variation_o_b_range_min = o_b_range_min_dict[k]\n",
    "        variation_o_b_range_max = o_b_range_max_dict[k]\n",
    "                \n",
    "        if number_variations_bool:\n",
    "            LATPLOT_number_bars_data(variation_o_map_dict[\"number\"],variation_o_b_range_plot,alpha=alpha)\n",
    "        LATPLOT_values_data(variation_o_map_dict[map_string],variation_o_map_dict[error_string],variation_o_b_range_min,variation_o_b_range_max,variation_o_b_range_plot,alpha=alpha)\n",
    "\n",
    "ax.plot([bmin,bmax],[0,0],color='black',linestyle='dotted')\n",
    "\n",
    "LATPLOT_number_bars_axis_settings()\n",
    "LATPLOT_xaxis_settings()\n",
    "LATPLOT_yaxis_settings()\n",
    "\n",
    "if True: # save\n",
    "    \n",
    "    xerr_string = f\"_xerr{xerr_frac}\" if x_error_data_bool and xerr_frac!=2 else \"\"\n",
    "    \n",
    "    variation_string = f\"_{variation_var}Var\"\n",
    "    for var_list in variations_list:\n",
    "        variation_string += f\"_{var_list[0]}-{var_list[1]}\"\n",
    "        \n",
    "    number_variation_string = \"_nBarPlotVar\" if number_variations_bool else \"\"\n",
    "    \n",
    "    outlier_string = '_NoOutlier' if map_string == \"anisotropy\" and not outlier_bool else ''\n",
    "    legend_string = '' if legend_bool else '_noLeg'\n",
    "    \n",
    "    filename = map_string + variation_string + number_variation_string + xerr_string + outlier_string + legend_string\n",
    "    print(save_path_variation+filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        for formatting in ['.png','.pdf']:\n",
    "            plt.savefig(save_path_variation+filename+formatting, bbox_inches='tight', dpi=300)\n",
    "            print(\"Saved\",formatting)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Illustrate bulge cuts variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently only implemented for radius variation (and hard-coded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False\n",
    "\n",
    "if True: # illustrate bulge cut variation\n",
    "    \n",
    "    fig,axs=plt.subplots(figsize=(15,10),nrows=2,sharex=True,gridspec_kw={\"hspace\":-0.43})\n",
    "    \n",
    "    MP.visualise_bulge_selection(given_axs=axs,cuts={\"lmax\":lmax,\"bmax\":bmax,\"dmax\":10.1,\"R0\":R0},y_max_plot=3)\n",
    "\n",
    "#     MP.plot_circle(radius=2.5,ax=axs[0],linestyle=\"--\",label=r\"$R_\\mathrm{GC}\\leq2.5$ kpc\")\n",
    "#     axs[1].axvline(-2.5,color=\"k\",linestyle=\"--\")\n",
    "#     axs[1].axvline(2.5,color=\"k\",linestyle=\"--\")\n",
    "\n",
    "    axs[0].scatter(pd.concat(df_metals)[\"x\"],pd.concat(df_metals)[\"y\"],color=\"grey\",s=1)\n",
    "    axs[1].scatter(pd.concat(df_metals)[\"x\"],pd.concat(df_metals)[\"z\"],color=\"grey\",s=1)\n",
    "    \n",
    "    for m,M in zip(o_b_range_min,o_b_range_max):\n",
    "        MP.plot_angled_line(axs[1],xmin=-R0,ymin=0,xmax=4,angle=m,color=\"red\",linestyle=\"--\")\n",
    "        MP.plot_angled_line(axs[1],xmin=-R0,ymin=0,xmax=4,angle=M,color=\"blue\",linestyle=\"--\")\n",
    "\n",
    "    _ = [ax.legend(fontsize=\"x-small\") for ax in axs]\n",
    "    \n",
    "    fig.delaxes(axs[0])\n",
    "    \n",
    "    axs[1].set_xlim(-R0-0.1)\n",
    "\n",
    "    filename = \"illustrate_cuts_data\"\n",
    "    print(filename)\n",
    "    if save_bool:\n",
    "        print(\"Saving in:\",save_path)\n",
    "        plt.savefig(save_path+filename+\".png\",dpi=200,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# young_bool = True\n",
    "young_bool = False\n",
    "\n",
    "save_bool = True\n",
    "# save_bool = False\n",
    "\n",
    "if True: # illustrate bulge cut variation for the simulation\n",
    "    \n",
    "    fig,axs=plt.subplots(figsize=(15,10),nrows=2,sharex=True,gridspec_kw={\"hspace\":-0.43})\n",
    "    \n",
    "    if young_bool:\n",
    "        df = df0[(df0[\"age\"]>=young_min)&(df0[\"age\"]<=young_max)]\n",
    "    else:\n",
    "        df = df0[(df0[\"age\"]>=old_min)&(df0[\"age\"]<=old_max)]\n",
    "        \n",
    "    MP.quick_show_xy_xz(df=df,bmin=bmin,axs=axs)\n",
    "    \n",
    "    MP.visualise_bulge_selection(given_axs=axs,cuts={\"lmax\":lmax,\"bmax\":bmax,\"dmax\":10.1,\"R0\":R0},y_max_plot=3)\n",
    "\n",
    "#     MP.plot_circle(radius=2.5,ax=axs[0],linestyle=\"--\",label=r\"$R_\\mathrm{GC}\\leq2.5$ kpc\")\n",
    "#     axs[1].axvline(-2.5,color=\"k\",linestyle=\"--\")\n",
    "#     axs[1].axvline(2.5,color=\"k\",linestyle=\"--\")\n",
    "    \n",
    "    for m,M in zip(sim_b_range_min,sim_b_range_max):\n",
    "        MP.plot_angled_line(axs[1],xmin=-R0,ymin=0,xmax=4,angle=m,color=\"red\",linestyle=\"--\")\n",
    "        MP.plot_angled_line(axs[1],xmin=-R0,ymin=0,xmax=4,angle=M,color=\"blue\",linestyle=\"--\")\n",
    "\n",
    "    _ = [ax.legend(fontsize=\"x-small\") for ax in axs]\n",
    "    \n",
    "    fig.delaxes(axs[0])\n",
    "    \n",
    "    axs[1].set_xlim(-R0-0.1)\n",
    "    \n",
    "    filename = \"illustrate_cut_sim%s\"%(\"Young\" if young_bool else \"Old\")\n",
    "\n",
    "    print(filename)\n",
    "    if save_bool:\n",
    "        print(\"Saving in:\",save_path)\n",
    "        plt.savefig(save_path+filename+\".png\",dpi=200,bbox_inches=\"tight\")\n",
    "        \n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even older"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standard & abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict_comp = {\n",
    "    0 : [\"blue\", \"red\"],\n",
    "    1 : [\"deepskyblue\", \"gold\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transparency = 0.5\n",
    "alpha_area = 0.4\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "divider = make_axes_locatable(ax)\n",
    "ax_histx = divider.append_axes(\"top\", size=1.2, pad=0, sharex=ax)\n",
    "ax_histx.xaxis.set_tick_params(labelbottom=False)\n",
    "\n",
    "map_string=\"vertex\"\n",
    "error_string = \"vertex_error\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = map_dict[error_string]\n",
    "map_symbol = symbol_dict[\"vertex\"]\n",
    "yticks = get_variable_ticks(map_string, map_array)\n",
    "displacement = max(yticks) - min(yticks)\n",
    "label_y = r\"$5-9.8$ Gyr\"\n",
    "label_o = r\"$9.8-10$ Gyr\"\n",
    "color_y, color_o = color_dict_comp[0][0], color_dict_comp[0][1]\n",
    "\n",
    "bar_width=0.2\n",
    "ax_histx.bar(b_range_plot-bar_width/2, map_dict[\"number\"][:,0], width=bar_width,alpha=transparency,log=True,color=color_y)\n",
    "ax_histx.bar(b_range_plot+bar_width/2, map_dict[\"number\"][:,1], width=bar_width,alpha=transparency,log=True,color=color_o)\n",
    "ax_histx.yaxis.set_tick_params(labelleft=False,labelright=True)\n",
    "\n",
    "ax.plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "ax.plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "ax.fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "ax.fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "ax.fill_between(b_range_plot, map_array[:,0]-error_array[:,0]+displacement, map_array[:,0]+error_array[:,0]+displacement,alpha=alpha_area, facecolor=color_y)\n",
    "ax.fill_between(b_range_plot, map_array[:,1]-error_array[:,1]+displacement, map_array[:,1]+error_array[:,1]+displacement,alpha=alpha_area, facecolor=color_o)\n",
    "ax.fill_between(b_range_plot, map_array[:,0]-error_array[:,0]-displacement, map_array[:,0]+error_array[:,0]-displacement,alpha=alpha_area, facecolor=color_y)\n",
    "ax.fill_between(b_range_plot, map_array[:,1]-error_array[:,1]-displacement, map_array[:,1]+error_array[:,1]-displacement,alpha=alpha_area, facecolor=color_o)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_ylim(min(yticks),max(yticks))\n",
    "\n",
    "\n",
    "map_string = \"vertex_abs\"\n",
    "error_string = \"vertex_error_abs\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = map_dict[error_string]\n",
    "yticks = get_variable_ticks(map_string, map_array)\n",
    "displacement = max(yticks) - min(yticks)\n",
    "color_y, color_o = color_dict_comp[1][0], color_dict_comp[1][1]\n",
    "label_y = r\"$5-9.8$ Gyr abs\"\n",
    "label_o = r\"$9.8-10$ Gyr abs\"\n",
    "\n",
    "bar_width=0.2\n",
    "ax_histx.bar(b_range_plot-bar_width/2, map_dict[\"number\"][:,0], width=bar_width,alpha=transparency,log=True,color=color_y)\n",
    "ax_histx.bar(b_range_plot+bar_width/2, map_dict[\"number\"][:,1], width=bar_width,alpha=transparency,log=True,color=color_o)\n",
    "ax_histx.yaxis.set_tick_params(labelleft=False,labelright=True)\n",
    "\n",
    "ax.plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "ax.plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "ax.fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "ax.fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# sort both labels and handles by labels\n",
    "labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "ax.legend(handles, labels, loc=\"upper left\")\n",
    "\n",
    "ax_histx.set_yticks([100,1000,10000,100000])\n",
    "ax_histx.set_ylabel(r\"$N$\",labelpad=5)\n",
    "ax_histx.yaxis.set_label_position(\"right\")\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax.tick_params(which='minor',direction='in',color='black',length=4)#,width=1)\n",
    "ax.set_xlim(0,-10)\n",
    "ax.set_xticks(np.arange(0,-10-1,-1))\n",
    "\n",
    "ax.set_xlabel(r\"$b$ [°]\")\n",
    "ax.set_ylabel(map_symbol)\n",
    "\n",
    "ax.set_aspect('auto')\n",
    "plt.savefig(save_path+\"vertex_comparison.png\",bbox_inches='tight',dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transparency = 0.5\n",
    "alpha_area = 0.4\n",
    "error_factor = 100\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "divider = make_axes_locatable(ax)\n",
    "ax_histx = divider.append_axes(\"top\", size=1.2, pad=0, sharex=ax)\n",
    "ax_histx.xaxis.set_tick_params(labelbottom=False)\n",
    "\n",
    "map_string=\"mean_vr\"\n",
    "error_string = \"varr\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = np.sqrt(map_dict[error_string])/error_factor\n",
    "yticks = get_variable_ticks(map_string, map_array)\n",
    "label_y = r\"$\\langle v_r \\rangle$ $5-9.8$ Gyr\"\n",
    "label_o = r\"$\\langle v_r \\rangle$ $9.8-10$ Gyr\"\n",
    "color_y, color_o = color_dict_comp[0][0], color_dict_comp[0][1]\n",
    "\n",
    "bar_width=0.2\n",
    "ax_histx.bar(b_range_plot-bar_width/2, map_dict[\"number\"][:,0], width=bar_width,alpha=transparency,log=True,color=color_y)\n",
    "ax_histx.bar(b_range_plot+bar_width/2, map_dict[\"number\"][:,1], width=bar_width,alpha=transparency,log=True,color=color_o)\n",
    "ax_histx.yaxis.set_tick_params(labelleft=False,labelright=True)\n",
    "\n",
    "ax.plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "ax.plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "ax.fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "ax.fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "\n",
    "map_string = \"mean_vl\"\n",
    "error_string = \"varl\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = np.sqrt(map_dict[error_string])/error_factor\n",
    "color_y, color_o = color_dict_comp[1][0], color_dict_comp[1][1]\n",
    "label_y = r\"$\\langle v_l \\rangle$ $5-9.8$ Gyr\"\n",
    "label_o = r\"$\\langle v_l \\rangle$ $9.8-10$ Gyr\"\n",
    "\n",
    "ax_histx.bar(b_range_plot-bar_width/2, map_dict[\"number\"][:,0], width=bar_width,alpha=transparency,log=True,color=color_y)\n",
    "ax_histx.bar(b_range_plot+bar_width/2, map_dict[\"number\"][:,1], width=bar_width,alpha=transparency,log=True,color=color_o)\n",
    "ax_histx.yaxis.set_tick_params(labelleft=False,labelright=True)\n",
    "\n",
    "ax.plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "ax.plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "ax.fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "ax.fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "#handles, labels = ax.get_legend_handles_labels()\n",
    "## sort both labels and handles by labels\n",
    "#labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "#ax.legend(handles, labels, loc=\"upper left\")\n",
    "ax.legend(loc='lower right',ncol=2,fontsize=16)\n",
    "\n",
    "ax_histx.set_yticks([100,1000,10000,100000])\n",
    "ax_histx.set_ylabel(r\"$N$\",labelpad=5)\n",
    "ax_histx.yaxis.set_label_position(\"right\")\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax.tick_params(which='minor',direction='in',color='black',length=4)#,width=1)\n",
    "ax.set_xlim(0,-10)\n",
    "ax.set_xticks(np.arange(0,-10-1,-1))\n",
    "\n",
    "ylim = 26\n",
    "yticks = np.linspace(-ylim,ylim,5)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_ylim(min(yticks),max(yticks))\n",
    "\n",
    "ax.set_xlabel(r\"$b$ [°]\")\n",
    "ax.set_ylabel(\"Mean velocity\")\n",
    "\n",
    "ax.set_aspect('auto')\n",
    "\n",
    "if error_factor != 1:\n",
    "    ax.text(-0.5,yticks[1]*7/4,r\"Error $\\times 10^{-%i}$\" % get_exponent(error_factor))\n",
    "\n",
    "error_factor_string = '_error'+str(error_factor) if error_factor != 1 else ''\n",
    "plt.savefig(save_path+f\"mean_velocities{error_factor_string}.png\",bbox_inches='tight',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### corr & anis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_b_range_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict_comp = {\n",
    "    0 : [\"blue\", \"red\"],\n",
    "    1 : [\"deepskyblue\", \"gold\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transparency = 0.5\n",
    "alpha_area = 0.4\n",
    "error_factor = 10\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "divider = make_axes_locatable(ax)\n",
    "ax_histx = divider.append_axes(\"top\", size=1.2, pad=0, sharex=ax)\n",
    "ax_histx.xaxis.set_tick_params(labelbottom=False)\n",
    "\n",
    "map_string=\"anisotropy\"\n",
    "error_string = \"anisotropy_error\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = np.sqrt(map_dict[error_string])/error_factor\n",
    "yticks = get_variable_ticks(map_string, map_array)\n",
    "label_y = r\"$1-\\sigma_{l}/\\sigma_r$ ($5-9.8$ Gyr)\"\n",
    "label_o = r\"$1-\\sigma_{l}/\\sigma_r$ ($9.8-10$ Gyr)\"\n",
    "color_y, color_o = color_dict_comp[0][0], color_dict_comp[0][1]\n",
    "\n",
    "bar_width=0.2\n",
    "ax_histx.bar(b_range_plot-bar_width/2, map_dict[\"number\"][:,0], width=bar_width,alpha=transparency,log=True,color=color_y)\n",
    "ax_histx.bar(b_range_plot+bar_width/2, map_dict[\"number\"][:,1], width=bar_width,alpha=transparency,log=True,color=color_o)\n",
    "ax_histx.yaxis.set_tick_params(labelleft=False,labelright=True)\n",
    "\n",
    "ax.plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "ax.plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "ax.fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "ax.fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "#OBSERVATIONS-----------------------------------------------------------------------------------------------\n",
    "o_map_array = o_map_dict[map_string]\n",
    "o_error_array = o_map_dict[error_string]\n",
    "\n",
    "#ax.errorbar(o_b_range_plot, o_map_array[:,0], yerr= o_error_array[:,0], color=color_y, fmt='o')\n",
    "#ax.errorbar(o_b_range_plot, o_map_array[:,1] , yerr= o_error_array[:,1], color=color_o, fmt='o')\n",
    "ax.scatter(o_b_range_plot, o_map_array[:,0], color=color_y)\n",
    "ax.scatter(o_b_range_plot, o_map_array[:,1] , color=color_o)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "map_string = \"correlation\"\n",
    "error_string = \"correlation_error\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = np.sqrt(map_dict[error_string])/error_factor\n",
    "color_y, color_o = color_dict_comp[1][0], color_dict_comp[1][1]\n",
    "label_y = r\"$\\rho_{rl}$ ($5-9.8$ Gyr)\"\n",
    "label_o = r\"$\\rho_{rl}$ ($9.8-10$ Gyr)\"\n",
    "\n",
    "ax_histx.bar(b_range_plot-bar_width/2, map_dict[\"number\"][:,0], width=bar_width,alpha=transparency,log=True,color=color_y)\n",
    "ax_histx.bar(b_range_plot+bar_width/2, map_dict[\"number\"][:,1], width=bar_width,alpha=transparency,log=True,color=color_o)\n",
    "ax_histx.yaxis.set_tick_params(labelleft=False,labelright=True)\n",
    "\n",
    "ax.plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "ax.plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "ax.fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "ax.fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "#OBSERVATIONS-----------------------------------------------------------------------------------------------\n",
    "o_map_array = o_map_dict[map_string]\n",
    "o_error_array = o_map_dict[error_string]\n",
    "\n",
    "ax.errorbar(o_b_range_plot, o_map_array[:,0], yerr= o_error_array[:,0], color=color_y, fmt='o')\n",
    "ax.errorbar(o_b_range_plot, o_map_array[:,1] , yerr= o_error_array[:,1], color=color_o, fmt='o')\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#handles, labels = ax.get_legend_handles_labels()\n",
    "## sort both labels and handles by labels\n",
    "#labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "#ax.legend(handles, labels, loc=\"upper left\")\n",
    "ax.legend(loc='best')\n",
    "\n",
    "ax_histx.set_yticks([100,1000,10000,100000])\n",
    "ax_histx.set_ylabel(r\"$N$\",labelpad=15,rotation=0)\n",
    "ax_histx.yaxis.set_label_position(\"right\")\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax.tick_params(which='minor',direction='in',color='black',length=4)#,width=1)\n",
    "ax.set_xlim(0,-10)\n",
    "ax.set_xticks(np.arange(0,-10-1,-1))\n",
    "\n",
    "ax.set_ylim(-1,1)\n",
    "\n",
    "ax.set_xlabel(r\"$b$ [°]\")\n",
    "ax.set_ylabel(\"Anisotropy & correlation\")\n",
    "#ax.set_yticks(np.array(yticks))\n",
    "#ax.set_ylim(min(yticks),max(yticks))\n",
    "\n",
    "ax.set_aspect('auto')\n",
    "\n",
    "x_error = -0.5\n",
    "if error_factor != 1:\n",
    "    ax.text(x_error,-0.85,r\"Error $\\times 10^{-%i}$\" % get_exponent(error_factor), size=15)#error_fontsize)\n",
    "\n",
    "error_factor_string = '_error'+str(error_factor) if error_factor != 1 else ''\n",
    "plt.savefig(save_path+f\"corr_anis{error_factor_string}.png\",bbox_inches='tight',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### vertex,anicorr,vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transparency = 0.5\n",
    "alpha_area = 0.4\n",
    "legend_fontsize = 15\n",
    "legend_ncol = 2\n",
    "error_fontsize=15\n",
    "\n",
    "fig, axs = plt.subplots(4,1,sharex=True,figsize=(7,16),gridspec_kw={\"hspace\":0, \"height_ratios\":[0.3,1,1,1]})\n",
    "\n",
    "for ax in axs:\n",
    "    if ax.is_last_row():\n",
    "        ax.set_xlabel(r\"$b$ [°]\")\n",
    "    else:\n",
    "        ax.xaxis.set_tick_params(labelbottom=False)\n",
    "    ax.set_aspect('auto')\n",
    "    \n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "    ax.tick_params(which='minor',direction='in',color='black',length=4)#,width=1)\n",
    "    ax.set_xlim(0,-10)\n",
    "    ax.set_xticks(np.arange(0,-10-1,-1))\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "error_factor_vert = 1\n",
    "\n",
    "map_string=\"vertex\"\n",
    "error_string = \"vertex_error\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = map_dict[error_string]/error_factor_vert\n",
    "yticks = get_variable_ticks(map_string, map_array)\n",
    "displacement = max(yticks) - min(yticks)\n",
    "label_y = r\"$l_{\\mathrm{v}}$ (Y)\"\n",
    "label_o = r\"$l_{\\mathrm{v}}$ (O)\"\n",
    "color_y, color_o = color_dict_comp[0][0], color_dict_comp[0][1]\n",
    "\n",
    "axs[1].plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "axs[1].plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "axs[1].fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "axs[1].fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "axs[1].fill_between(b_range_plot, map_array[:,0]-error_array[:,0]+displacement, map_array[:,0]+error_array[:,0]+displacement,alpha=alpha_area, facecolor=color_y)\n",
    "axs[1].fill_between(b_range_plot, map_array[:,1]-error_array[:,1]+displacement, map_array[:,1]+error_array[:,1]+displacement,alpha=alpha_area, facecolor=color_o)\n",
    "axs[1].fill_between(b_range_plot, map_array[:,0]-error_array[:,0]-displacement, map_array[:,0]+error_array[:,0]-displacement,alpha=alpha_area, facecolor=color_y)\n",
    "axs[1].fill_between(b_range_plot, map_array[:,1]-error_array[:,1]-displacement, map_array[:,1]+error_array[:,1]-displacement,alpha=alpha_area, facecolor=color_o)\n",
    "axs[1].set_yticks(yticks)\n",
    "axs[1].set_ylim(min(yticks),max(yticks))\n",
    "\n",
    "map_string = \"vertex_abs\"\n",
    "error_string = \"vertex_error_abs\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = map_dict[error_string]/error_factor_vert\n",
    "color_y, color_o = color_dict_comp[1][0], color_dict_comp[1][1]\n",
    "label_y = r\"$l_{\\mathrm{v}}^{\\mathrm{abs}}$ (Y)\"\n",
    "label_o = r\"$l_{\\mathrm{v}}^{\\mathrm{abs}}$ (O)\"\n",
    "\n",
    "axs[1].plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "axs[1].plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "axs[1].fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "axs[1].fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "#handles, labels = axs[1].get_legend_handles_labels()\n",
    "## sort both labels and handles by labels\n",
    "#labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "#axs[1].legend(handles, labels, loc=\"upper center\", fontsize=legend_fontsize)\n",
    "axs[1].legend(loc=\"upper left\", fontsize=legend_fontsize,ncol=legend_ncol)\n",
    "\n",
    "if error_factor_vert != 1:\n",
    "    if error_factor_vert >= 10:\n",
    "        axs[1].text(-0.5,yticks[1]*7/4,r\"Error $\\times 10^{-%i}$\" % get_exponent(error_factor_vert), size=error_fontsize)\n",
    "    elif error_factor_vert == 2:\n",
    "        axs[1].text(-0.5,yticks[1]*7/4,r\"Error $\\times 0.5$\", size=error_fontsize)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown error factor in vertex\")\n",
    "        \n",
    "axs[1].set_ylabel(\"Vertex deviation\")\n",
    "    \n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "error_factor_anicorr = 10\n",
    "\n",
    "map_string=\"anisotropy\"\n",
    "error_string = \"anisotropy_error\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = np.sqrt(map_dict[error_string])/error_factor_anicorr\n",
    "yticks = get_variable_ticks(map_string, map_array)\n",
    "label_y = r\"$1-\\sigma_{l}^2/\\sigma_r^2$ (Y)\"\n",
    "label_o = r\"$1-\\sigma_{l}^2/\\sigma_r^2$ (O)\"\n",
    "color_y, color_o = color_dict_comp[0][0], color_dict_comp[0][1]\n",
    "\n",
    "axs[2].plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "axs[2].plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "axs[2].fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "axs[2].fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "map_string = \"correlation\"\n",
    "error_string = \"correlation_error\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = np.sqrt(map_dict[error_string])/error_factor_anicorr\n",
    "color_y, color_o = color_dict_comp[1][0], color_dict_comp[1][1]\n",
    "label_y = r\"$\\rho_{rl}$ (Y)\"\n",
    "label_o = r\"$\\rho_{rl}$ (O)\"\n",
    "\n",
    "axs[2].plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "axs[2].plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "axs[2].fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "axs[2].fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "axs[2].set_ylabel(\"Anisotropy & correlation\")\n",
    "\n",
    "#handles, labels = ax.get_legend_handles_labels()\n",
    "## sort both labels and handles by labels\n",
    "#labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "#ax.legend(handles, labels, loc=\"upper left\")\n",
    "axs[2].legend(loc='upper right', fontsize=legend_fontsize,ncol=legend_ncol)\n",
    "\n",
    "yticks = np.linspace(-0.4,0.4,5)\n",
    "axs[2].set_yticks(yticks[:-1])\n",
    "axs[2].set_ylim(min(yticks),max(yticks))\n",
    "\n",
    "axs[2].text(-0.5,yticks[1]*7/4,r\"Error $\\times 10^{-%i}$\" % get_exponent(error_factor_anicorr), size=error_fontsize)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "error_factor_vel = 100\n",
    "\n",
    "map_string=\"mean_vr\"\n",
    "error_string = \"varr\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = np.sqrt(map_dict[error_string])/error_factor_vel\n",
    "yticks = get_variable_ticks(map_string, map_array)\n",
    "label_y = r\"$\\langle v_r \\rangle$ (Y)\"\n",
    "label_o = r\"$\\langle v_r \\rangle$ (O)\"\n",
    "color_y, color_o = color_dict_comp[0][0], color_dict_comp[0][1]\n",
    "\n",
    "axs[3].plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "axs[3].plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "axs[3].fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "axs[3].fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "map_string = \"mean_vl\"\n",
    "error_string = \"varl\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = np.sqrt(map_dict[error_string])/error_factor_vel\n",
    "color_y, color_o = color_dict_comp[1][0], color_dict_comp[1][1]\n",
    "label_y = r\"$\\langle v_l \\rangle$ (Y)\"\n",
    "label_o = r\"$\\langle v_l \\rangle$ (O)\"\n",
    "\n",
    "axs[3].plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "axs[3].plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "axs[3].fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "axs[3].fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "axs[3].set_ylabel(\"Mean velocity\")\n",
    "\n",
    "#handles, labels = ax.get_legend_handles_labels()\n",
    "## sort both labels and handles by labels\n",
    "#labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "#ax.legend(handles, labels, loc=\"upper left\")\n",
    "axs[3].legend(loc='lower right', fontsize=legend_fontsize,ncol=legend_ncol)\n",
    "ylim = 26\n",
    "yticks = np.linspace(-ylim,ylim,5)\n",
    "axs[3].set_yticks(yticks[:-1])\n",
    "axs[3].set_ylim(min(yticks),max(yticks))\n",
    "\n",
    "axs[3].text(-0.5,yticks[1]*7/4,r\"Error $\\times 10^{-%i}$\" % get_exponent(error_factor_vel), size=error_fontsize)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "bar_width=0.2\n",
    "axs[0].bar(b_range_plot-bar_width/2, map_dict[\"number\"][:,0], width=bar_width,alpha=transparency,log=True,color=color_dict_comp[0][0])\n",
    "axs[0].bar(b_range_plot+bar_width/2, map_dict[\"number\"][:,1], width=bar_width,alpha=transparency,log=True,color=color_dict_comp[0][1])\n",
    "axs[0].bar(b_range_plot-bar_width/2, map_dict[\"number\"][:,0], width=bar_width,alpha=transparency,log=True,color=color_dict_comp[1][0])\n",
    "axs[0].bar(b_range_plot+bar_width/2, map_dict[\"number\"][:,1], width=bar_width,alpha=transparency,log=True,color=color_dict_comp[1][1])\n",
    "axs[0].yaxis.set_tick_params(labelleft=False,labelright=True)\n",
    "\n",
    "axs[0].set_yticks([100,1000,10000,100000])\n",
    "axs[0].set_ylabel(r\"$N$\",labelpad=13,rotation=0)\n",
    "axs[0].yaxis.set_label_position(\"right\")\n",
    "\n",
    "axs[0].text(-7.4,3500,\"Y: 5-9.8 Gyr\\nO: 9.8-10 Gyr\", size=error_fontsize)\n",
    "\n",
    "error_string_vert = \"_errorvert\"+str(error_factor_vert) if error_factor_vert != 1 else ''\n",
    "error_string_anicorr = '_erroranicorr'+str(error_factor_anicorr) if error_factor_anicorr != 1 else ''\n",
    "error_string_vel = '_errorvel'+str(error_factor_vel) if error_factor_vel != 1 else ''\n",
    "filename = \"group\"+error_string_vert+error_string_anicorr+error_string_vel+'.png'\n",
    "plt.savefig(save_path+filename,bbox_inches='tight',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### vertex,anicorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transparency = 0.5\n",
    "alpha_area = 0.4\n",
    "legend_fontsize = 15\n",
    "error_fontsize=15\n",
    "\n",
    "fig, axs = plt.subplots(3,1,sharex=True,figsize=(7,12),gridspec_kw={\"hspace\":0, \"height_ratios\":[0.3,1,1]})\n",
    "\n",
    "for ax in axs:\n",
    "    if ax.is_last_row():\n",
    "        ax.set_xlabel(r\"$b$ [°]\")\n",
    "    else:\n",
    "        ax.xaxis.set_tick_params(labelbottom=False)\n",
    "    ax.set_aspect('auto')\n",
    "    \n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "    ax.tick_params(which='minor',direction='in',color='black',length=4)#,width=1)\n",
    "    ax.set_xlim(0,-10)\n",
    "    ax.set_xticks(np.arange(0,-10-1,-1))\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "error_factor_vert = 1\n",
    "\n",
    "map_string=\"vertex\"\n",
    "error_string = \"vertex_error\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = map_dict[error_string]/error_factor_vert\n",
    "yticks = get_variable_ticks(map_string, map_array)\n",
    "displacement = max(yticks) - min(yticks)\n",
    "label_y = r\"$l_{\\mathrm{v}}$ (Y)\"\n",
    "label_o = r\"$l_{\\mathrm{v}}$ (O)\"\n",
    "color_y, color_o = color_dict_comp[0][0], color_dict_comp[0][1]\n",
    "\n",
    "axs[1].plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "axs[1].plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "axs[1].fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "axs[1].fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "axs[1].fill_between(b_range_plot, map_array[:,0]-error_array[:,0]+displacement, map_array[:,0]+error_array[:,0]+displacement,alpha=alpha_area, facecolor=color_y)\n",
    "axs[1].fill_between(b_range_plot, map_array[:,1]-error_array[:,1]+displacement, map_array[:,1]+error_array[:,1]+displacement,alpha=alpha_area, facecolor=color_o)\n",
    "axs[1].fill_between(b_range_plot, map_array[:,0]-error_array[:,0]-displacement, map_array[:,0]+error_array[:,0]-displacement,alpha=alpha_area, facecolor=color_y)\n",
    "axs[1].fill_between(b_range_plot, map_array[:,1]-error_array[:,1]-displacement, map_array[:,1]+error_array[:,1]-displacement,alpha=alpha_area, facecolor=color_o)\n",
    "axs[1].set_yticks(yticks)\n",
    "axs[1].set_ylim(min(yticks),max(yticks))\n",
    "\n",
    "map_string = \"vertex_abs\"\n",
    "error_string = \"vertex_error_abs\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = map_dict[error_string]/error_factor_vert\n",
    "color_y, color_o = color_dict_comp[1][0], color_dict_comp[1][1]\n",
    "label_y = r\"$l_{\\mathrm{v}}^{\\mathrm{abs}}$ (Y)\"\n",
    "label_o = r\"$l_{\\mathrm{v}}^{\\mathrm{abs}}$ (O)\"\n",
    "\n",
    "axs[1].plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "axs[1].plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "axs[1].fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "axs[1].fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "#handles, labels = axs[1].get_legend_handles_labels()\n",
    "## sort both labels and handles by labels\n",
    "#labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "#axs[1].legend(handles, labels, loc=\"upper center\", fontsize=legend_fontsize)\n",
    "axs[1].legend(loc=\"upper left\", fontsize=legend_fontsize, ncol=2)\n",
    "\n",
    "if error_factor_vert != 1:\n",
    "    if error_factor_vert >= 10:\n",
    "        axs[1].text(-0.5,yticks[1]*7/4,r\"Error $\\times 10^{-%i}$\" % get_exponent(error_factor_vert), size=error_fontsize)\n",
    "    elif error_factor_vert == 2:\n",
    "        axs[1].text(-0.5,yticks[1]*7/4,r\"Error $\\times 0.5$\", size=error_fontsize)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown error factor in vertex\")\n",
    "        \n",
    "axs[1].set_ylabel(\"Vertex deviation\")\n",
    "    \n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "error_factor_anicorr = 10\n",
    "\n",
    "map_string=\"anisotropy\"\n",
    "error_string = \"anisotropy_error\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = np.sqrt(map_dict[error_string])/error_factor_anicorr\n",
    "yticks = get_variable_ticks(map_string, map_array)\n",
    "label_y = r\"$1-\\sigma_{l}^2/\\sigma_r^2$ (Y)\"\n",
    "label_o = r\"$1-\\sigma_{l}^2/\\sigma_r^2$ (O)\"\n",
    "color_y, color_o = color_dict_comp[0][0], color_dict_comp[0][1]\n",
    "\n",
    "axs[2].plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "axs[2].plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "axs[2].fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "axs[2].fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "map_string = \"correlation\"\n",
    "error_string = \"correlation_error\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = np.sqrt(map_dict[error_string])/error_factor_anicorr\n",
    "color_y, color_o = color_dict_comp[1][0], color_dict_comp[1][1]\n",
    "label_y = r\"$\\rho_{rl}$ (Y)\"\n",
    "label_o = r\"$\\rho_{rl}$ (O)\"\n",
    "\n",
    "axs[2].plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "axs[2].plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "axs[2].fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "axs[2].fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "axs[2].set_ylabel(\"Anisotropy & correlation\")\n",
    "\n",
    "#handles, labels = ax.get_legend_handles_labels()\n",
    "## sort both labels and handles by labels\n",
    "#labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "#ax.legend(handles, labels, loc=\"upper left\")\n",
    "axs[2].legend(loc='lower right', fontsize=legend_fontsize, ncol=2)\n",
    "\n",
    "yticks = np.linspace(-0.4,0.4,5)\n",
    "axs[2].set_yticks(yticks[:-1])\n",
    "axs[2].set_ylim(min(yticks),max(yticks))\n",
    "\n",
    "if error_factor_anicorr != 1:\n",
    "    if error_factor_anicorr >= 10:\n",
    "        axs[2].text(-0.5,yticks[1]*7/4,r\"Error $\\times 10^{-%i}$\" % get_exponent(error_factor_anicorr), size=error_fontsize)\n",
    "    elif error_factor_anicorr == 2:\n",
    "        axs[2].text(-0.5,yticks[1]*7/4,r\"Error $\\times 0.5$\", size=error_fontsize)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown error factor in anicorr\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "bar_width=0.2\n",
    "axs[0].bar(b_range_plot-bar_width/2, map_dict[\"number\"][:,0], width=bar_width,alpha=transparency,log=True,color=color_dict_comp[0][0])\n",
    "axs[0].bar(b_range_plot+bar_width/2, map_dict[\"number\"][:,1], width=bar_width,alpha=transparency,log=True,color=color_dict_comp[0][1])\n",
    "axs[0].bar(b_range_plot-bar_width/2, map_dict[\"number\"][:,0], width=bar_width,alpha=transparency,log=True,color=color_dict_comp[1][0])\n",
    "axs[0].bar(b_range_plot+bar_width/2, map_dict[\"number\"][:,1], width=bar_width,alpha=transparency,log=True,color=color_dict_comp[1][1])\n",
    "axs[0].yaxis.set_tick_params(labelleft=False,labelright=True)\n",
    "\n",
    "axs[0].set_yticks([100,1000,10000,100000])\n",
    "axs[0].set_ylim(10,500000)\n",
    "axs[0].set_ylabel(r\"$N$\",labelpad=13, rotation=0)\n",
    "axs[0].yaxis.set_label_position(\"right\")\n",
    "\n",
    "axs[0].text(-7.4,3500,\"Y: 5-9.8 Gyr\\nO: 9.8-10 Gyr\", size=error_fontsize)\n",
    "\n",
    "error_string_vert = \"_errorvert\"+str(error_factor_vert) if error_factor_vert != 1 else ''\n",
    "error_string_anicorr = '_erroranicorr'+str(error_factor_anicorr) if error_factor_anicorr != 1 else ''\n",
    "filename = \"group\"+error_string_vert+error_string_anicorr+'.png'\n",
    "plt.savefig(save_path+filename,bbox_inches='tight',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### vertex,covdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transparency = 0.5\n",
    "alpha_area = 0.4\n",
    "legend_fontsize = 15\n",
    "error_fontsize=15\n",
    "\n",
    "fig, axs = plt.subplots(3,1,sharex=True,figsize=(7,12),gridspec_kw={\"hspace\":0, \"height_ratios\":[0.3,1,1]})\n",
    "\n",
    "for ax in axs:\n",
    "    if ax.is_last_row():\n",
    "        ax.set_xlabel(r\"$b$ [°]\")\n",
    "    else:\n",
    "        ax.xaxis.set_tick_params(labelbottom=False)\n",
    "    ax.set_aspect('auto')\n",
    "    \n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "    ax.tick_params(which='minor',direction='in',color='black',length=4)#,width=1)\n",
    "    ax.set_xlim(0,-10)\n",
    "    ax.set_xticks(np.arange(0,-10-1,-1))\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "error_factor_vert = 1\n",
    "\n",
    "map_string=\"vertex\"\n",
    "error_string = \"vertex_error\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = map_dict[error_string]/error_factor_vert\n",
    "yticks = get_variable_ticks(map_string, map_array)\n",
    "displacement = max(yticks) - min(yticks)\n",
    "label_y = r\"$l_{\\mathrm{v}}$ (Y)\"\n",
    "label_o = r\"$l_{\\mathrm{v}}$ (O)\"\n",
    "color_y, color_o = color_dict_comp[0][0], color_dict_comp[0][1]\n",
    "\n",
    "axs[1].plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "axs[1].plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "axs[1].fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "axs[1].fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "axs[1].fill_between(b_range_plot, map_array[:,0]-error_array[:,0]+displacement, map_array[:,0]+error_array[:,0]+displacement,alpha=alpha_area, facecolor=color_y)\n",
    "axs[1].fill_between(b_range_plot, map_array[:,1]-error_array[:,1]+displacement, map_array[:,1]+error_array[:,1]+displacement,alpha=alpha_area, facecolor=color_o)\n",
    "axs[1].fill_between(b_range_plot, map_array[:,0]-error_array[:,0]-displacement, map_array[:,0]+error_array[:,0]-displacement,alpha=alpha_area, facecolor=color_y)\n",
    "axs[1].fill_between(b_range_plot, map_array[:,1]-error_array[:,1]-displacement, map_array[:,1]+error_array[:,1]-displacement,alpha=alpha_area, facecolor=color_o)\n",
    "axs[1].set_yticks(yticks[1:])\n",
    "axs[1].set_ylim(min(yticks),max(yticks))\n",
    "\n",
    "map_string = \"vertex_abs\"\n",
    "error_string = \"vertex_error_abs\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = map_dict[error_string]/error_factor_vert\n",
    "color_y, color_o = color_dict_comp[1][0], color_dict_comp[1][1]\n",
    "label_y = r\"$l_{\\mathrm{v}}^{\\mathrm{abs}}$ (Y)\"\n",
    "label_o = r\"$l_{\\mathrm{v}}^{\\mathrm{abs}}$ (O)\"\n",
    "\n",
    "axs[1].plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "axs[1].plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "axs[1].fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "axs[1].fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "#handles, labels = axs[1].get_legend_handles_labels()\n",
    "## sort both labels and handles by labels\n",
    "#labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "#axs[1].legend(handles, labels, loc=\"upper center\", fontsize=legend_fontsize)\n",
    "axs[1].legend(loc=\"best\", fontsize=legend_fontsize,ncol=2)\n",
    "\n",
    "if error_factor_vert != 1:\n",
    "    if error_factor_vert >= 10:\n",
    "        axs[1].text(-0.5,yticks[1]*7/4,r\"Error $\\times 10^{-%i}$\" % get_exponent(error_factor_vert), size=error_fontsize)\n",
    "    elif error_factor_vert == 2:\n",
    "        axs[1].text(-0.5,yticks[1]*7/4,r\"Error $\\times 0.5$\", size=error_fontsize)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown error factor in vertex\")\n",
    "\n",
    "axs[1].set_ylabel(\"Vertex deviation\")\n",
    "    \n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "map_string=\"var_difference\"\n",
    "error_string = \"var_difference_error\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = map_dict[error_string] #/error_factor_anicorr\n",
    "yticks = get_variable_ticks(map_string, map_array)\n",
    "label_y = r\"$\\sigma_r^2-\\sigma_{l}^2$ (Y)\"\n",
    "label_o = r\"$\\sigma_r^2-\\sigma_{l}^2$ (O)\"\n",
    "color_y, color_o = color_dict_comp[0][0], color_dict_comp[0][1]\n",
    "\n",
    "axs[2].plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "axs[2].plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "axs[2].fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "axs[2].fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "map_string = \"covariance\"\n",
    "error_string = \"covariance_error\"\n",
    "map_array = map_dict[map_string]\n",
    "error_array = map_dict[error_string] #/error_factor_anicorr\n",
    "color_y, color_o = color_dict_comp[1][0], color_dict_comp[1][1]\n",
    "label_y = r\"$\\sigma_{rl}^2$ (Y)\"\n",
    "label_o = r\"$\\sigma_{rl}^2$ (O)\"\n",
    "\n",
    "axs[2].plot(b_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "axs[2].plot(b_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "\n",
    "axs[2].fill_between(b_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "axs[2].fill_between(b_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "\n",
    "axs[2].set_ylabel(\"Dispersion difference & covariance\")\n",
    "\n",
    "#handles, labels = ax.get_legend_handles_labels()\n",
    "## sort both labels and handles by labels\n",
    "#labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "#ax.legend(handles, labels, loc=\"upper left\")\n",
    "axs[2].legend(loc='best', fontsize=legend_fontsize,ncol=2)\n",
    "\n",
    "yticks = np.concatenate(([0], np.linspace(-2900,5200,5)))\n",
    "axs[2].set_yticks(yticks)\n",
    "axs[2].set_ylim(min(yticks),max(yticks))\n",
    "\n",
    "#axs[2].text(-0.5,-0.17,r\"Error $\\times 10^{-%i}$\" % get_exponent(error_factor_anicorr), size=error_fontsize)\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "bar_width=0.2\n",
    "axs[0].bar(b_range_plot-bar_width/2, map_dict[\"number\"][:,0], width=bar_width,alpha=transparency,log=True,color=color_dict_comp[0][0])\n",
    "axs[0].bar(b_range_plot+bar_width/2, map_dict[\"number\"][:,1], width=bar_width,alpha=transparency,log=True,color=color_dict_comp[0][1])\n",
    "axs[0].bar(b_range_plot-bar_width/2, map_dict[\"number\"][:,0], width=bar_width,alpha=transparency,log=True,color=color_dict_comp[1][0])\n",
    "axs[0].bar(b_range_plot+bar_width/2, map_dict[\"number\"][:,1], width=bar_width,alpha=transparency,log=True,color=color_dict_comp[1][1])\n",
    "axs[0].yaxis.set_tick_params(labelleft=False,labelright=True)\n",
    "\n",
    "axs[0].set_yticks([100,1000,10000,100000])\n",
    "axs[0].set_ylabel(r\"$N$\",labelpad=13, rotation=0)\n",
    "axs[0].yaxis.set_label_position(\"right\")\n",
    "\n",
    "axs[0].text(-7.4,4000,\"Y: 5-9.8 Gyr\\nO: 9.8-10 Gyr\", size=error_fontsize)\n",
    "\n",
    "#error_string_ = '_erroranicorr'+str(error_factor_anicorr) if error_factor_anicorr != 1 else ''\n",
    "error_string_vert = \"_errorvert\"+str(error_factor_vert) if error_factor_vert != 1 else ''\n",
    "filename = \"vardiffcov\"+error_string_vert+'.png'\n",
    "plt.savefig(save_path+filename,bbox_inches='tight',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stellar populations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinematics vs age/FeH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_POPPLOT_path(resampled_sim_bool=False):\n",
    "    save_path = general_path+'graphs/Observations/Apogee/individual_variable/age_metal/'\n",
    "    \n",
    "    save_path += \"resampled_sim/\" if resampled_sim_bool else \"\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "def get_save_path_POPPLOT_spatial_cuts(resampled_sim_bool,extra_variable,extra_min,extra_max,depth_var,depth_min,depth_max,height_var,height_min,height_max):\n",
    "    \"\"\"\n",
    "    Expected values:\n",
    "    \n",
    "    extra_variable = \"R\" or \"d\"\n",
    "    depth_var = \"l\" or \"y\"\n",
    "    height_var = \"b\" or \"z\"\n",
    "    \"\"\"\n",
    "    \n",
    "    save_path = get_base_POPPLOT_path(resampled_sim_bool)\n",
    "\n",
    "    save_path += f\"{MF.return_int_or_dec(extra_min,2)}{extra_variable}{MF.return_int_or_dec(extra_max,2)}/\"\n",
    "    MF.create_dir(save_path)\n",
    "\n",
    "    save_path += f\"{MF.return_int_or_dec(depth_min,2)}{depth_var}{MF.return_int_or_dec(depth_max,2)}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{MF.return_int_or_dec(height_min,2)}{height_var}{MF.return_int_or_dec(height_max,2)}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "def get_save_path_POPPLOT_data(save_path_spatial, binning_str, pop_str):\n",
    "        \n",
    "    save_path = save_path_spatial + \"data/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{binning_str}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{pop_str}/\"\n",
    "    MF.create_dir(save_path)\n",
    "        \n",
    "    return save_path\n",
    "\n",
    "def get_save_path_POPPLOT_sim(save_path_spatial, binning_str, pop_str):\n",
    "        \n",
    "    save_path = save_path_spatial + \"sim/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{binning_str}/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += f\"{pop_str}/\"\n",
    "    MF.create_dir(save_path)\n",
    "        \n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metal_lowcut = -9999\n",
    "metal_lowcut = -1\n",
    "\n",
    "try:\n",
    "    data_trim = data[data['FeH']>=metal_lowcut]\n",
    "    print(f\"Chose minimum metallicity of {metal_lowcut}\" if metal_lowcut != -9999 else \"No minimum metallicity\")\n",
    "except NameError:\n",
    "    print(\"Working with simulation only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latitude ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently chosen according to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_variable_lims = {\n",
    "    \"l\": [-2,2],\n",
    "    \"y\": [-0.1,0.1]\n",
    "}\n",
    "\n",
    "overall_height_variable_lims = {\n",
    "    \"b\": [1.5,9],\n",
    "    \"z\": [0.2,2]\n",
    "}\n",
    "\n",
    "extra_variable_lims = {\n",
    "    \"d\": [6.1,10.1],\n",
    "    \"R\": [0,3.5]\n",
    "}\n",
    "\n",
    "# CHOOSE\n",
    "# extra_variable = \"d\"\n",
    "extra_variable = \"R\"\n",
    "depth_var = \"l\"\n",
    "height_var = \"b\"\n",
    "\n",
    "if True: # print\n",
    "    depth_min,depth_max = depth_variable_lims[depth_var]\n",
    "    overall_height_min,overall_height_max = overall_height_variable_lims[height_var]\n",
    "    extra_min,extra_max = extra_variable_lims[extra_variable]\n",
    "    \n",
    "    print(depth_var,depth_min,depth_max)\n",
    "    print(height_var,overall_height_min,overall_height_max)\n",
    "    print(extra_variable,extra_min,extra_max)\n",
    "    \n",
    "if True: # assert\n",
    "    assert depth_min == -2 and depth_max == 2, \"Are you sure you don't want to have l between -2 and 2?\"\n",
    "    assert extra_min == 0 and extra_max == 3.5, \"Are you sure you don't want to have R between 0 and 3.5?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if height_var == \"b\":\n",
    "    o_b_range_min,o_b_range_max = PH.get_equal_n_minmax_b_ranges(data_trim, n_points=3,\\\n",
    "                                                                 extra_variable=extra_variable,extra_min=extra_min,extra_max=extra_max,\\\n",
    "                                                                 depth_min=depth_min,depth_max=depth_max,\\\n",
    "                                                                 overall_bmin=overall_height_min,overall_bmax=overall_height_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_bin_idx = 0\n",
    "\n",
    "if height_var == \"b\":\n",
    "    bmin = o_b_range_min[lat_bin_idx]\n",
    "    bmax = o_b_range_max[lat_bin_idx]\n",
    "\n",
    "    print(bmin, MF.return_int_or_dec(bmin,2))\n",
    "    print(bmax, MF.return_int_or_dec(bmax,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will apply the same latitude binning (using 0R3.5) for the different radial variations (eg 0R2, for which the equal-number latitude binning would change slightly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In bulk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_ranges(df_extra, binning_type=\"equalN\", n_points=20, plot_median_bool=False):\n",
    "    if binning_type == \"manual\":\n",
    "\n",
    "        if old_subplots:\n",
    "    #         pop_str_sim = \"0to9in1_oldSplit\"\n",
    "    #         pop_min_range = np.array([0,4,5,6,7,8, 9,   9.5, 9.8,  9.9,   9.925, 9.95, 9.975])\n",
    "    #         pop_max_range = np.array([4,5,6,7,8,9, 9.5, 9.8, 10,   9.925, 9.95,  9.975, 10])\n",
    "\n",
    "            pop_str_sim = \"4to9in1_oldSplit\"\n",
    "            pop_min_range = np.array([4,5,6,7,8, 9,   9.5, 9.8,  9.9,   9.925, 9.95, 9.975])\n",
    "            pop_max_range = np.array([5,6,7,8,9, 9.5, 9.8, 10,   9.925, 9.95,  9.975, 10])\n",
    "\n",
    "            max_age_lim = 9\n",
    "\n",
    "            limit_index = np.where(pop_max_range == max_age_lim)[0][0] + 1\n",
    "        else:\n",
    "            pop_str_sim = \"4to10in1\"\n",
    "            pop_min_range = np.array([min_age,5,6,7,8, 9])\n",
    "            pop_max_range = np.array([5,6,7,8,9, max_age])\n",
    "\n",
    "    elif binning_type == \"equalN\":\n",
    "        all_age_bins = PH.get_equal_n_bin_edges(val_array=df_extra[\"age\"].values,n_bins=n_points,pandas_way=True)\n",
    "\n",
    "        pop_min_range = all_age_bins[:-1]\n",
    "        pop_max_range = all_age_bins[1:]\n",
    "\n",
    "        pop_str_sim = f\"{n_points}_datapoints\"\n",
    "\n",
    "    elif binning_type == \"equalSteps\":\n",
    "\n",
    "        all_age_bins = np.linspace(min_age,max_age,n_points+1)\n",
    "        pop_min_range = all_age_bins[:-1]\n",
    "        pop_max_range = all_age_bins[1:]\n",
    "\n",
    "        pop_str_sim = f\"{n_points}_datapoints\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown binning method.\")\n",
    "\n",
    "    assert len(pop_min_range) == len(pop_max_range), \"Lengths need to be equal\"\n",
    "\n",
    "    if plot_median_bool:\n",
    "        \"\"\"\n",
    "        If I show the values as a surface (with fill_between) I'd rather plot at the mean (i.e. mid-point of the bin) because otherwise I need to give some other indication\n",
    "        of the width of each bin, and I don't want to show x-error bars as I imagine they'd overlap in an ugly way with the surface (although I have not tried).\n",
    "        \"\"\"\n",
    "\n",
    "        pop_plot_range = PH.get_range_medians(df_extra[\"age\"],pop_min_range,pop_max_range)\n",
    "    else:\n",
    "        pop_plot_range = PH.get_range_means(pop_min_range,pop_max_range)\n",
    "        \n",
    "    return pop_min_range,pop_max_range,pop_plot_range,pop_str_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_variable_lims = {\n",
    "    \"l\": [-2,2],\n",
    "    \"y\": [coordinates.ang_to_rect(ang=-2,x=coordinates.get_solar_radius()), coordinates.ang_to_rect(ang=2,x=coordinates.get_solar_radius())]\n",
    "}\n",
    "\n",
    "height_variable_lims = {\n",
    "    \"b\": [bmin,bmax],\n",
    "    \"z\": [coordinates.ang_to_rect(bmin,x=R0), coordinates.ang_to_rect(bmax,x=R0)]\n",
    "} if \"bmin\" in globals() and \"bmax\" in globals() else {\n",
    "    \"b\": [1.5,9],\n",
    "    \"z\": [0.2,2]\n",
    "}\n",
    "\n",
    "z_range_min = [coordinates.ang_to_rect(bmin,x=R0) for bmin in o_b_range_min]\n",
    "z_range_max = [coordinates.ang_to_rect(bmax,x=R0) for bmax in o_b_range_max]\n",
    "\n",
    "extra_variable_lims = {\n",
    "    \"d\": [6.1,10.1],\n",
    "    \"R\": [0,3.5]\n",
    "}\n",
    "\n",
    "# CHOOSE\n",
    "# extra_variable = \"d\"\n",
    "extra_variable = \"R\"\n",
    "depth_var = \"l\"\n",
    "height_var = \"b\"\n",
    "\n",
    "if True: # print\n",
    "    depth_min,depth_max = depth_variable_lims[depth_var]\n",
    "    height_min,height_max = height_variable_lims[height_var]\n",
    "    extra_min,extra_max = extra_variable_lims[extra_variable]\n",
    "    \n",
    "    print(depth_var,depth_min,depth_max)\n",
    "    print(height_var,height_min,height_max)\n",
    "    print(extra_variable,extra_min,extra_max)\n",
    "    \n",
    "    print(\"\\nz ranges:\")\n",
    "    print(z_range_min)\n",
    "    print(z_range_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do everything up to saving the arrays in a loop\n",
    "\n",
    "save_arrays_bool = True\n",
    "# save_arrays_bool = False\n",
    "\n",
    "min_pop,max_pop = 4,10\n",
    "pop_var = \"age\"\n",
    "xlabel = \"Age [Gyr]\" # needed in visualise_1D_binning\n",
    "\n",
    "bootstrap_repeat = 500\n",
    "min_star_number = 50\n",
    "\n",
    "vel_hist_bool = True\n",
    "velhist_bins = 50\n",
    "\n",
    "binning_type_list = len(n_points_list)*[\"equalSteps\"]\n",
    "plot_median_list = len(n_points_list)*[True]\n",
    "\n",
    "cuts_dict_list = [\n",
    "    {depth_var:[depth_min,depth_max],height_var:[o_b_range_min[0],o_b_range_max[0]],extra_variable:[0,3.5],pop_var:[min_pop,max_pop]},\n",
    "    {depth_var:[depth_min,depth_max],height_var:[o_b_range_min[0],o_b_range_max[0]],extra_variable:[0,2],pop_var:[min_pop,max_pop]},\n",
    "    {depth_var:[depth_min,depth_max],height_var:[o_b_range_min[1],o_b_range_max[1]],extra_variable:[0,3.5],pop_var:[min_pop,max_pop]},\n",
    "    {depth_var:[depth_min,depth_max],height_var:[o_b_range_min[1],o_b_range_max[1]],extra_variable:[0,2],pop_var:[min_pop,max_pop]},\n",
    "    {depth_var:[depth_min,depth_max],height_var:[o_b_range_min[2],o_b_range_max[2]],extra_variable:[0,3.5],pop_var:[min_pop,max_pop]},\n",
    "    {depth_var:[depth_min,depth_max],height_var:[o_b_range_min[2],o_b_range_max[2]],extra_variable:[0,2],pop_var:[min_pop,max_pop]}\n",
    "]\n",
    "\n",
    "n_points_list = [\n",
    "    40,\n",
    "    40,\n",
    "    20,\n",
    "    20,\n",
    "    10,\n",
    "    10\n",
    "]\n",
    "\n",
    "n_points_list_resampled = [\n",
    "    8, # or 7\n",
    "    8, # or 7\n",
    "    6,\n",
    "    5,\n",
    "    4, # or 5\n",
    "    3\n",
    "]\n",
    "\n",
    "vel_freq_list = [\n",
    "    4,\n",
    "    4,\n",
    "    2,\n",
    "    2,\n",
    "    1,\n",
    "    1\n",
    "]\n",
    "\n",
    "n_points_list = n_points_list_resampled if sim_resampled_bool else n_points_list\n",
    "vel_freq_list = [1]*len(n_points_list) if sim_resampled_bool else vel_freq_list\n",
    "\n",
    "assert len(cuts_dict_list)==len(n_points_list)==len(vel_freq_list)==len(binning_type_list)==len(plot_median_list), \"All lists must have the same length\"\n",
    "\n",
    "for i in range(len(cuts_dict_list)):\n",
    "    df_extra = MF.apply_cuts_to_df(df0,cuts_dict=cuts_dict_list[i])\n",
    "    \n",
    "    pop_min_range,pop_max_range,pop_plot_range,pop_str_sim = get_plot_ranges(df_extra, binning_type=binning_type_list[i],\\\n",
    "                                                                 n_points=n_points_list[i],plot_median_bool=plot_median_list[i])\n",
    "    \n",
    "    print(cuts_dict_list[i])\n",
    "    print(f\"{len(df_extra)} total stars\")\n",
    "    print(f\"pop_plot_range: {pop_plot_range}\")\n",
    "    print(\"Star numbers:\",stat.binned_statistic(values=None,x=df_extra[pop_var].values,bins=np.union1d(pop_min_range,pop_max_range),statistic=\"count\")[0])\n",
    "    \n",
    "    extra_min,extra_max = cuts_dict_list[i][extra_variable]\n",
    "    depth_min,depth_max = cuts_dict_list[i][depth_var]\n",
    "    height_min,height_max = cuts_dict_list[i][height_var]\n",
    "    \n",
    "    save_path_spatial = get_save_path_POPPLOT_spatial_cuts(sim_resampled_bool,extra_variable,extra_min,extra_max,depth_var,depth_min,depth_max,height_var,height_min,height_max)\n",
    "    save_path = get_save_path_POPPLOT_sim(save_path_spatial, binning_type_list[i], pop_str_sim)\n",
    "    \n",
    "    print(\"save_path:\",save_path)\n",
    "    \n",
    "    MP.visualise_1D_binning(df_extra[pop_var].values, pop_min_range, pop_max_range, hist_bins=100, log=True,\\\n",
    "                            save_bool=True,save_path=save_path,filename_prefix=pop_var,xlabel=xlabel,show_bool=True)\n",
    "\n",
    "    if vel_hist_bool:\n",
    "        save_path_hist = save_path + \"vel_histograms/\"\n",
    "        MF.create_dir(save_path_hist)\n",
    "\n",
    "        save_path_hist += f\"{velhist_bins}bins/\"\n",
    "        MF.create_dir(save_path_hist)\n",
    "\n",
    "        print(\"Saving velocity histograms on\\n\",save_path_hist)\n",
    "        \n",
    "    if True: # get arrays\n",
    "        map_dict = {}\n",
    "        for map_string in full_map_string_list:\n",
    "            map_dict[map_string] = np.zeros(shape=(len(pop_min_range)))\n",
    "\n",
    "        for pop_index, (popmin, popmax) in enumerate(zip(pop_min_range,pop_max_range)):\n",
    "\n",
    "            print(popmin,popmax,end=\";  \")\n",
    "\n",
    "            include_lims = \"both\" if pop_index==len(pop_min_range)-1 else \"min\"\n",
    "            df_pop = MF.apply_cuts_to_df(df_extra, cuts_dict={pop_var:[popmin,popmax]}, lims_dict={pop_var:include_lims})\n",
    "\n",
    "            if vel_hist_bool and pop_index % vel_freq_list[i] == 0:\n",
    "                name_suffix = f\"{str(MF.return_int_or_dec(popmin,dec=2))}pop{str(MF.return_int_or_dec(popmax,dec=2))}\"\n",
    "                MP.plot_velocity_histograms_both_stats(df_pop,vel_x_variable,vel_y_variable,save_bool=True,save_path=save_path_hist,suffix=name_suffix,verbose=pop_index==0,bins=velhist_bins)\n",
    "\n",
    "            values = val_err.get_all_variable_values_and_errors(df_pop[f\"v{vel_x_variable}\"].values,df_pop[f\"v{vel_y_variable}\"].values, full_map_string_list,\\\n",
    "                                                                    repeat=bootstrap_repeat, min_number = min_star_number)   \n",
    "\n",
    "            if len(values) != len(full_map_string_list):\n",
    "                raise ValueError(\"The length of the values list does not match the string list!\")\n",
    "\n",
    "            for map_string in full_map_string_list:\n",
    "                map_dict[map_string][pop_index] = values[map_string]\n",
    "\n",
    "        del df_pop\n",
    "        print(\"Done\")\n",
    "    \n",
    "    if save_arrays_bool:\n",
    "\n",
    "        array_path = save_path + \"arrays/\"\n",
    "        \n",
    "        overwrite = False\n",
    "        if os.path.isdir(array_path):\n",
    "            overwrite_str = input(\"There may be files already in this folder, do you want to overwrite them? Y/N\\n\")\n",
    "            if overwrite_str.upper() == \"Y\":\n",
    "                overwrite = True\n",
    "        else:\n",
    "            MF.create_dir(array_path)\n",
    "            overwrite = True\n",
    "            \n",
    "        if overwrite:\n",
    "\n",
    "            if True: # values as .txt and .npy\n",
    "\n",
    "                with open(array_path+'values.txt','w') as f:\n",
    "                    for key in map_dict:\n",
    "                        f.write(key+'\\n')\n",
    "                        np.savetxt(f,map_dict[key],fmt='%.5f')\n",
    "                        f.write('\\n')\n",
    "\n",
    "                for map_string in full_map_string_list:\n",
    "                    np.save(array_path+map_string, map_dict[map_string])\n",
    "\n",
    "            if True: # plot limits as .txt and .npy\n",
    "\n",
    "                with open(array_path+'pop_ranges.txt','w') as f:\n",
    "                    f.write(\"pop_min_range\\n\")\n",
    "                    for mini in pop_min_range:\n",
    "                        f.write(f\"{mini}\\t\")\n",
    "                    f.write(\"\\n\\npop_max_range\\n\")\n",
    "                    for maxi in pop_max_range:\n",
    "                        f.write(f\"{maxi}\\t\")\n",
    "                    f.write(\"\\n\\npop_plot_range\\n\")\n",
    "                    for p in pop_plot_range:\n",
    "                        f.write(f\"{p}\\t\")\n",
    "\n",
    "                np.save(array_path+\"pop_min_range\", pop_min_range)\n",
    "                np.save(array_path+\"pop_max_range\", pop_max_range)\n",
    "                np.save(array_path+\"pop_plot_range\", pop_plot_range)\n",
    "\n",
    "            print(\"Saved .txt and .npy in\",array_path)\n",
    "    else:\n",
    "        print(\"Not saving\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_variable_lims = {\n",
    "    \"l\": [-2,2],\n",
    "    \"y\": [coordinates.ang_to_rect(ang=-2,x=coordinates.get_solar_radius()), coordinates.ang_to_rect(ang=2,x=coordinates.get_solar_radius())]\n",
    "}\n",
    "\n",
    "height_variable_lims = {\n",
    "    \"b\": [bmin,bmax],\n",
    "    \"z\": [coordinates.ang_to_rect(bmin,x=R0), coordinates.ang_to_rect(bmax,x=R0)]\n",
    "} if \"bmin\" in globals() and \"bmax\" in globals() else {\n",
    "    \"b\": [1.5,9],\n",
    "    \"z\": [0.2,2]\n",
    "}\n",
    "\n",
    "extra_variable_lims = {\n",
    "    \"d\": [6.1,10.1],\n",
    "    \"R\": [0,2]\n",
    "}\n",
    "\n",
    "# CHOOSE\n",
    "# extra_variable = \"d\"\n",
    "extra_variable = \"R\"\n",
    "depth_var = \"l\"\n",
    "height_var = \"b\"\n",
    "\n",
    "if True: # print\n",
    "    depth_min,depth_max = depth_variable_lims[depth_var]\n",
    "    height_min,height_max = height_variable_lims[height_var]\n",
    "    extra_min,extra_max = extra_variable_lims[extra_variable]\n",
    "    \n",
    "    print(depth_var,depth_min,depth_max)\n",
    "    print(height_var,height_min,height_max)\n",
    "    print(extra_variable,extra_min,extra_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # xz young-old density plot\n",
    "    \n",
    "    # save_bool = True\n",
    "    save_bool = False\n",
    "\n",
    "    # projection = \"xy\"\n",
    "    projection = \"xz\"\n",
    "\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "\n",
    "    if True: # visualise cuts for young and old\n",
    "\n",
    "        xymax = 3.5\n",
    "\n",
    "        zmax = 2.2\n",
    "        zmin = (0 if zabs else -zmax) if projection == \"xz\" else 0.5\n",
    "\n",
    "        bins_x=70\n",
    "        density_bool=False\n",
    "\n",
    "        young_ages,old_ages = [4,7],[9.5,10]\n",
    "\n",
    "        if True:\n",
    "\n",
    "            aspect_ratio = 2*(zmax-zmin)/(1.5*xymax) if projection == \"xz\" else 1\n",
    "\n",
    "            fig,axs=plt.subplots(figsize=(10,aspect_ratio*10),nrows=2,gridspec_kw={\"hspace\":0})\n",
    "\n",
    "            if True: # quick show & colorbar\n",
    "\n",
    "                spatial_cut_dict = { depth_var:[depth_min,depth_max] } if projection == \"xz\" else { \"z\":[zmin,zmax]}\n",
    "                young_cut_dict,old_cut_dict = {\"age\":young_ages}, {\"age\":old_ages}\n",
    "\n",
    "                if projection == \"xz\":\n",
    "                    c1 = MP.quick_show_xz(MF.apply_cuts_to_df(df0,[spatial_cut_dict,young_cut_dict]),bins_x=bins_x,zmin=zmin,zmax=zmax,xmin=-xymax,xmax=xymax,show=False,density=density_bool)\n",
    "                    c2 = MP.quick_show_xz(MF.apply_cuts_to_df(df0,[spatial_cut_dict,old_cut_dict]),bins_x=bins_x,zmin=zmin,zmax=zmax,xmin=-xymax,xmax=xymax,show=False,density=density_bool)\n",
    "                elif projection == \"xy\":\n",
    "                    c1 = MP.quick_show_xy(MF.apply_cuts_to_df(df0,[spatial_cut_dict,young_cut_dict]),bins_x=bins_x,ymin=-xymax,ymax=xymax,xmin=-xymax,xmax=xymax,show=False,density=density_bool)\n",
    "                    c2 = MP.quick_show_xy(MF.apply_cuts_to_df(df0,[spatial_cut_dict,old_cut_dict]),bins_x=bins_x,ymin=-xymax,ymax=xymax,xmin=-xymax,xmax=xymax,show=False,density=density_bool)\n",
    "                else:\n",
    "                    raise ValueError(\"Only xy and xz currently supported\")\n",
    "\n",
    "                norm = PH.get_norm_from_count_list([c1,c2],log=True)\n",
    "\n",
    "                if projection == \"xz\":\n",
    "                    _ = MP.quick_show_xz(MF.apply_cuts_to_df(df0,[spatial_cut_dict,young_cut_dict]),bins_x=bins_x,zmin=zmin,zmax=zmax,xmin=-xymax,xmax=xymax,ax=axs[0],norm=norm,density=density_bool)\n",
    "                    _ = MP.quick_show_xz(MF.apply_cuts_to_df(df0,[spatial_cut_dict,old_cut_dict]),bins_x=bins_x,zmin=zmin,zmax=zmax,xmin=-xymax,xmax=xymax,ax=axs[1],norm=norm,density=density_bool)\n",
    "                elif projection == \"xy\":\n",
    "                    _ = MP.quick_show_xy(MF.apply_cuts_to_df(df0,[spatial_cut_dict,young_cut_dict]),bins_x=bins_x,ymin=-xymax,ymax=xymax,xmin=-xymax,xmax=xymax,ax=axs[0],norm=norm,density=density_bool)\n",
    "                    _ = MP.quick_show_xy(MF.apply_cuts_to_df(df0,[spatial_cut_dict,old_cut_dict]),bins_x=bins_x,ymin=-xymax,ymax=xymax,xmin=-xymax,xmax=xymax,ax=axs[1],norm=norm,density=density_bool)\n",
    "                else:\n",
    "                    raise ValueError(\"Only xy and xz currently supported\")\n",
    "\n",
    "                cbar = plt.colorbar(cm.ScalarMappable(norm=norm,cmap=\"viridis\"),ax=axs,shrink=0.8)\n",
    "                cbar.set_label(mass_density_label) if density_bool else cbar.set_label(r\"$N$\",rotation=0,labelpad=20)\n",
    "\n",
    "            if True: # visualise cuts & legend\n",
    "\n",
    "                cuts_to_visualise = {depth_var:[depth_max],height_var:[height_min,height_max],\"R\":[2,3.5],\"l\":[2]}\n",
    "                if height_var == \"z\":\n",
    "                    cuts_to_visualise[\"b\"] = [bmin,bmax]\n",
    "\n",
    "                filename,_ = MP.visualise_bulge_selection(given_axs=axs[::-1],projection=projection,cuts_dict=cuts_to_visualise,R0=R0)\n",
    "                _,_ = MP.visualise_bulge_selection(given_axs=axs,projection=projection,cuts_dict=cuts_to_visualise,R0=R0)\n",
    "\n",
    "                axs[0].legend(loc=\"upper right\" if projection==\"xy\" else \"upper left\",framealpha=0.8,ncols=1 if projection==\"xy\" else 2)\n",
    "\n",
    "            for i,ax in enumerate(axs): # lims, aspect, titles\n",
    "                ax.set_xlim(-xymax,xymax)\n",
    "                ax.set_ylim(zmin,zmax) if projection == \"xz\" else ax.set_ylim(-xymax,xymax)\n",
    "                ax.set_aspect(\"equal\")\n",
    "\n",
    "                if projection == \"xy\":\n",
    "                    ax.text(x=0.03,y=0.97,s=[\"Young\",\"Old\"][i],transform=ax.transAxes,bbox={\"facecolor\":\"w\",\"alpha\":0.9},ha=\"left\",va=\"top\")\n",
    "                if projection == \"xz\":\n",
    "                    ax.set_title([\"Young\",\"Old\"][i])\n",
    "\n",
    "            if True: # filename and saving\n",
    "\n",
    "                filename += f\"_{projection}\" if projection != \"both\" else \"\"\n",
    "\n",
    "                filename += f\"_{MF.return_int_or_dec(depth_min,2)}{depth_var}{MF.return_int_or_dec(depth_max,2)}\" if projection == \"xz\" \\\n",
    "                            else f\"_{MF.return_int_or_dec(zmin,2)}z{MF.return_int_or_dec(zmax,2)}\"\n",
    "\n",
    "                print(filename)\n",
    "\n",
    "                save_path = f\"{general_path}graphs/other_plots/visualise_bulge_cuts/youngold_cbar/{projection}/\"\n",
    "                save_path += \"resampled/\" if sim_resampled_bool else \"\"\n",
    "\n",
    "                if save_bool:\n",
    "                    print(\"Saving in:\",save_path)\n",
    "                    plt.savefig(save_path+filename+\".png\", dpi=200,bbox_inches=\"tight\")\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_age,max_age = 4,10\n",
    "\n",
    "df_extra = MF.apply_cuts_to_df(df0,cuts_dict={depth_var:[depth_min,depth_max],height_var:[height_min,height_max],\\\n",
    "                                              extra_variable:[extra_min,extra_max],\"age\":[min_age,max_age]})\n",
    "\n",
    "print(len(df_extra),\"stars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_plot_median = True\n",
    "sim_plot_median = False\n",
    "\n",
    "equal_number = False\n",
    "equal_steps = True\n",
    "manual_ages = False\n",
    "\n",
    "n_points_sim = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning\n",
    "\n",
    "assert manual_ages + equal_steps + equal_number == 1, \"Select a single option\"\n",
    "binning_str_sim = np.array([\"custom_range\",\"equalSteps\",\"equalN\"])[np.array([manual_ages,equal_steps,equal_number])][0]\n",
    "print(\"Using\",binning_str_sim)\n",
    "\n",
    "if manual_ages:\n",
    "    \n",
    "    if old_subplots:\n",
    "#         pop_str_sim = \"0to9in1_oldSplit\"\n",
    "#         pop_min_range = np.array([0,4,5,6,7,8, 9,   9.5, 9.8,  9.9,   9.925, 9.95, 9.975])\n",
    "#         pop_max_range = np.array([4,5,6,7,8,9, 9.5, 9.8, 10,   9.925, 9.95,  9.975, 10])\n",
    "\n",
    "        pop_str_sim = \"4to9in1_oldSplit\"\n",
    "        pop_min_range = np.array([4,5,6,7,8, 9,   9.5, 9.8,  9.9,   9.925, 9.95, 9.975])\n",
    "        pop_max_range = np.array([5,6,7,8,9, 9.5, 9.8, 10,   9.925, 9.95,  9.975, 10])\n",
    "        \n",
    "        max_age_lim = 9\n",
    "        \n",
    "        limit_index = np.where(pop_max_range == max_age_lim)[0][0] + 1\n",
    "    else:\n",
    "        pop_str_sim = \"4to10in1\"\n",
    "        pop_min_range = np.array([min_age,5,6,7,8, 9])\n",
    "        pop_max_range = np.array([5,6,7,8,9, max_age])\n",
    "\n",
    "elif equal_number:\n",
    "    all_age_bins = PH.get_equal_n_bin_edges(val_array=df_extra[\"age\"].values,n_bins=n_points_sim,pandas_way=True)\n",
    "    \n",
    "    pop_min_range = all_age_bins[:-1]\n",
    "    pop_max_range = all_age_bins[1:]\n",
    "    \n",
    "    pop_str_sim = f\"{n_points_sim}_datapoints\"\n",
    "    \n",
    "elif equal_steps:\n",
    "    \n",
    "    all_age_bins = np.linspace(min_age,max_age,n_points_sim+1)\n",
    "    pop_min_range = all_age_bins[:-1]\n",
    "    pop_max_range = all_age_bins[1:]\n",
    "    \n",
    "    pop_str_sim = f\"{n_points_sim}_datapoints\"\n",
    "    \n",
    "else:\n",
    "    raise ValueError(\"Unknown binning method.\")\n",
    "    \n",
    "assert len(pop_min_range) == len(pop_max_range), \"Lengths need to be equal\"\n",
    "\n",
    "if sim_plot_median:\n",
    "    \"\"\"\n",
    "    If I show the values as a surface (with fill_between) I'd rather plot at the mean (i.e. mid-point of the bin) because otherwise I need to give some other indication\n",
    "    of the width of each bin, and I don't want to show x-error bars as I imagine they'd overlap in an ugly way with the surface (although I have not tried).\n",
    "    \"\"\"\n",
    "    \n",
    "    pop_plot_range = PH.get_range_medians(df_extra[\"age\"],pop_min_range,pop_max_range)\n",
    "    print(\"Plotting at the median\\n\",pop_plot_range)\n",
    "else:\n",
    "    pop_plot_range = PH.get_range_means(pop_min_range,pop_max_range)\n",
    "    print(\"Plotting at the mean\\n\",pop_plot_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(10,2))\n",
    "\n",
    "ax.errorbar(x=pop_plot_range,xerr=PH.get_xerr(minima=pop_min_range,maxima=pop_max_range,plot=pop_plot_range,frac=1),y=[0]*n_points_sim,fmt=\"d\",capsize=20)\n",
    "ax.set_xlim(3.95,10.05)\n",
    "ax.minorticks_on()\n",
    "ax.set_yticks([])\n",
    "ax.invert_xaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of stars per bin\n",
    "stat.binned_statistic(values=None,x=df_extra[\"age\"].values,bins=all_age_bins,statistic=\"count\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lengths = []\n",
    "for individual_age in ages_range:\n",
    "    age_step = age_step_young if individual_age < age_limit_oldyoung else age_step_old\n",
    "    \n",
    "    age_max = individual_age + age_step\n",
    "    age_min = individual_age\n",
    "    df = df_extra[(df_extra.age>=age_min)&(df_extra.age<age_max)]\n",
    "    lengths.append(len(df))\n",
    "    print(\"Age interval\", np.float16(age_min), \"to\", np.float16(age_max),\"has\",len(df),\"stars\")\n",
    "print(\"Total number of stars selected across time:\",np.sum(lengths))\n",
    "print(\"Which is \"+str(np.float16(100*np.sum(lengths)/len(df0)))+\"% of the total\")\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_variable_lims = {\n",
    "    \"l\": [-2,2],\n",
    "    \"y\": [-0.1,0.1]\n",
    "}\n",
    "\n",
    "height_variable_lims = {\n",
    "    \"b\": [bmin,bmax],\n",
    "    \"z\": [np.tan(bmin*np.pi/180)*R0, np.tan(bmax*np.pi/180)*R0]\n",
    "} if \"bmin\" in globals() and \"bmax\" in globals() else {\n",
    "    \"b\": [1.5,9],\n",
    "    \"z\": [0.2,2]\n",
    "}\n",
    "\n",
    "extra_variable_lims = {\n",
    "    \"d\": [6.1,10.1],\n",
    "    \"R\": [0,3.5]\n",
    "}\n",
    "\n",
    "# CHOOSE\n",
    "# extra_variable = \"d\"\n",
    "extra_variable = \"R\"\n",
    "depth_var = \"l\"\n",
    "height_var = \"b\"\n",
    "\n",
    "if True: # print\n",
    "    depth_min,depth_max = depth_variable_lims[depth_var]\n",
    "    height_min,height_max = height_variable_lims[height_var]\n",
    "    extra_min,extra_max = extra_variable_lims[extra_variable]\n",
    "    \n",
    "    print(depth_var,depth_min,depth_max)\n",
    "    print(height_var,height_min,height_max)\n",
    "    print(extra_variable,extra_min,extra_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_extra = MF.apply_cuts_to_df(data_trim,cuts_dict={depth_var:[depth_min,depth_max],height_var:[height_min,height_max],\\\n",
    "                                              extra_variable:[extra_min,extra_max]})\n",
    "\n",
    "print(len(data_extra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_number = True # divide in equal-number bins across all metallicities\n",
    "manual_metal = False\n",
    "equal_steps = False # divide in constant metallicity steps\n",
    "\n",
    "plot_median_bool = True\n",
    "# plot_median_bool = False # mid-point of bin\n",
    "\n",
    "n_points_data = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert manual_metal + equal_steps + equal_number == 1, \"Select a single option\"\n",
    "binning_str_data = np.array([\"custom_range\",\"equalSteps\",\"equalN\"])[np.array([manual_metal,equal_steps,equal_number])][0]\n",
    "\n",
    "if manual_metal:\n",
    "    min_metal,max_metal = min(data_extra[\"FeH\"]),max(data_extra['FeH'])\n",
    "    \n",
    "    pop_str_data = \"metal_cuts_equal\"\n",
    "    pop_min_range = np.array([min_metal, -0.55, -0.25, 0.15])\n",
    "    pop_max_range = np.array([-0.55,-0.25,0.15,max_metal])\n",
    "\n",
    "#     pop_str_data = \"metal_cuts_A\"\n",
    "#     pop_min_range = np.array([min_metal, -0.7, -0.4, -0.1, 0.3])\n",
    "#     pop_max_range = np.array([-0.7,-0.4,0.1,0.3,max_metal])\n",
    "    \n",
    "#     pop_str_data = \"metal_cuts_B\"\n",
    "#     pop_min_range = np.array([min_metal, -1, -0.5, 0,0.3])\n",
    "#     pop_max_range = np.array([-1,-0.5,0,0.3,max_metal])\n",
    "    \n",
    "#     pop_str_data = \"all_poor\"\n",
    "#     pop_max_range = np.array([-1.3,-1.2,-1.1,-1.0,-0.9,-0.8,-0.7])\n",
    "#     pop_min_range = np.array([min_metal]*len(pop_max_range))\n",
    "\n",
    "#     pop_str_data = \"axisymmetric\"\n",
    "#     pop_min_range = np.array([-1.2, -1.2, -1.2, -1.1,-1.1, -1,-1,-1])\n",
    "#     pop_max_range = np.array([-0.9,-0.8,-0.7,-0.9,-0.8,-0.7, -0.6,-0.5])\n",
    "\n",
    "#     pop_str_data = \"all_rich\"\n",
    "#     pop_min_range = np.array([-0.9,-0.8,-0.7,-0.6,-0.5,-0.4,-0.3,-0.2,-0.1,0])\n",
    "#     pop_max_range = np.array([max_metal]*len(pop_min_range))\n",
    "    \n",
    "    pass\n",
    "elif equal_steps:\n",
    "    min_metal = data_extra['FeH'].min()\n",
    "    metal_step = 0.1\n",
    "    pop_min_range = np.arange(min_metal,data_extra['FeH'].max(),metal_step)\n",
    "    pop_max_range = pop_min_range + metal_step\n",
    "    \n",
    "    pop_str_data = f\"{metal_step}step\"  \n",
    "elif equal_number:\n",
    "    \n",
    "    pop_str_data = f\"{n_points_data}_datapoints\"\n",
    "    \n",
    "    metal_edges = PH.get_equal_n_bin_edges(data_extra.FeH.values, n_points_data)\n",
    "    pop_max_range = metal_edges[1:]\n",
    "    pop_min_range = metal_edges[:-1]\n",
    "\n",
    "if True: # pop_plot_range\n",
    "    if manual_metal and range_str in [\"all_rich\",\"all_poor\"]:\n",
    "        if range_str == \"all_rich\":\n",
    "            pop_plot_range = pop_min_range\n",
    "        if range_str == \"all_poor\":\n",
    "            pop_plot_range = pop_max_range\n",
    "    elif plot_median_bool:\n",
    "        pop_plot_range = PH.get_range_medians(data_extra.FeH.values, pop_min_range, pop_max_range)\n",
    "    else:\n",
    "        pop_plot_range = np.array([np.mean([m,M]) for m,M in zip(pop_min_range,pop_max_range)])\n",
    "    \n",
    "assert len(pop_min_range) == len(pop_max_range), \"Lengths need to be equal\"\n",
    "print(pop_plot_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_spatial = get_save_path_POPPLOT_spatial_cuts(sim_resampled_bool,extra_variable,extra_min,extra_max,depth_var,depth_min,depth_max,height_var,height_min,height_max)\n",
    "\n",
    "if data_bool:\n",
    "    save_path = get_save_path_POPPLOT_data(save_path_spatial, binning_str_data, pop_str_data)\n",
    "else:\n",
    "    save_path = get_save_path_POPPLOT_sim(save_path_spatial, binning_str_sim, pop_str_sim)\n",
    "    \n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_extra if data_bool else df_extra\n",
    "pop_var = \"FeH\" if data_bool else \"age\"\n",
    "xlabel = \"[Fe/H]\" if data_bool else \"Age [Gyr]\"\n",
    "\n",
    "MP.visualise_1D_binning(df[pop_var].values, pop_min_range, pop_max_range, hist_bins=100, log=False,\\\n",
    "                        save_bool=True,save_path=save_path,filename_prefix=pop_var,xlabel=xlabel)\n",
    "\n",
    "if not data_bool:\n",
    "    MP.visualise_1D_binning(df[pop_var].values, pop_min_range, pop_max_range, hist_bins=100, log=True,\\\n",
    "                            save_bool=True,save_path=save_path,filename_prefix=pop_var,xlabel=xlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_repeat = 500\n",
    "min_star_number = 50 if not data_bool else 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_hist_bool = True\n",
    "# vel_hist_bool = False\n",
    "\n",
    "velhist_bins = 50 if not data_bool else 20\n",
    "\n",
    "if vel_hist_bool:\n",
    "    save_path_hist = save_path + \"vel_histograms/\"\n",
    "    MF.create_dir(save_path_hist)\n",
    "    \n",
    "    save_path_hist += f\"{velhist_bins}bins/\"\n",
    "    MF.create_dir(save_path_hist)\n",
    "    \n",
    "    print(\"Saving velocity histograms on\\n\",save_path_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if vel_hist_bool:\n",
    "    MP.plot_velocity_histograms_both_stats(df[(df[pop_var]>=min(pop_min_range))&(df[pop_var]<=min(pop_max_range))],vel_x_variable,vel_y_variable,\\\n",
    "                                           bins=velhist_bins,colour_var=\"x\",save_bool=False,suffix=\"example\",verbose=True,show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = {}\n",
    "for map_string in full_map_string_list:\n",
    "    map_dict[map_string] = np.zeros(shape=(len(pop_min_range)))\n",
    "    \n",
    "map_dict[\"mean_b\"] = np.zeros(shape=(len(pop_min_range)))\n",
    "map_dict[\"std_b\"] = np.zeros(shape=(len(pop_min_range)))\n",
    "\n",
    "for pop_index, (popmin, popmax) in enumerate(zip(pop_min_range,pop_max_range)):\n",
    "\n",
    "    print(popmin,popmax)\n",
    "    \n",
    "    include_lims = \"both\" if pop_index==len(pop_min_range)-1 else \"min\"\n",
    "    df_pop = MF.apply_cuts_to_df(df, cuts_dict={pop_var:[popmin,popmax]}, lims_dict={pop_var:include_lims})\n",
    "        \n",
    "    if vel_hist_bool:\n",
    "        name_suffix = f\"{str(MF.return_int_or_dec(popmin,dec=2))}pop{str(MF.return_int_or_dec(popmax,dec=2))}\"\n",
    "        MP.plot_velocity_histograms_both_stats(df_pop,vel_x_variable,vel_y_variable,save_bool=True,save_path=save_path_hist,suffix=name_suffix,verbose=pop_index==0,bins=velhist_bins)\n",
    "        \n",
    "    values = val_err.get_all_variable_values_and_errors(df_pop[f\"v{vel_x_variable}\"].values,df_pop[f\"v{vel_y_variable}\"].values, full_map_string_list,\\\n",
    "                                                            repeat=bootstrap_repeat, min_number = min_star_number)   \n",
    "\n",
    "    if len(values) != len(full_map_string_list):\n",
    "        raise ValueError(\"The length of the values list does not match the string list!\")\n",
    "\n",
    "    for map_string in full_map_string_list:\n",
    "        map_dict[map_string][pop_index] = values[map_string]\n",
    "        \n",
    "    map_dict[\"mean_b\"][pop_index] = np.mean(df_pop[\"b\"])\n",
    "    map_dict[\"std_b\"][pop_index] = np.std(df_pop[\"b\"])\n",
    "    \n",
    "del df_pop\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(map_dict['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save arrays\n",
    "\n",
    "array_path = save_path + \"arrays/\"\n",
    "MF.create_dir(array_path)\n",
    "\n",
    "if True: # values as .txt and .npy\n",
    "            \n",
    "    with open(array_path+'values.txt','w') as f:\n",
    "        for key in map_dict:\n",
    "            f.write(key+'\\n')\n",
    "            np.savetxt(f,map_dict[key],fmt='%.5f')\n",
    "            f.write('\\n')\n",
    "    \n",
    "    for map_string in full_map_string_list:\n",
    "        np.save(array_path+map_string, map_dict[map_string])\n",
    "        \n",
    "if True: # plot limits as .txt and .npy\n",
    "\n",
    "    with open(array_path+'pop_ranges.txt','w') as f:\n",
    "        f.write(\"pop_min_range\\n\")\n",
    "        for mini in pop_min_range:\n",
    "            f.write(f\"{mini}\\t\")\n",
    "        f.write(\"\\n\\npop_max_range\\n\")\n",
    "        for maxi in pop_max_range:\n",
    "            f.write(f\"{maxi}\\t\")\n",
    "        f.write(\"\\n\\npop_plot_range\\n\")\n",
    "        for p in pop_plot_range:\n",
    "            f.write(f\"{p}\\t\")\n",
    "    \n",
    "    np.save(array_path+\"pop_min_range\", pop_min_range)\n",
    "    np.save(array_path+\"pop_max_range\", pop_max_range)\n",
    "    np.save(array_path+\"pop_plot_range\", pop_plot_range)\n",
    "    \n",
    "print(\"Saved .txt and .npy in\",array_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POPPLOT functions\n",
    "\n",
    "# Takes global: bar_log, bar_width\n",
    "def POPPLOT_number_bar(barax, plot_range, number_array,color,alpha=1,zorder=0, bar_width=50):\n",
    "    barax.bar(plot_range,number_array,width=bar_width,log=bar_log,color=color,alpha=alpha,zorder=zorder)\n",
    "        \n",
    "def POPPLOT_values_scatter(ax, val_array, err_array, plot_range, min_range, max_range, color, label,line_alpha=1,zorder=0,lines_bool=True,x_error_bool=True):\n",
    "    xerror = PH.get_xerr(min_range,max_range,plot_range)\n",
    "\n",
    "    ax.errorbar(plot_range,val_array,yerr=err_array,xerr=xerror if x_error_bool else None,capsize=capsize,marker='.',color=color,\\\n",
    "                label=label,linestyle=None if lines_bool else '',alpha=line_alpha,zorder=zorder)\n",
    "\n",
    "def POPPLOT_values_surface(ax, val_array, err_array, plot_range,color,label,line_alpha=1,surface_alpha=0.75,zorder=0):\n",
    "    ax.plot(plot_range,val_array,color=color,alpha=line_alpha,zorder=zorder)\n",
    "    ax.fill_between(plot_range,val_array-err_array,val_array+err_array,label=label,color=color,alpha=surface_alpha,linewidth=0,zorder=zorder)\n",
    "        \n",
    "def POPPLOT_number_bar_axis_settings(barax,min_n,max_n,bar_log=True,labels_on=True,min_shift_bool=True,max_shift_bool=True):\n",
    "    if bar_log:\n",
    "        exponent_ticks = np.arange(MF.get_exponent(min_n),MF.get_exponent(max_n)+1,1)\n",
    "        barax.set_yticks([10**i for i in exponent_ticks])\n",
    "        barax.set_ylim(bottom = 10**min(exponent_ticks) - (min_n/3 if min_shift_bool else 0))\n",
    "        barax.set_ylim(top = max_n + (10**MF.get_exponent(max_n) if max_shift_bool else 0))\n",
    "    elif equal_number:\n",
    "        barax.set_yticks([0,max_n])\n",
    "            \n",
    "    barax.yaxis.set_tick_params(which='minor', right=True,left=False)\n",
    "\n",
    "    barax.tick_params(which='both',labelleft=False,labelright=labels_on)\n",
    "    barax.tick_params(which='minor',labelright=False)\n",
    "\n",
    "    if labels_on:\n",
    "        barax.set_ylabel(r\"$N$\",rotation=0,labelpad=20)\n",
    "        barax.yaxis.set_label_position(\"right\")\n",
    "    \n",
    "def POPPLOT_xaxis_settings(ax,xmin,xmax,xlabel,xticks=None,labels_on=True):\n",
    "#     ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.25))\n",
    "    \n",
    "    ax.set_xlim(xmin,xmax)\n",
    "    \n",
    "    if xticks is not None:\n",
    "        ax.set_xticks(xticks)\n",
    "    \n",
    "    if labels_on:\n",
    "        ax.set_xlabel(xlabel)\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "def _POPPLOT_compute_ylims(map_dict, map_string, error_string, var1_bool=False):\n",
    "    minimum = np.nanmin(map_dict[map_string]-map_dict[error_string])\n",
    "    maximum = np.nanmax(map_dict[map_string]+map_dict[error_string])\n",
    "\n",
    "    if var1_bool:\n",
    "        minimum1 = np.nanmin(map_dict[var1]-map_dict[err1])\n",
    "        maximum1 = np.nanmax(map_dict[var1]+map_dict[err1])\n",
    "\n",
    "        minimum = min([minimum,minimum1])\n",
    "        maximum = max([maximum,maximum1])\n",
    "    \n",
    "    if map_string in yshift_dict:\n",
    "        minimum -= yshift_dict[map_string]\n",
    "        maximum += yshift_dict[map_string]\n",
    "\n",
    "    if symmetric_ylims_bool:\n",
    "        maxabs = np.nanmax(np.abs([minimum,maximum]))\n",
    "        ax.set_ylim(-maxabs,maxabs)\n",
    "    else:\n",
    "        ax.set_ylim(minimum,maximum)\n",
    "        \n",
    "def POPPLOT_yaxis_settings(ax, map_string, error_string, map_dict=None, labels_on=True,var1_bool=False, set_ylims=True):\n",
    "    \n",
    "    if map_string == 'tilt_abs':# or \"mean\" in map_string or \"std\" in map_string:\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(20))\n",
    "        #ax.yaxis.set_minor_locator(ticker.MultipleLocator(5))\n",
    "    elif map_string == 'anisotropy':# or map_string == 'correlation':\n",
    "#         ax.yaxis.set_major_locator(ticker.MultipleLocator(0.25))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "        ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.25))\n",
    "    elif map_string == \"correlation\":\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(0.15))\n",
    "#     elif map_string in [\"mean_vx\",\"mean_vy\"]:\n",
    "#         ax.yaxis.set_major_locator(ticker.MultipleLocator(15))\n",
    "    elif map_string in [\"std_vx\",\"std_vy\"]:\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "    \n",
    "    if not var1_bool and labels_on:\n",
    "        ax.set_ylabel(symbol_dict[map_string]+units_dict[map_string],fontsize=ylabel_size)\n",
    "    \n",
    "    if set_ylims:\n",
    "        if hard_coded_ylims_bool and map_string in hard_coded_ylims:\n",
    "            ax.set_ylim(hard_coded_ylims[map_string])\n",
    "        else:\n",
    "            if map_dict is None:\n",
    "                raise ValueError(\"Cannot compute ylims if `map_dict` is None.\")\n",
    "            _POPPLOT_compute_ylims(map_dict, map_string, error_string, var1_bool=var1_bool)\n",
    "        \n",
    "    if not labels_on:\n",
    "        ax.set_yticklabels([])\n",
    "        \n",
    "def get_label(map_string):\n",
    "    return symbol_dict[map_string]+units_dict[map_string]\n",
    "\n",
    "def get_legend_label(var_tuple,variable):\n",
    "    var_symbol = pos_symbols_dict[variable]\n",
    "    var_units = pos_units_dict[variable]\n",
    "    \n",
    "    if var_tuple[0] == 0:\n",
    "        return var_symbol + fr\"$< {var_tuple[1]}~$\"+var_units\n",
    "    else:\n",
    "        return r\"$%s<$\"%str(var_tuple[0]) + var_symbol + r\"$/\\mathrm{%s}$\"%var_units + fr\"$<{var_tuple[1]}$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsize = 5\n",
    "ylabel_size = \"medium\"\n",
    "\n",
    "data_xerror_bool = True\n",
    "# data_xerror_bool = False\n",
    "\n",
    "# bar_log = True\n",
    "bar_log = False\n",
    "# bar_log = not data_bool\n",
    "\n",
    "data_lines_bool = True\n",
    "# data_lines_bool = False\n",
    "\n",
    "# data_surface_bool = True\n",
    "data_surface_bool = False\n",
    "\n",
    "sim_surface_bool = True\n",
    "# sim_surface_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponent_ticks = [1,2,3] if data_bool else [3,4,5]\n",
    "xlabel = \"[Fe/H]\" if data_bool else \"Age [Gyr]\"\n",
    "\n",
    "line_alpha = 0.75\n",
    "surface_alpha = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'mean_vx';        var1_bool=True\n",
    "# var = 'anisotropy';     var1_bool=True\n",
    "# var = \"std_vx\";         var1_bool=True\n",
    "# var = 'tilt_abs';       var1_bool=False\n",
    "\n",
    "err = var + \"_error\"\n",
    "\n",
    "print(var,err)\n",
    "\n",
    "color = 'steelblue'\n",
    "if var1_bool:\n",
    "    color = 'purple'\n",
    "    color1 = 'orange'\n",
    "    \n",
    "    if var == 'anisotropy': var1 = 'correlation'\n",
    "    elif \"vx\" in var: var1 = var.split(\"vx\")[0] + \"vy\" + var.split(\"vx\")[1]\n",
    "    else: raise ValueError(\"Could not determine var1\")\n",
    "    \n",
    "    err1 = var1+'_error'\n",
    "    \n",
    "    print(var1,err1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard_coded_ylims_bool = True\n",
    "hard_coded_ylims_bool = False\n",
    "# hard_coded_ylims_bool = var == \"tilt_abs\"\n",
    "\n",
    "# symmetric_ylims_bool = True\n",
    "symmetric_ylims_bool = False\n",
    "\n",
    "hard_coded_ylims = {\n",
    "    \"tilt_abs\": [-45,3]\n",
    "}\n",
    "\n",
    "yshift_dict = {\n",
    "    \"anisotropy\": 0.01,\n",
    "    \"tilt_abs\": 5,\n",
    "    \"mean_b\": 0.25,\n",
    "    \"std_vx\": 1,\n",
    "    \"mean_vx\": 1\n",
    "}\n",
    "\n",
    "legend_loc = \"best\"\n",
    "# legend_loc = \"upper left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "if True: # fig, bar, axhline\n",
    "    fig,(barax,ax) = plt.subplots(figsize=(10,10),nrows=2,ncols=1, sharex=True,facecolor='w',gridspec_kw={'hspace':0,'height_ratios':[0.15,1]})\n",
    "\n",
    "    POPPLOT_number_bar(barax, pop_plot_range, map_dict[\"number\"],color=\"grey\",alpha=line_alpha)\n",
    "    POPPLOT_number_bar_axis_settings(barax,min_n=np.min(map_dict[\"number\"]),max_n=np.max(map_dict[\"number\"]))\n",
    "\n",
    "if True: # plot\n",
    "    \n",
    "    if data_bool or not sim_surface_bool:\n",
    "        POPPLOT_values_data(ax, map_dict[var], map_dict[err], pop_plot_range, pop_min_range, pop_max_range,color,get_label(var),alpha=line_alpha)\n",
    "    else:\n",
    "        POPPLOT_values_sim(ax,map_dict[var],map_dict[err],pop_plot_range,color,get_label(var),line_alpha=line_alpha,surface_alpha=surface_alpha)\n",
    "\n",
    "    if var1_bool: # var1, legend\n",
    "        if data_bool or not sim_surface_bool:\n",
    "            POPPLOT_values_data(ax, map_dict[var1], map_dict[err1], pop_plot_range, pop_min_range, pop_max_range,color1,get_label(var1),alpha=line_alpha)\n",
    "        else:\n",
    "            POPPLOT_values_sim(ax,map_dict[var1],map_dict[err1],pop_plot_range,color1,get_label(var1),line_alpha=line_alpha,surface_alpha=surface_alpha)\n",
    "\n",
    "        ax.legend(loc=legend_loc)\n",
    "        \n",
    "    if True: # zero line\n",
    "        minima = [np.nanmin(map_dict[var]-map_dict[err])]\n",
    "        maxima = [np.nanmax(map_dict[var]+map_dict[err])]\n",
    "        if var1_bool:\n",
    "            minima.append(np.nanmin(map_dict[var1]-map_dict[err1]))\n",
    "            maxima.append(np.nanmax(map_dict[var1]+map_dict[err1]))\n",
    "            \n",
    "        zero_line_within_lims = False\n",
    "        if hard_coded_ylims_bool and var in hard_coded_ylims:\n",
    "            zero_line_within_lims = hard_coded_ylims[var][0] < 0 and hard_coded_ylims[var][1] > 0\n",
    "            \n",
    "        zero_line_within_lims_1 = False\n",
    "        if var1_bool and hard_coded_ylims_bool and var1 in hard_coded_ylims:\n",
    "            zero_line_within_lims_1 = hard_coded_ylims[var1][0] < 0 and hard_coded_ylims[var1][1] > 0\n",
    "        \n",
    "        if zero_line_within_lims or zero_line_within_lims_1 or PH.shall_plot_zero_line(minima,maxima):\n",
    "            ax.axhline(y=0,linestyle='--',color='grey')\n",
    "\n",
    "if True: # axis\n",
    "    POPPLOT_xaxis_settings(ax,xmin=min(pop_min_range),xmax=max(pop_max_range),xlabel=xlabel)\n",
    "    POPPLOT_yaxis_settings(ax,var,err,map_dict,var1_bool=var1_bool)\n",
    "    \n",
    "    if not data_bool:\n",
    "        ax.invert_xaxis()\n",
    "\n",
    "if True: # save\n",
    "\n",
    "    filename = var\n",
    "    if var1_bool: filename += var1\n",
    "\n",
    "    if filename == 'anisotropycorrelation': filename = 'anicorr'\n",
    "    elif filename == 'mean_vxmean_vy': filename = 'vel'\n",
    "\n",
    "    if data_bool and data_lines_bool:\n",
    "        filename += \"_lines\"\n",
    "\n",
    "    if bootstrap_repeat != 500:\n",
    "        filename += f'_boot{bootstrap_repeat}'\n",
    "\n",
    "    print(filename)\n",
    "\n",
    "    if save_bool:\n",
    "        for formatting in ['.png','.pdf']:\n",
    "            plt.savefig(save_path+filename+formatting,bbox_inches='tight',dpi=300)\n",
    "        print(\"Saved in\",save_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metal_poor = data_extra[(data_extra['FeH']>-1) & (data_extra['FeH'] < -0.5)]\n",
    "vr = metal_poor.vr.values\n",
    "vl = metal_poor.vl.values\n",
    "\n",
    "velocity_plot.velocity_plot(vr,vl,tilt_abs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimise cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_corr(plim,rlim,lowlim=data_extra['FeH'].min(),highlim=0.3):\n",
    "    left_pop = data_extra[(data_extra['FeH']>lowlim)&(data_extra['FeH']<plim)]\n",
    "    centre_pop = data_extra[(data_extra['FeH']>plim)&(data_extra['FeH']<rlim)]\n",
    "    right_pop = data_extra[(data_extra['FeH']>rlim)&(data_extra['FeH']<highlim)]\n",
    "\n",
    "    left_corr = CV.calculate_correlation(left_pop.vr.values,left_pop.vl.values)\n",
    "    centre_corr = CV.calculate_correlation(centre_pop.vr.values,centre_pop.vl.values)\n",
    "    right_corr = CV.calculate_correlation(right_pop.vr.values,right_pop.vl.values)\n",
    "    \n",
    "    return left_corr,centre_corr,right_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowlim = data_extra['FeH'].min()\n",
    "highlim = 0.3\n",
    "\n",
    "# Initial guesses\n",
    "plim = -0.5\n",
    "rlim = -0.2\n",
    "\n",
    "step = 0.1\n",
    "combinations = [[i,j] for i in [-step,0,step] for j in [-step,0,step]]\n",
    "\n",
    "l,c,r = compute_corr(plim,rlim) # We want largest l, lowest |c|, lowest r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "\n",
    "while iterations:    \n",
    "    \n",
    "    for comb in combinations:\n",
    "        new_plim = plim+comb[0]\n",
    "        new_rlim = rlim+comb[1]\n",
    "        new_l,new_c,new_r = compute_corr(new_plim,new_rlim)\n",
    "        \n",
    "        if new_l > l and abs(new_c) < abs(c) and new_r < r:\n",
    "            plim,rlim = new_plim,new_rlim\n",
    "            l,c,r = new_l,new_c,new_r\n",
    "        elif new_l > l and abs(new_c) < abs(c):\n",
    "            plim = new_plim\n",
    "            l,c = new_l,new_c\n",
    "        elif abs(new_c) < abs(c) and new_r < r:\n",
    "            rlim = new_rlim\n",
    "            c,r = new_c,new_r\n",
    "        \n",
    "        #print(\"%.4f\\t%.4f\"%(plim, rlim))\n",
    "        \n",
    "    iterations -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plim, rlim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_pop = data_extra[(data_extra['FeH']>lowlim)&(data_extra['FeH']<plim)]\n",
    "centre_pop = data_extra[(data_extra['FeH']>plim)&(data_extra['FeH']<rlim)]\n",
    "right_pop = data_extra[(data_extra['FeH']>rlim)&(data_extra['FeH']<highlim)]\n",
    "\n",
    "for pop in [left_pop,centre_pop,right_pop]:\n",
    "    velocity_plot.velocity_plot(pop.vr.values,pop.vl.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sim & data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can't be used the same way as in the latitude plots because currently the code is run mutually exclusive way for data or sim. As a consequence, here we will load everything, including the main plot\n",
    "* Run all the code above for the variations you want, in order to save the arrays\n",
    "* The code below will load the main plot and the shadows, and create the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: currently I can only plot at the median if pop_plot_range.npy is saved at median values, as it requires having the whole array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_units_dict[\"b\"] = \"deg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_var_tuple_str(variable,var_tuple):\n",
    "    if len(var_tuple) == 1:\n",
    "        return f\"{variable}{MF.return_int_or_dec(var_tuple[0],2)}\"\n",
    "    elif len(var_tuple) > 2:\n",
    "        return f\"{variable}\" + \",\".join([str(MF.return_int_or_dec(v,2)) for v in var_tuple])\n",
    "    else:\n",
    "        return f\"{MF.return_int_or_dec(var_tuple[0],2)}{variable}{MF.return_int_or_dec(var_tuple[1],2)}\"\n",
    "\n",
    "def get_variation_str(var,all_value_tuples):\n",
    "    var_str = \"\"\n",
    "\n",
    "    for val_tuple in all_value_tuples:\n",
    "        var_str += get_var_tuple_str(var,val_tuple) + \"_\"\n",
    "    \n",
    "    return var_str.removesuffix(\"_\") + \"/\"\n",
    "\n",
    "def get_save_path_POPPLOT_both(save_path,extra_var,depth_var,height_var,sim_bool=True,data_bool=True,binning_str_sim=None,binning_str_data=None,pop_str_data=None,\\\n",
    "                               pop_str_sim=None,extra_min=None,extra_max=None,depth_min=None,depth_max=None,height_min=None,height_max=None,all_variations_dict=None):\n",
    "        \n",
    "    for var,m,M in zip([extra_var,depth_var,height_var],[extra_min,depth_min,height_min],[extra_max,depth_max,height_max]):\n",
    "        save_path += get_variation_str(var,all_variations_dict[var]) if var in all_variations_dict else get_var_tuple_str(var,[m,M])+\"/\"\n",
    "        MF.create_dir(save_path)\n",
    "    \n",
    "    save_path += \"both/\"\n",
    "    MF.create_dir(save_path)\n",
    "    \n",
    "    if data_bool:\n",
    "        save_path += f\"data_{binning_str_data}/\"\n",
    "        MF.create_dir(save_path)\n",
    "\n",
    "        save_path += \"data_\"+get_variation_str(\"n\",all_variations_dict[\"n_data\"]) if \"n_data\" in all_variations_dict else f\"data_{pop_str_data}/\"\n",
    "        MF.create_dir(save_path)\n",
    "    \n",
    "    if sim_bool:\n",
    "        save_path += f\"sim_{binning_str_sim}/\"\n",
    "        MF.create_dir(save_path)\n",
    "\n",
    "        save_path += \"sim_\"+get_variation_str(\"n\",all_variations_dict[\"n_sim\"]) if \"n_sim\" in all_variations_dict else f\"sim_{pop_str_sim}/\"\n",
    "        MF.create_dir(save_path)\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_values_and_plot_ranges(path,full_map_string_list):\n",
    "    \n",
    "    map_dict = {}\n",
    "    for m in full_map_string_list:\n",
    "        map_dict[m] = np.load(f\"{path}{m}.npy\")\n",
    "    \n",
    "    min_range = np.load(path + f\"pop_min_range.npy\")\n",
    "    max_range = np.load(path + f\"pop_max_range.npy\")\n",
    "    plot_range = np.load(path + f\"pop_plot_range.npy\")\n",
    "    \n",
    "    return map_dict, min_range, max_range, plot_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_variable_lims = {\n",
    "    \"l\": [-2,2],\n",
    "    \"y\": [coordinates.ang_to_rect(ang=-2,x=coordinates.get_solar_radius()), coordinates.ang_to_rect(ang=2,x=coordinates.get_solar_radius())]\n",
    "}\n",
    "\n",
    "overall_height_variable_lims = {\n",
    "    \"b\": [1.5,9],\n",
    "    \"z\": [coordinates.ang_to_rect(ang=1.5,x=coordinates.get_solar_radius()), coordinates.ang_to_rect(ang=9,x=coordinates.get_solar_radius())]\n",
    "}\n",
    "\n",
    "extra_variable_lims = {\n",
    "    \"d\": [6.1,10.1],\n",
    "    \"R\": [0,3.5]\n",
    "}\n",
    "\n",
    "# CHOOSE variables for selection\n",
    "# extra_variable = \"d\"\n",
    "extra_variable = \"R\"\n",
    "depth_var = \"l\"\n",
    "height_var = \"b\"\n",
    "\n",
    "if True: # print\n",
    "    depth_min,depth_max = depth_variable_lims[depth_var]\n",
    "    overall_height_min,overall_height_max = overall_height_variable_lims[height_var]\n",
    "    extra_min,extra_max = extra_variable_lims[extra_variable]\n",
    "    \n",
    "    print(depth_var,depth_min,depth_max)\n",
    "    print(height_var,overall_height_min,overall_height_max)\n",
    "    print(extra_variable,extra_min,extra_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://colorbrewer2.org/#type=qualitative&scheme=Dark2&n=3\n",
    "\n",
    "# colors = [\"blue\",\"blue\",\"blue\"]\n",
    "colors = [\"#1b9e77\",\"#d95f02\",\"#7570b3\"]\n",
    "\n",
    "line_alpha = 0.9\n",
    "surface_alpha = 0.75\n",
    "alpha_reduction_factor = 0.25\n",
    "\n",
    "number_alpha = surface_alpha\n",
    "number_alpha_reduction_factor = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_str_data = \"equalN\"\n",
    "binning_str_sim = \"equalN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_first = True\n",
    "# current_first = False\n",
    "\n",
    "# current_first_N = True\n",
    "current_first_N = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bool = True\n",
    "# data_bool = False\n",
    "\n",
    "sim_bool = True\n",
    "# sim_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # height_variations\n",
    "\n",
    "    height_range_min,height_range_max = PH.get_equal_n_minmax_b_ranges(data_trim, n_points=3,\\\n",
    "                                                                 extra_variable=extra_variable,extra_min=extra_min,extra_max=extra_max,\\\n",
    "                                                                 depth_min=depth_variable_lims[\"l\"][0],depth_max=depth_variable_lims[\"l\"][1],\\\n",
    "                                                                 overall_bmin=overall_height_variable_lims[\"b\"][0],overall_bmax=overall_height_variable_lims[\"b\"][1])\n",
    "    \n",
    "    if height_var == \"z\":\n",
    "        height_range_min = [coordinates.ang_to_rect(ang=bmin,x=coordinates.get_solar_radius()) for bmin in height_range_min]\n",
    "        height_range_max = [coordinates.ang_to_rect(ang=bmax,x=coordinates.get_solar_radius()) for bmax in height_range_max]\n",
    "    \n",
    "    if True: # choose parameters\n",
    "        extra_variations = [[0,3.5],[0,2]]\n",
    "        height_variations = [[MF.return_int_or_dec(m,2),MF.return_int_or_dec(M,2)] for (m,M) in zip(height_range_min,height_range_max)]\n",
    "\n",
    "        n_extra_var,n_height_var = len(extra_variations),len(height_variations)\n",
    "\n",
    "        if data_bool:\n",
    "            n_data = 4\n",
    "            n_variations_data = n_extra_var*[[n_data,n_data,n_data-1]]\n",
    "            metal_str_variations = [[f\"{x}_datapoints\" for x in n_variations_data[i]] for i in range(len(n_variations_data))]\n",
    "\n",
    "        if sim_bool:\n",
    "            if sim_resampled_bool:\n",
    "                n_variations_sim = n_variations_data\n",
    "            else:\n",
    "                n_sim = 20\n",
    "                n_variations_sim = n_extra_var*[[n_sim,n_sim,n_sim-5]]\n",
    "            age_str_variations = [[f\"{x}_datapoints\" for x in n_variations_sim[i]] for i in range(len(n_variations_sim))]\n",
    "\n",
    "        all_colors = n_extra_var*[colors]\n",
    "        line_alphas = [n_height_var*[line_alpha], n_height_var*[line_alpha*alpha_reduction_factor]]\n",
    "        surface_alphas = [n_height_var*[surface_alpha], n_height_var*[surface_alpha*alpha_reduction_factor]]\n",
    "        number_alphas = [n_height_var*[number_alpha], n_height_var*[number_alpha*number_alpha_reduction_factor]]\n",
    "\n",
    "        z_orders = [[len(extra_variations)*len(height_variations)-i + (-j if current_first else j) for j in range(len(height_variations))]\\\n",
    "                     for i in np.arange(0,len(extra_variations)*len(height_variations),len(height_variations))]\n",
    "        z_orders_N = [[len(extra_variations)*len(height_variations)-i + (-j if current_first_N else j) for j in range(len(height_variations))]\\\n",
    "                       for i in np.arange(0,len(extra_variations)*len(height_variations),len(height_variations))]\n",
    "    \n",
    "    all_dicts = []\n",
    "    \n",
    "    for i,(em,eM) in enumerate(extra_variations):\n",
    "        for j,(hm,hM) in enumerate(height_variations):\n",
    "            \n",
    "            current_dict = {\n",
    "                \"color\":all_colors[i][j],\n",
    "                \"line_alpha\":line_alphas[i][j],\n",
    "                \"surface_alpha\":surface_alphas[i][j],\n",
    "                \"number_alpha\":number_alphas[i][j],\n",
    "                \"zorder\": z_orders[i][j],\n",
    "                \"zorderN\": z_orders_N[i][j],\n",
    "                \"label_sim\": get_legend_label([hm,hM],height_var) if i==0 else None,\n",
    "                \"label_data\": None\n",
    "            }\n",
    "            \n",
    "            if data_bool:\n",
    "                spatial_path = get_save_path_POPPLOT_spatial_cuts(resampled_sim_bool=False,\\\n",
    "                                                                  extra_variable=extra_variable,extra_min=em,extra_max=eM,\\\n",
    "                                                                  depth_var=depth_var,depth_min=depth_min,depth_max=depth_max,\\\n",
    "                                                                  height_var=height_var,height_min=hm,height_max=hM)\n",
    "                \n",
    "                load_path_data = get_save_path_POPPLOT_data(save_path_spatial=spatial_path, binning_str=binning_str_data,\\\n",
    "                                                        pop_str=metal_str_variations[i][j]) + \"arrays/\"\n",
    "                current_dict[\"load_path_data\"] = load_path_data\n",
    "                \n",
    "            if sim_bool:\n",
    "                spatial_path = get_save_path_POPPLOT_spatial_cuts(resampled_sim_bool=sim_resampled_bool,\\\n",
    "                                                                  extra_variable=extra_variable,extra_min=em,extra_max=eM,\\\n",
    "                                                                  depth_var=depth_var,depth_min=depth_min,depth_max=depth_max,\\\n",
    "                                                                  height_var=height_var,height_min=hm,height_max=hM)\n",
    "                \n",
    "                load_path_sim = get_save_path_POPPLOT_sim(save_path_spatial=spatial_path, binning_str=binning_str_sim,\\\n",
    "                                                      pop_str=age_str_variations[i][j]) + \"arrays/\"\n",
    "                current_dict[\"load_path_sim\"] = load_path_sim\n",
    "            \n",
    "            all_dicts.append(current_dict)\n",
    "            \n",
    "    all_variations_dict = {extra_variable:extra_variations,height_var:height_variations}\n",
    "    if data_bool:\n",
    "        all_variations_dict[\"n_data\"] = n_variations_data\n",
    "    if sim_bool:\n",
    "        all_variations_dict[\"n_sim\"] = n_variations_sim\n",
    "    \n",
    "    save_path = get_save_path_POPPLOT_both(save_path=get_base_path(sim_resampled_bool),\\\n",
    "                                           extra_var=extra_variable,depth_var=depth_var,height_var=height_var,\\\n",
    "                                           binning_str_sim=binning_str_sim,binning_str_data=binning_str_data,\\\n",
    "                                           depth_min=depth_min,depth_max=depth_max,\\\n",
    "                                           all_variations_dict=all_variations_dict,\n",
    "                                           data_bool=data_bool,sim_bool=sim_bool)\n",
    "\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sim_bool:\n",
    "    for dicts in all_dicts:\n",
    "        print(dicts[\"load_path_sim\"])\n",
    "\n",
    "if data_bool:\n",
    "    print(\"\\n\")\n",
    "    for dicts in all_dicts:\n",
    "        print(dicts[\"load_path_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_surface_bool = True\n",
    "# sim_surface_bool = False\n",
    "\n",
    "data_surface_bool = True\n",
    "# data_surface_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# everything below only takes effect if surface_bool is False\n",
    "\n",
    "capsize = 5\n",
    "\n",
    "data_xerror_bool = True\n",
    "# data_xerror_bool = False\n",
    "data_lines_bool = True\n",
    "# data_lines_bool = False\n",
    "\n",
    "sim_xerror_bool = True\n",
    "# sim_xerror_bool = False\n",
    "sim_lines_bool = True\n",
    "# sim_lines_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_title = \"Model\"\n",
    "# data_title = \"Data\"\n",
    "\n",
    "sim_title = \"Galactic spatial cuts\"\n",
    "data_title = \"Rectangular spatial cuts\"\n",
    "\n",
    "\n",
    "sim_xlabel = r\"Age [Gyr]\"\n",
    "# data_xlabel = \"[Fe/H]\"\n",
    "data_xlabel = r\"Age [Gyr]\"\n",
    "\n",
    "invert_sim_xaxis = True\n",
    "invert_data_xaxis = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot at the median we can only get the plotting locations from pop_plot_range.npy (assuming it was saved at the median) as they require having the full array\n",
    "\n",
    "data_plot_range_str = \"mean\"\n",
    "# data_plot_range_str = \"median\"\n",
    "\n",
    "sim_plot_range_str = \"mean\"\n",
    "# sim_plot_range_str = \"median\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_bool = True\n",
    "# number_bool = False\n",
    "\n",
    "bar_log = True\n",
    "# bar_log = False\n",
    "\n",
    "# number_variations_bool = True\n",
    "number_variations_bool = False\n",
    "\n",
    "idx_variations_begin = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_coded_ylims_bool = True # currently needed to ensure the y axis is shared correctly\n",
    "# hard_coded_ylims_bool = False\n",
    "\n",
    "# symmetric_ylims_bool = True\n",
    "symmetric_ylims_bool = False\n",
    "\n",
    "hard_coded_ylims = {\n",
    "    \"tilt_abs\": [-45,3],\n",
    "}\n",
    "\n",
    "yshift_dict = {\n",
    "    \"tilt_abs\": 2,\n",
    "    \"anisotropy\": 0.02,\n",
    "    \"correlation\": 0.01,\n",
    "    \"mean_vx\": 1,\n",
    "    \"mean_vy\": 1,\n",
    "    \"std_vx\": 2,\n",
    "    \"std_vy\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_row = 1\n",
    "# legend_row = len(map_list)\n",
    "\n",
    "# legend_loc = \"best\"; ncols_leg=1\n",
    "# legend_loc = \"lower left\"; ncols_leg=1\n",
    "\n",
    "if sim_bool and data_bool:\n",
    "    legend_loc = (0.25,1.25 if not number_bool else 1.65); ncols_leg=len(colors)\n",
    "else:\n",
    "    legend_loc = (-0.25,1.05 if not number_bool else 1.45); ncols_leg=len(colors)\n",
    "\n",
    "# legend_bool = True\n",
    "legend_bool = False\n",
    "\n",
    "# legend_data_bool = True\n",
    "legend_data_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_line_color = \"grey\"\n",
    "zero_line_alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 22\n",
    "ylabel_size = 24\n",
    "legend_fontsize = 15.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_x = 15\n",
    "\n",
    "# figsize_y = 14/3*0.9*len(map_list)\n",
    "figsize_y = 1.41*figsize_x # aspect ratio of A4\n",
    "\n",
    "figsize_x /= 2 if sim_bool+data_bool == 1 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\",\"anisotropy\",\"correlation\",\"tilt_abs\"]; map_list_string = \"all\"\n",
    "# map_list = [\"anisotropy\",\"correlation\",\"tilt_abs\"]; map_list_string = \"anicorrtilt\"\n",
    "# map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\"]; map_list_string = \"velmeanstd\"\n",
    "# map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\",\"anisotropy\"]; map_list_string = \"meanstdani\"\n",
    "# map_list = [\"std_vx\",\"std_vy\",\"anisotropy\"]; map_list_string = \"stdani\"\n",
    "# map_list = [\"mean_vx\",\"mean_vy\"]; map_list_string = \"velmeans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_suffix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/luismi/Desktop/MRes_UCLan/graphs/Observations/Apogee/individual_variable/age_metal/0R3.5_0R2/-2l2__-0.28y0.28/\"+\\\n",
    "            \"1.5b3.51_3.51b6.6_7.13b8.85__0.21z0.5_0.5z0.94_1.01z1.26/sim/sim_equalN/sim_n20,20,15_n20,20,15__n20,20,15_n20,20,15/\"\n",
    "\n",
    "os.makedirs(save_path,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "fig,axs = plt.subplots(figsize=(figsize_x,figsize_y),nrows=len(map_list)+1,ncols=sim_bool+data_bool, facecolor='w',\\\n",
    "                       gridspec_kw={'hspace':0,'wspace':0,'height_ratios':[0.35]+len(map_list)*[1]})\n",
    "\n",
    "if True: # select axes\n",
    "    if sim_bool and data_bool: \n",
    "        sim_axes,data_axes = axs[:,0], axs[:,1]\n",
    "    elif sim_bool:\n",
    "        sim_axes = axs\n",
    "    elif data_bool:\n",
    "        data_axes = axs\n",
    "    else:\n",
    "        raise ValueError(\"Both sim_bool and data_bool were set to False...\")\n",
    "\n",
    "if number_bool: # title and number bars\n",
    "    if sim_bool and data_bool:\n",
    "        sim_axes[0].set_title(sim_title)\n",
    "        data_axes[0].set_title(data_title)\n",
    "    \n",
    "    bar_n_min,bar_n_max = [10**30],[0]\n",
    "    \n",
    "    for i,d in enumerate(all_dicts):\n",
    "        if not number_variations_bool and i >= idx_variations_begin:\n",
    "            break\n",
    "        \n",
    "        if sim_bool:\n",
    "            map_dict,min_range,max_range,plot_range = load_values_and_plot_ranges(d[\"load_path_sim\"],full_map_string_list)\n",
    "            plot_range = PH.get_range_means(min_range,max_range)\n",
    "            POPPLOT_number_bar(sim_axes[0], plot_range, map_dict[\"number\"],color=d[\"color\"],alpha=d[\"number_alpha\"],zorder=d[\"zorderN\"])\n",
    "            \n",
    "            bar_n_min = min(bar_n_min, np.min(map_dict[\"number\"]))\n",
    "            bar_n_max = max(bar_n_max, np.max(map_dict[\"number\"]))\n",
    "        \n",
    "        if data_bool:\n",
    "            o_map_dict,o_min_range,o_max_range,o_plot_range = load_values_and_plot_ranges(d[\"load_path_data\"],full_map_string_list)\n",
    "            o_plot_range = o_plot_range if data_plot_range_str==\"median\" else PH.get_range_means(o_min_range,o_max_range)\n",
    "            POPPLOT_number_bar(data_axes[0], o_plot_range, o_map_dict[\"number\"],color=d[\"color\"],alpha=d[\"number_alpha\"],zorder=d[\"zorderN\"])\n",
    "    \n",
    "            bar_n_min = min(bar_n_min, np.min(o_map_dict[\"number\"]))\n",
    "            bar_n_max = max(bar_n_max, np.max(o_map_dict[\"number\"]))\n",
    "    \n",
    "    if sim_bool: POPPLOT_number_bar_axis_settings(sim_axes[0],min_n=bar_n_min,max_n=bar_n_max,bar_log=bar_log,min_shift_bool=False,labels_on=not data_bool)\n",
    "    if data_bool: POPPLOT_number_bar_axis_settings(data_axes[0],min_n=bar_n_min,max_n=bar_n_max,bar_log=bar_log,min_shift_bool=False,labels_on=data_bool)\n",
    "else:\n",
    "    if sim_bool: fig.delaxes(sim_axes[0])\n",
    "    if data_bool: fig.delaxes(data_axes[0])\n",
    "    \n",
    "    if sim_bool and data_bool:\n",
    "        sim_axes[1].set_title(\"Model\")\n",
    "        data_axes[1].set_title(\"Data\")\n",
    "\n",
    "for row,map_string in enumerate(map_list): # plot\n",
    "    error_string = map_string+\"_error\"\n",
    "    \n",
    "    ymin,ymax = [float(\"inf\")],[float(\"-inf\")]\n",
    "    \n",
    "    for i,d in enumerate(all_dicts):\n",
    "        \n",
    "        if sim_bool:\n",
    "            map_dict,min_range,max_range,plot_range = load_values_and_plot_ranges(d[\"load_path_sim\"],full_map_string_list)\n",
    "            plot_range = plot_range if sim_plot_range_str==\"median\" else PH.get_range_means(min_range,max_range)\n",
    "            label = d[\"label_sim\"] if row == legend_row-1 else None\n",
    "            \n",
    "            if sim_surface_bool:\n",
    "                POPPLOT_values_surface(sim_axes[row+1],map_dict[map_string],map_dict[error_string],plot_range,\\\n",
    "                               color=d[\"color\"],label=label,line_alpha=d[\"line_alpha\"],surface_alpha=d[\"surface_alpha\"],zorder=d[\"zorder\"])\n",
    "            else:\n",
    "                POPPLOT_values_scatter(sim_axes[row+1],map_dict[map_string],map_dict[error_string],plot_range,min_range,max_range,\\\n",
    "                           color=d[\"color\"],label=label,line_alpha=d[\"line_alpha\"],zorder=d[\"zorder\"],lines_bool=sim_lines_bool,x_error_bool=sim_xerror_bool)\n",
    "            \n",
    "            ymin = min(ymin, np.nanmin(map_dict[map_string]-map_dict[error_string]))\n",
    "            ymax = max(ymax, np.nanmax(map_dict[map_string]+map_dict[error_string]))\n",
    "            \n",
    "            POPPLOT_yaxis_settings(sim_axes[row+1],map_string,error_string,set_ylims=False)\n",
    "            \n",
    "            sim_axes[row+1].axhline(y=0,linestyle='--',color=zero_line_color,alpha=zero_line_alpha,zorder=0)\n",
    "            \n",
    "        if data_bool:\n",
    "            o_map_dict,o_min_range,o_max_range,o_plot_range = load_values_and_plot_ranges(d[\"load_path_data\"],full_map_string_list)\n",
    "            o_plot_range = o_plot_range if data_plot_range_str==\"median\" else PH.get_range_means(o_min_range,o_max_range)\n",
    "            o_label = d[\"label_data\"] if row == legend_row-1 else None\n",
    "            \n",
    "            if data_surface_bool:\n",
    "                POPPLOT_values_surface(data_axes[row+1],o_map_dict[map_string],o_map_dict[error_string],o_plot_range,\\\n",
    "                               color=d[\"color\"],label=o_label,line_alpha=d[\"line_alpha\"],surface_alpha=d[\"surface_alpha\"],zorder=d[\"zorder\"])\n",
    "            else:\n",
    "                POPPLOT_values_scatter(data_axes[row+1],o_map_dict[map_string],o_map_dict[error_string],o_plot_range,o_min_range,o_max_range,\\\n",
    "                           color=d[\"color\"],label=o_label,line_alpha=d[\"line_alpha\"],zorder=d[\"zorder\"],lines_bool=data_lines_bool,x_error_bool=data_xerror_bool)\n",
    "        \n",
    "            ymin = min(ymin, np.nanmin(o_map_dict[map_string]-o_map_dict[error_string]))\n",
    "            ymax = max(ymax, np.nanmax(o_map_dict[map_string]+o_map_dict[error_string]))\n",
    "    \n",
    "            POPPLOT_yaxis_settings(data_axes[row+1],map_string,error_string,labels_on=False,set_ylims=False)\n",
    "\n",
    "            data_axes[row+1].axhline(y=0,linestyle='--',color=zero_line_color,alpha=zero_line_alpha,zorder=0)\n",
    "    \n",
    "    if map_string in yshift_dict:\n",
    "        ymin -= yshift_dict[map_string]\n",
    "        ymax += yshift_dict[map_string]\n",
    "    \n",
    "    if hard_coded_ylims_bool and map_string in hard_coded_ylims:\n",
    "        ymin,ymax = hard_coded_ylims[map_string]\n",
    "    \n",
    "    if sim_bool: sim_axes[row+1].set_ylim(ymin,ymax)\n",
    "    if data_bool: data_axes[row+1].set_ylim(ymin,ymax)\n",
    "\n",
    "if legend_bool: # legend\n",
    "    if sim_bool: \n",
    "        sim_axes[legend_row].legend(loc=legend_loc,fontsize=legend_fontsize,ncols=ncols_leg)#,loc=\"lower left\")\n",
    "    if data_bool and legend_data_bool: \n",
    "        data_axes[legend_row].legend(loc=legend_loc,fontsize=legend_fontsize,ncols=ncols_leg)\n",
    "    \n",
    "if True: # x-axis\n",
    "    \n",
    "    if sim_bool: \n",
    "        _,min_range,max_range,_ = load_values_and_plot_ranges(all_dicts[0][\"load_path_sim\"],full_map_string_list)\n",
    "    if data_bool:\n",
    "        _,o_min_range,o_max_range,_ = load_values_and_plot_ranges(all_dicts[0][\"load_path_data\"],full_map_string_list)\n",
    "    \n",
    "    for row in range(len(map_list)+1): # include number bars\n",
    "        \n",
    "        x_labels_on = row == len(map_list)\n",
    "        \n",
    "        if sim_bool:\n",
    "            age_ticks = np.arange(min(min_range)+1,max(max_range)+1,1)\n",
    "            POPPLOT_xaxis_settings(sim_axes[row],xmin=min(min_range),xmax=max(max_range),xlabel=sim_xlabel,\\\n",
    "                                   xticks=age_ticks,labels_on=x_labels_on)\n",
    "            if invert_sim_xaxis:\n",
    "                sim_axes[row].invert_xaxis()\n",
    "        \n",
    "        if data_bool:\n",
    "#             metal_ticks = np.arange(-0.9,0.6+0.3,0.3)\n",
    "            metal_ticks = np.arange(min(o_min_range)+1,max(o_max_range)+1,1)\n",
    "            POPPLOT_xaxis_settings(data_axes[row],xmin=min(o_min_range),xmax=max(o_max_range),xlabel=data_xlabel,xticks=metal_ticks,labels_on=x_labels_on)\n",
    "            \n",
    "            if invert_data_xaxis:\n",
    "                data_axes[row].invert_xaxis()\n",
    "    \n",
    "    fig.align_labels()\n",
    "    \n",
    "if True: # save\n",
    "    \n",
    "    filename = \"kinpop_\" + map_list_string\n",
    "    \n",
    "    filename += \"_noN\" if not number_bool else \"\"\n",
    "    \n",
    "    filename += \"_noNvar\" if number_bool and not number_variations_bool else \"\"\n",
    "    \n",
    "    filename += \"_noLeg\" if not legend_bool else \"\"\n",
    "    \n",
    "    if not data_lines_bool:\n",
    "        filename += \"_noDataLines\"\n",
    "    \n",
    "    filename += filename_suffix\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        print(\"Saving in\",save_path)\n",
    "        for formatting in ['.png','.pdf']:\n",
    "            plt.savefig(save_path+filename+formatting, bbox_inches='tight', dpi=300)\n",
    "            print(\"Saved\",formatting)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_units_dict[\"b\"] = \"deg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_values_and_plot_ranges(path,full_map_string_list):\n",
    "    \n",
    "    map_dict = {}\n",
    "    for m in full_map_string_list:\n",
    "        map_dict[m] = np.load(f\"{path}{m}.npy\")\n",
    "    \n",
    "    min_range = np.load(path + f\"pop_min_range.npy\")\n",
    "    max_range = np.load(path + f\"pop_max_range.npy\")\n",
    "    plot_range = np.load(path + f\"pop_plot_range.npy\")\n",
    "    \n",
    "    return map_dict, min_range, max_range, plot_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some reference values\n",
    "\n",
    "l_cuts = [-2,2]\n",
    "y_cuts = MF.return_int_or_dec_for_array([coordinates.ang_to_rect(ang=l_cut,x=coordinates.get_solar_radius()) for l_cut in l_cuts])\n",
    "\n",
    "b_range_min,b_range_max = PH.get_equal_n_minmax_b_ranges(data_trim)\n",
    "b_variations = [[MF.return_int_or_dec(m,2),MF.return_int_or_dec(M,2)] for (m,M) in zip(b_range_min,b_range_max)]\n",
    "\n",
    "z_range_min = [coordinates.ang_to_rect(ang=bmin,x=coordinates.get_solar_radius()) for bmin in b_range_min]\n",
    "z_range_max = [coordinates.ang_to_rect(ang=bmax,x=coordinates.get_solar_radius()) for bmax in b_range_max]\n",
    "z_variations = [[MF.return_int_or_dec(m,2),MF.return_int_or_dec(M,2)] for (m,M) in zip(z_range_min,z_range_max)]\n",
    "\n",
    "R_variations = [[0,3.5],[0,2]]\n",
    "\n",
    "print(\"l\",l_cuts)\n",
    "print(\"y\",y_cuts)\n",
    "print(\"b\",b_variations)\n",
    "print(\"z\",z_variations)\n",
    "print(\"R\",R_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://colorbrewer2.org/#type=qualitative&scheme=Dark2&n=3\n",
    "\n",
    "# colors = [\"blue\",\"blue\",\"blue\"]\n",
    "colors = [\"#1b9e77\",\"#d95f02\",\"#7570b3\"]\n",
    "\n",
    "line_alpha = 0.9\n",
    "surface_alpha = 0.75\n",
    "alpha_reduction_factor = 0.25\n",
    "\n",
    "number_alpha = 0.75\n",
    "number_alpha_reduction_factor = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim galactic vs rectangular 3 columns\n",
    "\n",
    "# binning_type = \"equalN\"\n",
    "binning_type = \"equalSteps\"\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/1.5b3.51/sim/{binning_type}/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-0.28y0.28/0.21z0.5/sim/{binning_type}/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/1.5b3.51/sim/{binning_type}/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-0.28y0.28/0.21z0.5/sim/{binning_type}/40_datapoints/arrays/\"\n",
    "        ],\n",
    "        \"labels\": [None,None,get_legend_label([1.5,3.51],\"b\"),get_legend_label([0.21,0.5],\"z\")],\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/3.51b6.6/sim/{binning_type}/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-0.28y0.28/0.5z0.94/sim/{binning_type}/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/3.51b6.6/sim/{binning_type}/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-0.28y0.28/0.5z0.94/sim/{binning_type}/20_datapoints/arrays/\"\n",
    "        ],\n",
    "        \"labels\": [None,None,get_legend_label([3.51, 6.6],\"b\"),get_legend_label([0.5,0.94],\"z\")],\n",
    "    },\n",
    "    2: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/7.13b8.85/sim/{binning_type}/10_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-0.28y0.28/1.01z1.26/sim/{binning_type}/10_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/7.13b8.85/sim/{binning_type}/10_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-0.28y0.28/1.01z1.26/sim/{binning_type}/10_datapoints/arrays/\"\n",
    "        ],\n",
    "        \"labels\": [None,None,get_legend_label([7.13, 8.85],\"b\"),get_legend_label([0.5,0.94],\"z\")],\n",
    "    },   \n",
    "}\n",
    "\n",
    "save_path = get_base_POPPLOT_path(resampled_sim_bool=False) + \\\n",
    "            f\"0R3.5_0R2/-2l2_-0.28y0.28/1.5b3.51_0.21z0.5__3.51b6.6_0.5z0.94__7.13b8.85_1.01z1.26/sim/sim_{binning_type}/sim_n40,40_n40,40__n20,20_n20,20__n10,10_n10,10/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [5,6,7,8]\n",
    "    all_dicts[key][\"colors\"] = 2*[\"blue\", \"orange\"]\n",
    "    all_dicts[key][\"line_alphas\"] = 2*[alpha_reduction_factor*line_alpha] + 2*[line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 2*[alpha_reduction_factor*surface_alpha] + 2*[surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = 2*[number_alpha_reduction_factor*number_alpha] + 2*[number_alpha]\n",
    "    all_dicts[key][\"zorderNs\"] = [6,6,5,5]\n",
    "    all_dicts[key][\"plot_ranges_str\"] = nplots*[\"mean\"]\n",
    "    all_dicts[key][\"surface_bools\"] = nplots*[True]\n",
    "    all_dicts[key][\"scatter_join_bools\"] = nplots*[True]\n",
    "    all_dicts[key][\"number_bools\"] = [False,False,True,True]\n",
    "    \n",
    "    all_dicts[key][\"invert_xaxis\"] = True\n",
    "    all_dicts[key][\"title\"] = None\n",
    "    all_dicts[key][\"xaxis_label\"] = \"Age [Gyr]\"\n",
    "    all_dicts[key][\"x_ticks\"] = np.arange(5,11,1) #np.arange(-0.9,0.6+0.3,0.3)\n",
    "    all_dicts[key][\"x_lims\"] = [4,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim normal vs resampled 3 columns\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/sim/equalN/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/sim/equalN/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R2/-2l2/1.5b3.51/sim/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R3.5/-2l2/1.5b3.51/sim/equalN/4_datapoints/arrays/\",\n",
    "\n",
    "        ],\n",
    "        \"title\": get_legend_label([1.5,3.51],\"b\"),\n",
    "        \"labels\": 4*[None],\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/sim/equalN/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/sim/equalN/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R2/-2l2/3.51b6.6/sim/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R3.5/-2l2/3.51b6.6/sim/equalN/4_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": get_legend_label([3.51,6.6],\"b\"),\n",
    "        \"labels\": [None,\"Model\",None,\"Resampled model (k=10)\"]\n",
    "    },\n",
    "    2: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/sim/equalN/15_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/sim/equalN/15_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R2/-2l2/7.13b8.85/sim/equalN/3_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + \"0R3.5/-2l2/7.13b8.85/sim/equalN/3_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": get_legend_label([7.13,8.85],\"b\"),\n",
    "        \"labels\": 4*[None]\n",
    "    },\n",
    "    \n",
    "}\n",
    "\n",
    "save_path = get_base_POPPLOT_path(resampled_sim_bool=False) + \\\n",
    "            \"sim__resampled_sim/0R3.5_0R2/-2l2/1.5b3.51__3.51b6.6__7.13b8.85/sim_equalN/sim_n20,20_n4,4__n20,20_n4,4__n15,15_n3,3/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [5,6,7,8]\n",
    "    all_dicts[key][\"zorderNs\"] = [5,5,6,6]\n",
    "    all_dicts[key][\"colors\"] = [\"blue\",\"blue\",\"orange\",\"orange\"]\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = 2*[alpha_reduction_factor*line_alpha, line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 2*[alpha_reduction_factor*surface_alpha, surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    \n",
    "    all_dicts[key][\"plot_ranges_str\"] = [\"mean\",\"mean\",\"median\",\"median\"]\n",
    "    all_dicts[key][\"surface_bools\"] = [True,True,False,False]\n",
    "    all_dicts[key][\"scatter_join_bools\"] = nplots*[True]\n",
    "    all_dicts[key][\"number_bools\"] = [False,True,False,True]\n",
    "    \n",
    "    all_dicts[key][\"invert_xaxis\"] = True\n",
    "    all_dicts[key][\"xaxis_label\"] = \"Age [Gyr]\"\n",
    "    all_dicts[key][\"x_ticks\"] = np.arange(5,11,1) #np.arange(-0.9,0.6+0.3,0.3)\n",
    "    all_dicts[key][\"x_lims\"] = [4,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data and sim 2 columns (sim equalN)\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Data\",\n",
    "        \"labels\": 6*[None],\n",
    "        \"plot_ranges_str\": 6*[\"median\"],\n",
    "        \"surface_bools\": 6*[False],\n",
    "        \"invert_xaxis\": False,\n",
    "        \"xaxis_label\": \"[Fe/H]\",\n",
    "        \"x_ticks\": np.arange(-0.9,0.6+0.3,0.3),\n",
    "        \"x_lims\": [-1,0.61]\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/sim/equalN/30_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/sim/equalN/30_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/sim/equalN/25_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/sim/equalN/30_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/sim/equalN/30_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/sim/equalN/25_datapoints/arrays/\",\n",
    "\n",
    "        ],\n",
    "        \"title\": \"Model\",\n",
    "        \"labels\": 3*[None] + [get_legend_label([1.5,3.51],\"b\"), get_legend_label([3.51,6.6],\"b\"), get_legend_label([7.13,8.85],\"b\")],\n",
    "        \"plot_ranges_str\": 6*[\"mean\"],\n",
    "        \"surface_bools\": 6*[True],\n",
    "        \"invert_xaxis\": True,\n",
    "        \"xaxis_label\": \"Age [Gyr]\",\n",
    "        \"x_ticks\": np.arange(5,10,1),\n",
    "        \"x_lims\": [4,10]\n",
    "    }, \n",
    "}\n",
    "\n",
    "save_path = get_base_POPPLOT_path(resampled_sim_bool=False) + \\\n",
    "            \"0R3.5_0R2/-2l2/1.5b3.51_3.51b6.6_7.13b8.85/both/data_equalN/data_n4,4,3_n4,4,3/sim_equalN/sim_n30,30,25_n30,30,25/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [5,4,3,8,7,6]\n",
    "    all_dicts[key][\"zorderNs\"] = [5,5,5,6,7,8]\n",
    "    all_dicts[key][\"colors\"] = 2*colors\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = 3*[alpha_reduction_factor*line_alpha] + 3*[line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 3*[alpha_reduction_factor*surface_alpha] + 3*[surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    \n",
    "    all_dicts[key][\"number_bools\"] = 3*[False] + 3*[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data and sim 2 columns (sim equalSteps)\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Data\",\n",
    "        \"labels\": 6*[None],\n",
    "        \"plot_ranges_str\": 6*[\"median\"],\n",
    "        \"surface_bools\": 6*[False],\n",
    "        \"invert_xaxis\": False,\n",
    "        \"xaxis_label\": \"[Fe/H]\",\n",
    "        \"x_ticks\": np.arange(-0.9,0.6+0.3,0.3),\n",
    "        \"x_lims\": [-1,0.61]\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/sim/equalSteps/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/sim/equalSteps/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/sim/equalSteps/10_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/sim/equalSteps/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/sim/equalSteps/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/sim/equalSteps/10_datapoints/arrays/\",\n",
    "\n",
    "        ],\n",
    "        \"title\": \"Model\",\n",
    "        \"labels\": 3*[None] + [get_legend_label([1.5,3.51],\"b\"), get_legend_label([3.51,6.6],\"b\"), get_legend_label([7.13,8.85],\"b\")],\n",
    "        \"plot_ranges_str\": 6*[\"mean\"],\n",
    "        \"surface_bools\": 6*[True],\n",
    "        \"invert_xaxis\": True,\n",
    "        \"xaxis_label\": \"Age [Gyr]\",\n",
    "        \"x_ticks\": np.arange(4,10,1),\n",
    "        \"x_lims\": [4,10]\n",
    "    }, \n",
    "}\n",
    "\n",
    "save_path = get_base_POPPLOT_path(resampled_sim_bool=False) + \\\n",
    "            \"0R3.5_0R2/-2l2/1.5b3.51_3.51b6.6_7.13b8.85/both/data_equalN/data_n4,4,3_n4,4,3/sim_equalSteps/sim_n40,20,10_n40,20,10/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [5,4,3,8,7,6]\n",
    "    all_dicts[key][\"zorderNs\"] = [5,5,5,6,7,8]\n",
    "    all_dicts[key][\"colors\"] = 2*colors\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = 3*[alpha_reduction_factor*line_alpha] + 3*[line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 3*[alpha_reduction_factor*surface_alpha] + 3*[surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    \n",
    "    all_dicts[key][\"number_bools\"] = 3*[False] + 3*[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, sim and sim resampled 3 columns\n",
    "\n",
    "# sim_binning_type = \"equalN\"\n",
    "sim_binning_type = \"equalSteps\"\n",
    "\n",
    "all_dicts = {\n",
    "    0: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R2/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/1.5b3.51/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/3.51b6.6/data/equalN/4_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + \"0R3.5/-2l2/7.13b8.85/data/equalN/3_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Data\",\n",
    "        \"labels\": 6*[None],\n",
    "        \"plot_ranges_str\": 6*[\"median\"],\n",
    "        \"surface_bools\": 6*[False],\n",
    "        \"invert_xaxis\": False,\n",
    "        \"xaxis_label\": \"[Fe/H]\",\n",
    "        \"x_ticks\": np.arange(-0.9,0.6+0.3,0.3),\n",
    "        \"x_lims\": [-1,0.61],\n",
    "        \"bar_width\": 0.03\n",
    "    },\n",
    "    1: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/1.5b3.51/sim/{sim_binning_type}/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/3.51b6.6/sim/{sim_binning_type}/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R2/-2l2/7.13b8.85/sim/{sim_binning_type}/10_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/1.5b3.51/sim/{sim_binning_type}/40_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/3.51b6.6/sim/{sim_binning_type}/20_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=False) + f\"0R3.5/-2l2/7.13b8.85/sim/{sim_binning_type}/10_datapoints/arrays/\",\n",
    "\n",
    "        ],\n",
    "        \"title\": \"Model\",\n",
    "        \"labels\": 3*[None] + [get_legend_label([1.5,3.51],\"b\"), get_legend_label([3.51,6.6],\"b\"), get_legend_label([7.13,8.85],\"b\")],\n",
    "        \"plot_ranges_str\": 6*[\"mean\"],\n",
    "        \"surface_bools\": 6*[True],\n",
    "        \"invert_xaxis\": True,\n",
    "        \"xaxis_label\": \"Age [Gyr]\",\n",
    "        \"x_ticks\": np.arange(5,10,1),\n",
    "        \"x_lims\": [4,10],\n",
    "        \"bar_width\": 0.05\n",
    "    },\n",
    "    2: {\n",
    "        \"load_paths\": [\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R2/-2l2/1.5b3.51/sim/{sim_binning_type}/8_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R2/-2l2/3.51b6.6/sim/{sim_binning_type}/5_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R2/-2l2/7.13b8.85/sim/{sim_binning_type}/3_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R3.5/-2l2/1.5b3.51/sim/{sim_binning_type}/8_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R3.5/-2l2/3.51b6.6/sim/{sim_binning_type}/6_datapoints/arrays/\",\n",
    "            get_base_POPPLOT_path(resampled_sim_bool=True) + f\"0R3.5/-2l2/7.13b8.85/sim/{sim_binning_type}/4_datapoints/arrays/\",\n",
    "        ],\n",
    "        \"title\": \"Resampled model\",\n",
    "        \"labels\": 6*[None],\n",
    "        \"plot_ranges_str\": 6*[\"median\"],\n",
    "        \"surface_bools\": 6*[False],\n",
    "        \"invert_xaxis\": True,\n",
    "        \"xaxis_label\": \"Age [Gyr]\",\n",
    "        \"x_ticks\": np.arange(5,10,1),\n",
    "        \"x_lims\": [4,10],\n",
    "        \"bar_width\": 0.12\n",
    "    }    \n",
    "}\n",
    "\n",
    "save_path = get_base_POPPLOT_path(resampled_sim_bool=False) + \\\n",
    "            f\"data__sim__resampled_sim/0R3.5_0R2/-2l2/1.5b3.51_3.51b6.6_7.13b8.85/both/data_equalN__sim_{sim_binning_type}/\"+\\\n",
    "            \"data_n4,4,3_n4,4,3__sim_n40,20,10_n40,20,10__resampledsim_n8,6,4_n8,5,3/\"\n",
    "\n",
    "ncols = len(all_dicts)\n",
    "\n",
    "for key in all_dicts: # this loop sets features/settings that share the same values across the columns\n",
    "    \n",
    "    nplots = len(all_dicts[key][\"load_paths\"])\n",
    "    \n",
    "    all_dicts[key][\"zorders\"] = [5,4,3,8,7,6]\n",
    "    all_dicts[key][\"zorderNs\"] = [5,5,5,6,7,8]\n",
    "    all_dicts[key][\"colors\"] = 2*colors\n",
    "    \n",
    "    all_dicts[key][\"line_alphas\"] = 3*[alpha_reduction_factor*line_alpha] + 3*[line_alpha]\n",
    "    all_dicts[key][\"surface_alphas\"] = 3*[alpha_reduction_factor*surface_alpha] + 3*[surface_alpha]\n",
    "    all_dicts[key][\"number_alphas\"] = nplots*[number_alpha]\n",
    "    \n",
    "    all_dicts[key][\"number_bools\"] = 3*[False] + 3*[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in all_dicts:\n",
    "    print(key)\n",
    "    for path in all_dicts[key][\"load_paths\"]:\n",
    "        print(path)\n",
    "        if not os.path.isdir(path):\n",
    "            raise ValueError(\"Path did not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(save_path,exist_ok=True)\n",
    "\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsize = 5\n",
    "\n",
    "scatter_join_bool = True\n",
    "# scatter_join_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_bool = True\n",
    "# number_bool = False\n",
    "\n",
    "# number_variations_bool = True\n",
    "number_variations_bool = False\n",
    "\n",
    "bar_log = True\n",
    "# bar_log = False\n",
    "\n",
    "if number_bool: # check there are actually any to be plotted\n",
    "    \n",
    "    any_number_bool = False\n",
    "    for key in all_dicts:\n",
    "        any_number_bool = any_number_bool or any(all_dicts[key][\"number_bools\"])\n",
    "        \n",
    "    if not any_number_bool:\n",
    "        number_bool = False\n",
    "        print(\"No plot with number bool to draw, setting number_bool=False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_coded_ylims_bool = True # currently needed to ensure the y axis is shared correctly\n",
    "# hard_coded_ylims_bool = False\n",
    "\n",
    "# symmetric_ylims_bool = True\n",
    "symmetric_ylims_bool = False\n",
    "\n",
    "hard_coded_ylims = {\n",
    "#     \"tilt_abs\": [-45,3],\n",
    "    \"tilt_abs\": [-45,45],\n",
    "}\n",
    "\n",
    "yshift_dict = {\n",
    "    \"tilt_abs\": 2,\n",
    "    \"anisotropy\": 0.02,\n",
    "    \"correlation\": 0.01,\n",
    "    \"mean_vx\": 1,\n",
    "    \"mean_vy\": 1,\n",
    "    \"std_vx\": 2,\n",
    "    \"std_vy\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_legend_params(ncols, all_dicts,number_bool):\n",
    "    \n",
    "    if ncols != len(all_dicts):\n",
    "        raise ValueError(\"Expected the `ncols` to match the length of `all_dicts`.\")\n",
    "    \n",
    "    legend_cols = []\n",
    "    for k in all_dicts.keys():\n",
    "        if any(all_dicts[k][\"labels\"]):\n",
    "            legend_cols.append(k)\n",
    "    \n",
    "    ncols_leg = len(np.unique(all_dicts[legend_cols[0]][\"colors\"])) if len(legend_cols) == 1 else 1\n",
    "    \n",
    "    if ncols == 2:\n",
    "        loc_x = -0.75\n",
    "    elif ncols == 3:\n",
    "        loc_x = -0.6 if len(legend_cols) == 1 else 0.16\n",
    "    elif ncols == 1:\n",
    "        loc_x = -0.25\n",
    "        \n",
    "    legend_loc = [loc_x, 1.65]\n",
    "    \n",
    "    if not any(any(all_dicts[k][\"number_bools\"]) for k in all_dicts.keys()):\n",
    "        legend_loc[1] -= 0.4\n",
    "        \n",
    "    if not any(all_dicts[k][\"title\"] for k in all_dicts.keys()):\n",
    "        legend_loc[1] -= 0.15\n",
    "    \n",
    "    return legend_cols, legend_loc, ncols_leg\n",
    "            \n",
    "legend_row = 1\n",
    "# legend_row = len(map_list)\n",
    "\n",
    "legend_cols, legend_loc, ncols_leg = get_legend_params(ncols, all_dicts,number_bool)\n",
    "# legend_loc = \"upper right\"; ncols_leg=1\n",
    "# legend_cols = [1]\n",
    "\n",
    "legend_bool = True\n",
    "# legend_bool = False\n",
    "\n",
    "if legend_bool: # check there are actually any labels to be plotted\n",
    "    \n",
    "    any_legend_bool = False\n",
    "    for key in all_dicts:\n",
    "        any_legend_bool = any_legend_bool or any(all_dicts[key][\"labels\"])\n",
    "        \n",
    "    if not any_legend_bool:\n",
    "        legend_bool = False\n",
    "        print(\"No plot with label, setting legend_bool=False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_line_color = \"grey\"\n",
    "zero_line_alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 22\n",
    "ylabel_size = 24\n",
    "legend_fontsize = 15.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize_x = 15\n",
    "\n",
    "figsize_y = 1.41*figsize_x # aspect ratio of A4\n",
    "\n",
    "figsize_x /= 2 if ncols == 1 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\",\"anisotropy\",\"correlation\",\"tilt_abs\"]; map_list_string = \"all\"\n",
    "# map_list = [\"anisotropy\",\"correlation\",\"tilt_abs\"]; map_list_string = \"anicorrtilt\"\n",
    "# map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\"]; map_list_string = \"velmeanstd\"\n",
    "# map_list = [\"mean_vx\",\"mean_vy\",\"std_vx\",\"std_vy\",\"anisotropy\"]; map_list_string = \"meanstdani\"\n",
    "# map_list = [\"std_vx\",\"std_vy\",\"anisotropy\"]; map_list_string = \"stdani\"\n",
    "# map_list = [\"mean_vx\",\"mean_vy\"]; map_list_string = \"velmeans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_suffix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bool = True\n",
    "# save_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "fig,axs = plt.subplots(figsize=(figsize_x,figsize_y),nrows=len(map_list)+1,ncols=ncols, facecolor='w',\\\n",
    "                       gridspec_kw={'hspace':0,'wspace':0,'height_ratios':[0.35]+len(map_list)*[1]})\n",
    "\n",
    "if number_bool: # number and title\n",
    "    bar_n_min,bar_n_max = [10**30],[0]\n",
    "\n",
    "    for col in all_dicts:\n",
    "        dic = all_dicts[col]\n",
    "\n",
    "        axs[0,col].set_title(dic[\"title\"])\n",
    "\n",
    "        for i in range(len(dic[\"load_paths\"])):\n",
    "            if dic[\"number_bools\"][i]:\n",
    "                map_dict,min_range,max_range,plot_range = load_values_and_plot_ranges(dic[\"load_paths\"][i],full_map_string_list)\n",
    "                \n",
    "                if dic[\"plot_ranges_str\"][i] == \"mean\":\n",
    "                    plot_range = PH.get_range_means(min_range,max_range)\n",
    "\n",
    "                POPPLOT_number_bar(axs[0,col], plot_range, map_dict[\"number\"],color=dic[\"colors\"][i],alpha=dic[\"number_alphas\"][i],\\\n",
    "                                   zorder=dic[\"zorderNs\"][i], bar_width=dic[\"bar_width\"])\n",
    "\n",
    "                bar_n_min = min(bar_n_min, np.min(map_dict[\"number\"]))\n",
    "                bar_n_max = max(bar_n_max, np.max(map_dict[\"number\"]))\n",
    "    \n",
    "    for col in all_dicts:\n",
    "        POPPLOT_number_bar_axis_settings(axs[0,col],min_n=bar_n_min,max_n=bar_n_max,bar_log=bar_log,labels_on=col==ncols-1)        \n",
    "else:\n",
    "    for col in all_dicts:\n",
    "        fig.delaxes(axs[0,col])\n",
    "        \n",
    "        axs[1,col].set_title(all_dicts[col])\n",
    "\n",
    "for row,map_string in enumerate(map_list): # plot\n",
    "    error_string = map_string+\"_error\"\n",
    "    \n",
    "    ymin,ymax = [float(\"inf\")],[float(\"-inf\")]\n",
    "    \n",
    "    for col in all_dicts:\n",
    "        \n",
    "        POPPLOT_yaxis_settings(axs[row+1,col],map_string,error_string,set_ylims=False,labels_on=col==0)\n",
    "        axs[row+1,col].axhline(y=0,linestyle='--',color=zero_line_color,alpha=zero_line_alpha,zorder=0)\n",
    "        \n",
    "        dic = all_dicts[col]\n",
    "        for i in range(len(dic[\"load_paths\"])):\n",
    "            \n",
    "            map_dict,min_range,max_range,plot_range = load_values_and_plot_ranges(dic[\"load_paths\"][i],full_map_string_list)\n",
    "            plot_range = plot_range if dic[\"plot_ranges_str\"][i]==\"median\" else PH.get_range_means(min_range,max_range)\n",
    "            label = dic[\"labels\"][i] if row == legend_row-1 else None\n",
    "            \n",
    "            if dic[\"surface_bools\"][i]:\n",
    "                POPPLOT_values_surface(axs[row+1,col],map_dict[map_string],map_dict[error_string],plot_range,color=dic[\"colors\"][i],label=label,\\\n",
    "                                       line_alpha=dic[\"line_alphas\"][i],surface_alpha=dic[\"surface_alphas\"][i],zorder=dic[\"zorders\"][i])\n",
    "            else:\n",
    "                POPPLOT_values_scatter(axs[row+1,col],map_dict[map_string],map_dict[error_string],plot_range,min_range,max_range,color=dic[\"colors\"][i],label=label,\\\n",
    "                                       line_alpha=dic[\"line_alphas\"][i],zorder=dic[\"zorders\"][i],lines_bool=scatter_join_bool)\n",
    "            \n",
    "            ymin = min(ymin, np.nanmin(map_dict[map_string]-map_dict[error_string]))\n",
    "            ymax = max(ymax, np.nanmax(map_dict[map_string]+map_dict[error_string]))\n",
    "    \n",
    "    if map_string in yshift_dict:\n",
    "        ymin -= yshift_dict[map_string]\n",
    "        ymax += yshift_dict[map_string]\n",
    "    \n",
    "    if hard_coded_ylims_bool and map_string in hard_coded_ylims:\n",
    "        ymin,ymax = hard_coded_ylims[map_string]\n",
    "    \n",
    "    for col in all_dicts:\n",
    "        axs[row+1,col].set_ylim(ymin,ymax)\n",
    "\n",
    "if legend_bool: # legend\n",
    "    for col in all_dicts:\n",
    "        if col in legend_cols:\n",
    "            axs[legend_row,col].legend(loc=legend_loc,fontsize=legend_fontsize,ncols=ncols_leg)#,loc=\"lower left\")\n",
    "    \n",
    "if True: # x-axis\n",
    "        \n",
    "    for col in all_dicts:\n",
    "        \n",
    "        dic = all_dicts[col]\n",
    "    \n",
    "        for row in range(len(map_list)+1): # include number bars\n",
    "\n",
    "            POPPLOT_xaxis_settings(axs[row,col],xmin=dic[\"x_lims\"][0],xmax=dic[\"x_lims\"][1],xlabel=dic[\"xaxis_label\"],xticks=dic[\"x_ticks\"],labels_on=row==len(map_list))\n",
    "\n",
    "            if dic[\"invert_xaxis\"]:\n",
    "                axs[row,col].invert_xaxis()\n",
    "    \n",
    "    fig.align_labels()\n",
    "    \n",
    "if True: # save\n",
    "    \n",
    "    filename = \"kinpop_\" + map_list_string\n",
    "    \n",
    "    filename += \"_noN\" if not number_bool else \"\"\n",
    "    \n",
    "    filename += \"_noNvar\" if number_bool and not number_variations_bool else \"\"\n",
    "    \n",
    "    filename += \"_noLeg\" if not legend_bool else \"\"\n",
    "    \n",
    "    if not scatter_join_bool:\n",
    "        filename += \"_noLines\"\n",
    "    \n",
    "    filename += filename_suffix\n",
    "    \n",
    "    print(filename)\n",
    "    \n",
    "    if save_bool:\n",
    "        print(\"Saving in\",save_path)\n",
    "        for formatting in ['.png','.pdf']:\n",
    "            plt.savefig(save_path+filename+formatting, bbox_inches='tight', dpi=300)\n",
    "            print(\"Saved\",formatting)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sim & data same ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Victor didn't like this as the two x-axis are confusing (and they represent different things so a 1-to-1 comparison within the plot isn't appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax1 = ax.twiny()\n",
    "ax1.set_xlabel('[Fe/H]',labelpad=10)\n",
    "ax1.plot(metal_midranges, o_vertex_values, linestyle='--',color='red')\n",
    "ax1.fill_between(metal_midranges, o_vertex_values-o_vertex_errors, o_vertex_values+o_vertex_errors,alpha=0.4, color='red',label='Apogee') #edgecolor='#CC4F1B', facecolor='#FF9848'\n",
    "ax1.set_xticks(np.linspace(metal_poor_lim,metal_rich_lim,5))\n",
    "ax1.set_xlim(metal_rich_lim,metal_poor_lim)\n",
    "\n",
    "ax.set_xlabel('Age [Gyr]')\n",
    "ax.set_ylabel(r'$l_{\\mathrm{v}} \\:\\: [^\\circ]$')\n",
    "#ax.tick_params(labelsize=15,length=4,width=1)\n",
    "ax.set_ylim(-45,45)\n",
    "\n",
    "invert_axis_bool = False #invert x-axis (from old to young)\n",
    "if invert_axis_bool:\n",
    "    ax.set_xlim(max(age_mid_ranges)+half_range/2, min(age_mid_ranges)-half_range/2)\n",
    "else:\n",
    "    ax.set_xticks(np.arange(min(age_mid_ranges)-0.5, max(age_mid_ranges)+0.5, 1.0))\n",
    "\n",
    "vertex_values = np.array(vertex_values)\n",
    "#ax.errorbar(xb, yb,\n",
    "#            yerr=vertex_err,\n",
    "#            fmt='-o')\n",
    "ax.plot(age_mid_ranges, vertex_values, linestyle='--',color='blue')\n",
    "ax.fill_between(age_mid_ranges, vertex_values-vertex_errors, vertex_values+vertex_errors,alpha=0.4, facecolor='blue',label='D17') #edgecolor='#CC4F1B', facecolor='#FF9848'\n",
    "\n",
    "fig.legend(loc=(0.15,0.8))\n",
    "\n",
    "l_text = fr\"${lmin}<l$[{degree_symbol}]$<{lmax}$\"\n",
    "b_text = fr\"${bmin}<|b|$[{degree_symbol}]$<{bmax}$\"\n",
    "x,y= 0.06,0.75\n",
    "ax.text(x=x,y=y,s=l_text,transform=ax.transAxes)\n",
    "ax.text(x=x,y=y-0.05,s=b_text,transform=ax.transAxes)\n",
    "\n",
    "#file_name = 'rotangle' + str(rot_angle)+'_708_vertex_age_'+str(age_step_old)+'oldResolution_'+str(age_limit_oldyoung)+'ageLimit_window2x2_invertaxis'+str(invert_axis_bool)+'.png'\n",
    "\n",
    "plt.savefig(save_path_pop+'age_metal.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sim old subdivision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data_bool:\n",
    "    \n",
    "    fig,axs = plt.subplots(figsize=(13,10),nrows=2,ncols=2, gridspec_kw={'wspace':0.15,'hspace':0,'width_ratios':[1,0.17],'height_ratios':[0.15,1]})\n",
    "\n",
    "    barax = axs[0,0]\n",
    "    barax1 = axs[0,1]\n",
    "    ax = axs[1,0]\n",
    "    ax1 = axs[1,1]\n",
    "\n",
    "    if True: # left right array division \n",
    "        age_plot_left = pop_plot_range[:limit_index]\n",
    "        var_left = map_dict[var][:limit_index]\n",
    "        err_left = map_dict[err][:limit_index]\n",
    "\n",
    "        age_plot_right = pop_plot_range[limit_index:]\n",
    "        var_right = map_dict[var][limit_index:]\n",
    "        err_right = map_dict[err][limit_index:]\n",
    "\n",
    "    if True: # bar plots\n",
    "\n",
    "        number_left = map_dict['number'][:limit_index]\n",
    "        number_right = map_dict['number'][limit_index:]\n",
    "\n",
    "        barax.hist(df_extra[df_extra[\"age\"]>4][\"age\"],bins=50,log=True,histtype=\"step\",color=\"k\")\n",
    "\n",
    "        barax.bar(age_plot_left,number_left,log=True,width=0.2,color=\"grey\",alpha=0.8)\n",
    "        barax1.bar(age_plot_right,number_right,log=True,width=0.01)\n",
    "\n",
    "    #     barax.plot(age_plot_left,number_left)\n",
    "    #     barax1.plot(age_plot_right,number_right)\n",
    "\n",
    "        for bar in [barax,barax1]:\n",
    "            bar.minorticks_off()\n",
    "            bar.set_xticklabels([])\n",
    "\n",
    "            min_barticks = 3\n",
    "            max_bartick = 5\n",
    "            bar.set_yticks([10**i for i in np.arange(min_barticks,max_bartick+1,1)])\n",
    "\n",
    "        if old_subplots:\n",
    "            barax.tick_params(labelleft=False)\n",
    "            barax1.tick_params(labelleft=False,labelright=True)\n",
    "        else:\n",
    "            barax.tick_params(labelleft=False,labelright=True)\n",
    "\n",
    "    if True: # plot\n",
    "        ax.plot(age_plot_left,var_left,color=color)\n",
    "        ax.fill_between(age_plot_left,var_left-err_left,var_left+err_left,label=symbol_dict[var],color=color,alpha=0.5,linewidth=0)\n",
    "        ax1.plot(age_plot_right,var_right,color=color)\n",
    "        ax1.fill_between(age_plot_right,var_right-err_right,var_right+err_right,label=symbol_dict[var],color=color,alpha=0.5,linewidth=0)\n",
    "\n",
    "    if var1_bool: # var1, legend \n",
    "        var1_left = map_dict[var1][:limit_index]\n",
    "        err1_left = map_dict[err1][:limit_index]\n",
    "\n",
    "        var1_right = map_dict[var1][limit_index:]\n",
    "        err1_right = map_dict[err1][limit_index:]\n",
    "\n",
    "        ax.plot(age_plot_left,var1_left,color=color1)\n",
    "        ax.fill_between(age_plot_left,var1_left-err1_left,var1_left+err1_left,label=r\"$%s$\"%only_symbol_dict[var1],color=color1,alpha=0.5,linewidth=0)\n",
    "        ax1.plot(age_plot_right,var1_right,color=color1)\n",
    "        ax1.fill_between(age_plot_right,var1_right-err1_right,var1_right+err1_right,label=r\"$%s$\"%only_symbol_dict[var1],color=color1,alpha=0.5,linewidth=0)\n",
    "\n",
    "        ax.legend(loc='lower right')\n",
    "\n",
    "    if True: # axhlines, ylim, ticks\n",
    "\n",
    "        ax.axhline(y=0,linestyle='--',color='grey')\n",
    "        ax1.axhline(y=0,linestyle='--',color='grey')\n",
    "\n",
    "        ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.25))\n",
    "        barax.xaxis.set_minor_locator(ticker.MultipleLocator(0.25))\n",
    "\n",
    "        ax1.xaxis.set_minor_locator(ticker.MultipleLocator(0.025))\n",
    "        barax1.xaxis.set_minor_locator(ticker.MultipleLocator(0.025))\n",
    "\n",
    "        for axis in [ax,ax1]:\n",
    "\n",
    "            if var == 'anisotropy' or var == 'correlation':\n",
    "                ybottom, ytop = -0.5,0.2\n",
    "                axis.set_ylim(ybottom,ytop); print(f\"Lims {ybottom},{ytop}\")\n",
    "                axis.yaxis.set_major_locator(ticker.MultipleLocator(0.1))\n",
    "                axis.yaxis.set_minor_locator(ticker.MultipleLocator(0.05))\n",
    "\n",
    "            elif var == 'tilt_abs':\n",
    "                ybottom, ytop = -45, -10\n",
    "                axis.set_ylim(ybottom,ytop); print(f\"Lims {ybottom},{ytop}\")\n",
    "                axis.yaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "                axis.yaxis.set_minor_locator(ticker.MultipleLocator(2.5))\n",
    "            else:\n",
    "                maxabs = max(np.abs([min(map_dict[var]-map_dict[err]),max(map_dict[var]+map_dict[err])]))\n",
    "\n",
    "                if var1_bool:\n",
    "                    maxabs1 = max(np.abs([min(map_dict[var1]-map_dict[err1]),max(map_dict[var1]+map_dict[err1])]))\n",
    "\n",
    "                    maxabs = max(maxabs,maxabs1)\n",
    "\n",
    "                axis.set_ylim(-maxabs-0.05,maxabs+0.05)\n",
    "\n",
    "        ax1.set_yticklabels([])\n",
    "\n",
    "    if True: # labels and text\n",
    "        ax.set_xlabel('Age [Gyr]')\n",
    "        if not var1_bool:\n",
    "            ax.set_ylabel(symbol_dict[var]+units_dict[var])\n",
    "\n",
    "    #         if var == 'vertex_abs':\n",
    "    #             ax.text(x=0.05,y=0.6,s=fr\"$|l|<{lmax}^\\circ$\"+'\\n'+fr\"${bmin}^\\circ<|b|<{bmax}^\\circ$\"+'\\n'+fr\"${dmin}<d/\\mathrm{{kpc}}<{dmax}$\",\n",
    "    #                     transform=ax.transAxes,fontsize=15)#,bbox={'facecolor':'w'})\n",
    "\n",
    "        if not old_subplots:\n",
    "            barax.set_ylabel(r\"$N$\",rotation=0,labelpad=20)\n",
    "            barax.yaxis.set_label_position(\"right\")\n",
    "\n",
    "    if True: # xlim, broken axes params\n",
    "\n",
    "        if old_subplots:\n",
    "            left_age_transition = max_age#age_limit_oldyoung\n",
    "            ax.set_xlim(min_age,left_age_transition)\n",
    "            barax.set_xlim(min_age,left_age_transition)\n",
    "\n",
    "            ax1.set_xlim(age_limit_old,max_age)\n",
    "            barax1.set_xlim(age_limit_old,max_age)\n",
    "\n",
    "        # hide the spines between ax and ax1\n",
    "    #     ax.spines['right'].set_visible(False)\n",
    "    #     ax1.spines['left'].set_visible(False)\n",
    "    #     ax.tick_params(which='both',right=False)\n",
    "    #     ax1.tick_params(which='both',left=False)\n",
    "\n",
    "    #     d = .01\n",
    "    #     kwargs = dict(transform=ax.transAxes, color='r', clip_on=False)\n",
    "    #     ax.plot((1-d,1+d), (-d,+d), **kwargs)\n",
    "    #     ax.plot((1-d,1+d),(1-d,1+d), **kwargs)\n",
    "\n",
    "    #     # uncomment the lines below if wanting to leave a space between the axes\n",
    "    #     kwargs.update(transform=ax1.transAxes)  # switch to the bottom axes\n",
    "    #     d_x = .057\n",
    "    #     d_y = 0.011\n",
    "    #     ax1.plot((-d_x,+d_x), (1-d_y,1+d_y), **kwargs)\n",
    "    #     ax1.plot((-d_x,+d_x), (-d_y,+d_y), **kwargs)\n",
    "\n",
    "        else:\n",
    "            ax.set_xlim(min(df[\"age\"]),max(df[\"age\"]))\n",
    "            barax.set_xlim(min(df[\"age\"]),max(df[\"age\"]))\n",
    "\n",
    "    if not old_subplots: # delete right column axes \n",
    "        fig.delaxes(ax1)\n",
    "        fig.delaxes(barax1)\n",
    "\n",
    "    if True: # save\n",
    "\n",
    "        filename = var\n",
    "        if var1_bool: filename += var1\n",
    "\n",
    "        if filename == 'anisotropycorrelation': filename = 'anicorr'\n",
    "        elif filename == 'mean_vxmean_vy': filename = 'vel'\n",
    "\n",
    "        filename += f'_sim'\n",
    "        print(filename)\n",
    "\n",
    "        if save_bool:\n",
    "            for f in ['.png','.pdf']:\n",
    "                plt.savefig(save_path+filename+f,bbox_inches='tight',dpi=200)\n",
    "            print(save_path+filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how wide in longitude we can go before the metal-poor develop a tilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmax = 2\n",
    "bmin = 0.5\n",
    "bmax = 10\n",
    "\n",
    "data_bulge = data[(np.abs(data['l'])<lmax)&(data['d']>6)&(data['d']<10)&(data['b']>bmin)&(data['b']<bmax)]\n",
    "\n",
    "data_bulge_poor = data_bulge[data_bulge['FeH']<-0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vx = data_bulge_poor.vr.values\n",
    "vy = data_bulge_poor.vl.values\n",
    "\n",
    "# val = CV.calculate_tilt(vx,vy,absolute=True)\n",
    "# err = CV.get_std_bootstrap(vx,vy,CV.calculate_tilt,tilt=True,absolute=True)\n",
    "val = CV.calculate_correlation(vx,vy)\n",
    "err = CV.get_std_bootstrap(vx,vy,CV.calculate_correlation)\n",
    "\n",
    "print(r\"%.2f +- %.2f\"%(val,err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in distance distribution for the simulation, check at what latitude it appears\n",
    "\n",
    "In the literature they say the MW's one appears with $l=0$ and $b=-5$, but most of my data lives below $b=5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 to 7 Gyr: inner split visible at $b>2.5$, hard to see at $b>4$, where outer X-shape dominates\n",
    "\n",
    "9.8 to 10 Gyr: visible at $b>3.5$, far end dissappears after $b>6$\n",
    "\n",
    "4 to 10 Gyr: visible at $b>3$, far end dissapears after $b>6$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmax = 2\n",
    "bmin = 6\n",
    "bmax = 10\n",
    "\n",
    "# agemin = 4\n",
    "# agemax = 10\n",
    "agemin = 4\n",
    "agemax = 7\n",
    "# agemin = 9.8\n",
    "# agemax = 10\n",
    "\n",
    "df_bulge = df0[(np.abs(df0['l'])<lmax)&(df0['d']>6)&(df0['d']<10)&(df0['b']>bmin)&(df0['b']<bmax)&(df0['age']>agemin)&(df0['age']<agemax)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.hist(df_bulge['d'],bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmax = 2\n",
    "bmin = 2.5\n",
    "bmax = 10\n",
    "\n",
    "metalmin = data['FeH'].min()\n",
    "metalmax = data['FeH'].max()\n",
    "\n",
    "data_bulge = data[(np.abs(data['l'])<lmax)&(data['d']>6)&(data['d']<10)&(data['b']>bmin)&(data['b']<bmax)&(data['FeH']>metalmin)&(data['FeH']<metalmax)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "\n",
    "ax.hist(data_bulge['d'],bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmin = -1.5\n",
    "lmax = 1.5\n",
    "bmin = 2.5\n",
    "bmax = 4.5\n",
    "\n",
    "dmin = 6\n",
    "dmax = 10\n",
    "\n",
    "df_extra = df0[(df0[\"l\"]>lmin)&(df0[\"l\"]<lmax)&(df0[\"d\"]>dmin)&(df0[\"d\"]<dmax)&(df0[\"b\"]>bmin)&(df0[\"b\"]<bmax+b_step)]\n",
    "df_ages = [df_extra[(df_extra[\"age\"]>agelim[0])&(df_extra[\"age\"]<agelim[1])] for agelim in age_limits]\n",
    "\n",
    "poor_condition = (o_df_extra[\"FeH\"] < metal_poor_highlim)&(o_df_extra[\"FeH\"] > metal_poor_lowlim)\n",
    "rich_condition = o_df_extra[\"FeH\"] > metal_rich_lowlim if metal_rich_highlim is None else (o_df_extra[\"FeH\"] < metal_rich_highlim)&(o_df_extra[\"FeH\"] > metal_rich_lowlim)\n",
    "\n",
    "df_metals = [o_df_extra[rich_condition], o_df_extra[poor_condition]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_step = 1\n",
    "d_range = np.arange(dmin,dmax,d_step)\n",
    "d_range_plot = d_range+d_step/2\n",
    "o_d_range_plot = d_range_plot\n",
    "print(\"d_range is\",d_range)\n",
    "print(\"Plotting at:\",d_range_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = general_path + \"708main_simulation/graphs/Oscar/Apogee/\"\n",
    "create_dir(save_path)\n",
    "\n",
    "# save_path += \"scaling_\"+str(sim_scaling)+'/'\n",
    "# MF.create_dir(save_path)\n",
    "\n",
    "save_path += \"individual_variable/\"\n",
    "MF.create_dir(save_path)\n",
    "\n",
    "save_path += \"distance/\"\n",
    "MF.create_dir(save_path)\n",
    "    \n",
    "save_path += f\"{lmin}l{lmax}/\"\n",
    "create_dir(save_path)\n",
    "\n",
    "save_path += f\"{bmin}b{bmax}/\"\n",
    "create_dir(save_path)\n",
    "    \n",
    "save_path += f\"{young_min}-{young_max}_{old_min}-{old_max}/\"\n",
    "create_dir(save_path)\n",
    "\n",
    "#save_path += 'halo_metal/'\n",
    "#create_dir(save_path)\n",
    "\n",
    "if not galactocentric:\n",
    "    save_path += 'LSR/'\n",
    "    create_dir(save_path)\n",
    "\n",
    "poor_condition = (o_df_extra[\"FeH\"] < metal_poor_highlim)&(o_df_extra[\"FeH\"] > metal_poor_lowlim)\n",
    "label_poor = fr'${metal_poor_lowlim}<$[Fe/H]$<{metal_poor_highlim}$'\n",
    "\n",
    "if metal_rich_highlim is None:\n",
    "    rich_condition = o_df_extra[\"FeH\"] > metal_rich_lowlim\n",
    "    label_rich = fr'${metal_rich_lowlim}<$[Fe/H]'\n",
    "    save_path += f\"{metal_rich_lowlim}to{metal_rich_highlim}_{metal_poor_lowlim}to{metal_poor_highlim}/\"\n",
    "else:\n",
    "    rich_condition = (o_df_extra[\"FeH\"] < metal_rich_highlim)&(o_df_extra[\"FeH\"] > metal_rich_lowlim)\n",
    "    label_rich = fr'${metal_rich_lowlim}<$[Fe/H]$<{metal_rich_highlim}$'\n",
    "    save_path += f\"{metal_rich_lowlim}to{metal_rich_highlim}_{metal_poor_lowlim}to{metal_poor_highlim}/\"\n",
    "\n",
    "df_metals = [o_df_extra[rich_condition], o_df_extra[poor_condition]]\n",
    "label_rich += f\" ({len(df_metals[0])})\"\n",
    "label_poor += f\" ({len(df_metals[1])})\"\n",
    "\n",
    "create_dir(save_path)\n",
    "\n",
    "if halo_bool:\n",
    "    df_metals.append(o_df_extra[o_df_extra[\"FeH\"] < metal_halo_lim])    \n",
    "    label_halo = fr'(%i) [Fe/H]$<{metal_halo_lim}$'%len(df_metals[2])\n",
    "    print(\"Working with the halo population\")\n",
    "\n",
    "print(\"SAVING IN\\n\"+save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "alpha=0.7\n",
    "bins = np.linspace(dmin,dmax,50)\n",
    "if not halo_bool:\n",
    "    ax.hist(o_df_extra['d'],bins=bins,label='(%i) All'%len(o_df_extra['d']),alpha=alpha,color='orange')\n",
    "ax.hist(df_metals[1]['d'],bins=bins,label=label_poor,alpha=alpha,color='blue')\n",
    "ax.hist(df_metals[0]['d'],bins=bins,label=label_rich,alpha=alpha,color='red')\n",
    "if halo_bool:\n",
    "    ax.hist(df_metals[2]['d'],bins=bins,label=label_halo,alpha=alpha*0.75,color='cyan')\n",
    "ax.set_xlim(dmin,dmax)\n",
    "ax.set_xticks(np.arange(dmin,dmax,1))\n",
    "ax.set_xlabel(r'$d$ [kpc]')\n",
    "ax.set_ylabel(r\"$N$\",rotation=0,labelpad=20)\n",
    "ax.legend(loc='upper right')\n",
    "ax.text(0.05,0.9,fr\"${lmin} < l < {lmax}$\",transform=ax.transAxes)\n",
    "ax.text(0.07,0.85,fr\"${bmin} < b < {bmax}$\",transform=ax.transAxes)\n",
    "plt.savefig(save_path+f\"number_observations_{lmin}l{lmax}_{bmin}b{bmax}.png\",bbox_inches='tight',dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_arrays = np.zeros(shape=(len(full_map_string_list),len(d_range),len(df_ages)))\n",
    "o_all_arrays = np.zeros(shape=(len(full_map_string_list),len(d_range),len(df_metals)))\n",
    "\n",
    "for d_index,distance in enumerate(d_range):\n",
    "    for age_index,df in enumerate(df_ages):\n",
    "        vr = df[(df['d']>distance)&(df['d']<distance+d_step)].vr.values\n",
    "        vl = df[(df['d']>distance)&(df['d']<distance+d_step)].vl.values\n",
    "        \n",
    "        values = get_all_variable_values_and_errors(vr,vl,bootstrap_repeat=100,min_number=min_number_sim)\n",
    "        \n",
    "        for index, val in enumerate(values):\n",
    "            all_arrays[index, d_index, age_index] = val\n",
    "    \n",
    "    for metal_index, o_df in enumerate(df_metals):\n",
    "        vr = o_df[(o_df['d']>distance)&(o_df['d']<distance+d_step)].vr.values\n",
    "        vl = o_df[(o_df['d']>distance)&(o_df['d']<distance+d_step)].vl.values\n",
    "        \n",
    "        values = get_all_variable_values_and_errors(vr,vl,bootstrap_repeat=100,min_number=10)\n",
    "        \n",
    "        for index, val in enumerate(values):\n",
    "            o_all_arrays[index, d_index, metal_index] = val\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = create_map_array_dict(full_map_string_list, all_arrays)\n",
    "o_map_dict = create_map_array_dict(full_map_string_list, o_all_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsymbol = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_string = \"vertex_abs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_array = map_dict[map_string]\n",
    "error_array = map_dict[error_string]\n",
    "map_symbol = symbol_dict[map_string]\n",
    "map_title = title_dict[map_string]\n",
    "yticks = get_variable_ticks(map_string, map_array)\n",
    "displacement = max(yticks) - min(yticks)\n",
    "\n",
    "color_y, color_o = color_dict['vertex_abs'][0], color_dict['vertex_abs'][1]\n",
    "\n",
    "transparency = 0.5\n",
    "alpha_area = 0.4\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "ax_histx = divider.append_axes(\"top\", size=1.2, pad=0, sharex=ax)\n",
    "ax_histx.xaxis.set_tick_params(labelbottom=False)\n",
    "\n",
    "alpha=0.7\n",
    "ax_histx.hist(df_metals[1]['d'],bins=bins,alpha=1,color=color_o)\n",
    "ax_histx.hist(df_metals[0]['d'],bins=bins,alpha=alpha,color=color_y)\n",
    "if halo_bool:\n",
    "    ax_histx.hist(df_metals[2]['d'],bins=bins,alpha=alpha,color='cyan')\n",
    "\n",
    "bar_width=0.2\n",
    "ax_histx.bar(d_range_plot-bar_width/2, map_dict[\"number\"][:,0], width=bar_width,alpha=transparency,log=True,color=color_y)\n",
    "ax_histx.bar(d_range_plot+bar_width/2, map_dict[\"number\"][:,1], width=bar_width,alpha=transparency,log=True,color=color_o)\n",
    "ax_histx.yaxis.set_tick_params(labelleft=False,labelright=True)\n",
    "ax_histx.set_yticks([1,10,100,1000,10000,100000])\n",
    "ax_histx.set_ylabel(r\"$N$\",labelpad=15,rotation=0)\n",
    "ax_histx.yaxis.set_label_position(\"right\")\n",
    "\n",
    "ax.plot(d_range_plot, map_array[:,1] , color=color_o, linestyle='--', lw=1)\n",
    "ax.plot(d_range_plot, map_array[:,0], color=color_y, linestyle='--', lw=1)\n",
    "\n",
    "\n",
    "ax.fill_between(d_range_plot, map_array[:,1]-error_array[:,1], map_array[:,1]+error_array[:,1],alpha=alpha_area, facecolor=color_o, label=label_o)\n",
    "ax.fill_between(d_range_plot, map_array[:,0]-error_array[:,0], map_array[:,0]+error_array[:,0],alpha=alpha_area, facecolor=color_y, label=label_y)\n",
    "\n",
    "if not absolute:\n",
    "    ax.fill_between(d_range_plot, map_array[:,1]-error_array[:,1]+displacement, map_array[:,1]+error_array[:,1]+displacement,alpha=alpha_area, facecolor=color_o)\n",
    "    ax.fill_between(d_range_plot, map_array[:,1]-error_array[:,1]-displacement, map_array[:,1]+error_array[:,1]-displacement,alpha=alpha_area, facecolor=color_o)\n",
    "    ax.fill_between(d_range_plot, map_array[:,0]-error_array[:,0]+displacement, map_array[:,0]+error_array[:,0]+displacement,alpha=alpha_area, facecolor=color_y)\n",
    "    ax.fill_between(d_range_plot, map_array[:,0]-error_array[:,0]-displacement, map_array[:,0]+error_array[:,0]-displacement,alpha=alpha_area, facecolor=color_y)\n",
    "\n",
    "#OBSERVATIONS-----------------------------------------------------------------------------------------------\n",
    "o_map_array = o_map_dict[map_string]\n",
    "o_error_array = o_map_dict[error_string]\n",
    "\n",
    "ax.errorbar(o_d_range_plot, o_map_array[:,1] , yerr= o_error_array[:,1], color=color_o, label=label_poor,fmt='o',marker=\"$\\u25A1$\")\n",
    "ax.errorbar(o_d_range_plot, o_map_array[:,0], yerr= o_error_array[:,0], color=color_y, alpha=0.8,label=label_rich,fmt='s',marker=\"$\\u25EF$\")\n",
    "if halo_bool:\n",
    "    ax.errorbar(o_d_range_plot, o_map_array[:,2] , yerr=o_error_array[:,2], color='cyan', label=label_halo,fmt='o',markersize=8,marker=\"$\\u25B3$\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "ax.legend(fontsize=15,loc=\"best\")\n",
    "\n",
    "ax.set_xlim(dmin,dmax)\n",
    "ax.set_xticks(np.arange(dmin,dmax,1))\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_ylim(min(yticks),max(yticks))\n",
    "\n",
    "ax.set_xlabel(r\"$%s$ [°]\"%xsymbol)\n",
    "ax.set_ylabel(map_symbol)\n",
    "\n",
    "title_string = 'Vertex deviation (absolute value equation)' if absolute else 'Vertex deviation'\n",
    "ax_histx.set_title(title_string,fontsize=18,pad=10)\n",
    "\n",
    "#ax.set_aspect(0.082 if absolute else 0.04)\n",
    "\n",
    "ax.text(x=-0.14,y=1.24,s='Sim scaling '+str(sim_scaling),size=13, transform=ax.transAxes)\n",
    "l_string = r\"$%i < l [%s] < {%i},$\"%(lmin,degree_symbol,lmax)\n",
    "d_string = r\"${%i}<d [\\mathrm{%s}]<{%i}$\"%(dmin,'kpc',dmax)\n",
    "text_y = -0.09\n",
    "ax.text(x=0.79,y=text_y,s=l_string,size=13,transform=ax.transAxes)\n",
    "ax.text(x=0.94,y=text_y,s=d_string,size=13,transform=ax.transAxes)\n",
    "plt.savefig(save_path+map_string+'_distance.pdf',bbox_inches='tight')\n",
    "print(save_path+map_string)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_min = 9.\n",
    "age_max = 10.\n",
    "\n",
    "dmin = 6\n",
    "dmax = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_step = 0.5\n",
    "distance_range = np.arange(dmin,dmax,d_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_step = 1.5\n",
    "\n",
    "lmin = -lb_step/2\n",
    "lmax = lb_step/2\n",
    "bmin = -lb_step/2\n",
    "bmax = lb_step/2\n",
    "\n",
    "min_star_number = 10\n",
    "\n",
    "limit_vertex = -40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude_range = np.arange(lmin, lmax, lb_step)\n",
    "latitude_range = np.arange(bmin, bmax, lb_step)\n",
    "\n",
    "print(\"Longitude range:\",longitude_range)\n",
    "print(\"Latitude range:\",latitude_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in latitude_range:\n",
    "    print(i,i+lb_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"708main_simulation/graphs/vertex_distance/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No division in distance intervals\n",
    "theta_across_d = []\n",
    "\n",
    "df_dist_age = df0[(df0.age <= age_max)&(df0.age >= age_min)&(df0.d <= dmax)&(df0.d>=dmin)]\n",
    "\n",
    "for longitude in longitude_range:\n",
    "        df_long = df_dist_age[(df_dist_age.l >= longitude)&(df_dist_age.l < longitude + lb_step)]\n",
    "\n",
    "        for latitude in latitude_range:\n",
    "            df_lat = df_long[(df_long.b >= latitude)&(df_long.b < latitude + lb_step)]\n",
    "\n",
    "            cov = np.cov(df_lat.vr.values, df_lat.pml.values)\n",
    "            varr = cov[0,0]\n",
    "            varl = cov[1,1]\n",
    "            covrl = cov[0,1]\n",
    "\n",
    "            if len(df_lat) > min_star_number:\n",
    "                theta = np.degrees(np.arctan2(2.*covrl, np.abs(varr - varl))/2.)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            print(theta)\n",
    "            theta_across_d.append(theta)\n",
    "del df_dist_age, df_long, df_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path + \"total_vertex_\"+str(lmin)+\"l\"+str(lmax)+\"_\"+str(bmin)+\"b\"+str(bmax)+\".txt\", 'w') as f:\n",
    "    f.write(\"The total vertex deviation across the line of sight (6 < d < 10)kpc is: \"+str(theta_across_d[0])+'°'\\\n",
    "           \"\\n\\nWorking with a \"+str(lb_step)+\"×\"+str(lb_step)+\"° window in: \\n\"+str(lmin)+\" <= l < \"+str(lmax)+\n",
    "           \"\\n\"+str(bmin)+\" <= b < \"+str(bmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = df0[(df0.age <= age_max)&(df0.age >= age_min)]\n",
    "\n",
    "x_positions, y_positions, x_velocities, y_velocities, r_vel, t_vel = [], [], [], [], [], []\n",
    "theta_values, number_points = [], []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for distance in distance_range:\n",
    "    df_dist = df_age[(df_age.d >= distance)&(df_age.d < distance + d_step)]\n",
    "\n",
    "    for longitude in longitude_range:\n",
    "        df_long = df_dist[(df_dist.l >= longitude)&(df_dist.l < longitude + lb_step)]\n",
    "\n",
    "        for latitude in latitude_range:\n",
    "            df_lat = df_long[(df_long.b >= latitude)&(df_long.b < latitude + lb_step)]\n",
    "\n",
    "            cov = np.cov(df_lat.vr.values, df_lat.pml.values)\n",
    "            varr = cov[0,0]\n",
    "            varl = cov[1,1]\n",
    "            covrl = cov[0,1]\n",
    "\n",
    "            if len(df_lat) > min_star_number:\n",
    "                theta = np.degrees(np.arctan2(2.*covrl, np.abs(varr - varl))/2.)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            print(theta)\n",
    "            #if theta < limit_vertex:\n",
    "            number_points.append(len(df_lat.x.values))\n",
    "            theta_values.append(theta)\n",
    "            x_positions.append(df_lat.x.values)\n",
    "            y_positions.append(df_lat.y.values)\n",
    "            x_velocities.append(df_lat.vx.values)\n",
    "            y_velocities.append(df_lat.vy.values)\n",
    "            r_vel.append(df_lat.vr.values)\n",
    "            t_vel.append(df_lat.pml.values)\n",
    "        \n",
    "        i+=1\n",
    "                        \n",
    "print(\"There were\",i,\"intervals\")\n",
    "print(\"There are\",len(distance_range),\"distance bins\")\n",
    "\n",
    "del df_dist, df_long, df_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The max number of points is\",np.max(number_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "n_points_frac = 0.5\n",
    "l1= ax.scatter(distance_range+0.25, theta_values, s=n_points_frac*np.array(number_points), alpha=0.7)\n",
    "ax.plot(distance_range+0.25, theta_values)#, s=number_points, alpha=0.7)\n",
    "\n",
    "ax.set_xlim(6,10)\n",
    "\n",
    "\n",
    "#handles, labels = l1.legend_elements(prop=\"sizes\", num = [500,1000,1500], alpha=0.7, color='blue')\n",
    "#leg = ax.legend(handles, labels, loc=\"lower right\", title=\"#Datapoints\", numpoints = 1, fontsize=13, labelspacing=1)\n",
    "#leg.get_title().set_fontsize('13')\n",
    "size1, size2, size3 = 500, 1500, 2500\n",
    "leg_colour = \"tab:blue\"\n",
    "leg1 = ax.scatter([],[],s = n_points_frac*size1, color=leg_colour, alpha=0.7)\n",
    "leg2 = ax.scatter([],[],s = n_points_frac*size2, color=leg_colour, alpha=0.7)\n",
    "leg3 = ax.scatter([],[],s = n_points_frac*size3, color=leg_colour, alpha=0.7)\n",
    "\n",
    "leg = ax.legend((leg1, leg2, leg3),\n",
    "             (str(size1),str(size2),str(size3)),\n",
    "             scatterpoints=1,\n",
    "             loc=\"lower right\",\n",
    "             ncol=1,\n",
    "             fontsize=13,\n",
    "             title = \"# datapoints\",\n",
    "             labelspacing=1.3)\n",
    "leg.get_title().set_fontsize('14')\n",
    "\n",
    "\n",
    "ax.set_xlabel(r\"Distance (kpc)\")\n",
    "ax.set_ylabel(r\"$\\theta_v \\hspace{0.4}[°]$\")\n",
    "\n",
    "filename = \"vertexdistance_\"+str(lmin)+\"l\"+str(lmax)+\"_\"+str(bmin)+\"b\"+str(bmax)+\"_\"+str(dmin)+\"d\"+str(dmax)+\".png\"\n",
    "plt.savefig(save_path + filename, bbox='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_vel = save_path + \"velocities_\"+str(lmin)+\"l\"+str(lmax)+\"_\"+str(bmin)+\"b\"+str(bmax)+'/'\n",
    "\n",
    "if not os.path.isdir(save_path_vel):\n",
    "    os.mkdir(save_path_vel)\n",
    "\n",
    "print(save_path_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(theta_values)):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.scatter(r_vel[index], t_vel[index], marker='.', color='grey')\n",
    "\n",
    "    cmap2 = 'coolwarm'\n",
    "\n",
    "    level_n = 10\n",
    "\n",
    "    sns.kdeplot(r_vel[index], t_vel[index], cmap=cmap2, cut=1, n_levels=level_n, fill=True, shade_lowest=False, \\\n",
    "                alpha=0.4, cbar=False, aspect='equal', extend='both')\n",
    "\n",
    "    mec = sns.kdeplot(r_vel[index], t_vel[index], cmap=cmap2, cut=1, n_levels=level_n, fill=False, shade_lowest=False, \\\n",
    "                alpha=1, cbar=True, aspect='equal', extend='both', linewidths=2, \\\n",
    "                      cbar_kws={'label': r'Probability density [$\\rm s^{2} \\hspace{0.3} km^{-2}$]'})\n",
    "\n",
    "    ax.set_xlabel(r\"$v_r$ [km $\\rm s^{-1}$]\")\n",
    "    ax.set_ylabel(r\"$\\mu_l$ [km $\\rm s^{-1}$]\")\n",
    "\n",
    "    text_box = dict(boxstyle='round', facecolor='wheat', alpha=1)\n",
    "    theta = theta_values[index]\n",
    "    ax.text(0.6, 0.95, r\"$\\theta_v=$\"+(r'$-$' if abs(theta) != theta else '')\\\n",
    "            +str(np.float16(abs(theta)))+'°', transform=ax.transAxes, fontsize=20, verticalalignment='top', bbox=text_box)\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    dmin = distance_range[index]\n",
    "    dmax = dmin + d_step\n",
    "    \n",
    "    ax.set_title(str(dmin)+r\" $\\leq$ Distance [kpc] $<$ \"+str(dmax), fontsize=18)\n",
    "    \n",
    "    filename = \"velocity_\"+str(lmin)+\"l\"+str(lmax)+\"_\"+str(bmin)+\"b\"+str(bmax)+\"_\"+str(dmin)+\"d\"+str(dmax)+\".png\"\n",
    "    plt.savefig(save_path_vel+filename, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "257.938px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
